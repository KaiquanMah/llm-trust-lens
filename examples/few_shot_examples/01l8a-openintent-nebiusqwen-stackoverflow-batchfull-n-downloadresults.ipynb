{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Refactored code for\n* Setting up and running Ollama in Kaggle\n* Downloading THUIAR dataset\n* Zero-Shot Prompt\n* Use LLM to classify intent from an input 'question' dataset\n* To configure your file/folder paths, LLM, dataset, start_index and end_index for each run, please update the config.py file\n\nThis notebook will also be used as the base to test any fixes to the LLM intent classification pipeline.\n* 2025.05.26: Updated results output file from JSON to Pickle, to store list of dictionaries. 1 dictionary contains the results for each record. Lists of dictionaries can be downloaded from multiple notebooks, then concatenated for analysis\n* 2025.05.30: Update prompt and bulletpts_intent.\n  * Check if dataset contains 'oos' (out of scope) category\n  * If dataset has no 'oos' (out of scope) category, turn 1 category into 'oos'. Use updated categories in bulletpts_intent. Also update prompt instructions on when to classify an example as 'oos'\n  * **This force_oos fix is implemented in [notebook 01E](https://www.kaggle.com/code/kaiquanmah/01e-kaggle-ollama-llama3-2-w-force-oos?scriptVersionId=242648764)**\n* 2025.05.30: Add pydantic schema with enums\n  * From an analysis of errors, the model previously had a 45% average accuracy rate across categories. The model predicted a set of categories outside of what we gave it in 'bulletpts_intent'\n  * To fix this, we will try to implement a pydantic schema solution for the model to only predict categories from the allowed list of categories ('bulletpts_intent')\n* 2025.05.30: Set Ollama chat temperature to 0\n  * Previously, we used the default temperature of 0.8, which might have caused the model to predict categories we did not provide to it ([Reading](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html))\n  * **The pydantic schema and temperature fixes are implemented in [notebook 01F](https://www.kaggle.com/code/kaiquanmah/01f-kaggle-ollama-llama3-2-w-pydantic-schema)**\n* 2025.06.03:\n  1. **Remove 'oos' from `bulletpts_intent` input into prompt**, to be consistent with the team's approach when exploring embedding approaches to classify 'oos' examples. **Keep 'oos' in pydantic enums/Literal (for LLM to output 'oos' as an allowed class value)**\n  2. **Remove 0.99 when defining the prompt format - to avoid anchoring LLM on outputting confidence of 0.99**\n  3. **Added ability for user to define which classes are 'oos'**\n  * **These 3 fixes are in [notebook 01G](https://www.kaggle.com/code/kaiquanmah/01g-kaggle-ollama-llama3-2-oos-update)**\n* 2025.06.10:\n  * From an error analysis earlier, **models can get confused between similar intent classes**\n  * Therefore **we will analyse similar intent classes/labels -> get their indexes -> put them into 'oos' in [notebook 01H](https://www.kaggle.com/code/kaiquanmah/01h1-openintent-ollama-llama3-2-3b-banking77)**\n  * **Going from zero-shot prompt previously, to few-shot prompt (with 5 examples) from known intents**. These 5 examples were **non-oos, and misclassified previously**. This 'fix' is in **[notebook 01i](https://www.kaggle.com/code/kaiquanmah/01i1-openintent-ollama-llama3-2-3b-banking77)**\n* 2025.06.16:\n  * For known intents (ie not in the 'oos' class), give 5 examples each in the few-shot prompt **[notebook 01J](https://www.kaggle.com/code/kaiquanmah/01j1-openintent-ollama-llama3-2-3b-banking77)**\n* 2025.06.17:\n  * Now we explore how changing the number of known intent classes affects the recall of oos in **[notebook 01K](https://www.kaggle.com/code/kaiquanmah/01k1-openintent-ollama-llama3-2-3b-banking77)**\n  * For quick experimentation, we implement (1) fewshot prompt with 1 example per known intent class, (2) changing number of known intent classes in various notebook runs, (3) 100 oos sentences for the model to classify (taking from first class for banking77 and stackoverflow dataset, or the oos class for CLINC150 oos dataset)\n    * For (3) - Added 'first_class' variable for each dataset to Config\n    * For (3) - Created new fn to filter and keep 100 records from 'first/oos class' to input to the model to classify\n* 2025.07.07:\n  * Explore free, rate-limited API model (such as Gemini) in **[notebook 01L](https://www.kaggle.com/code/kaiquanmah/01l1-openintent-gemini-banking77-explore)**\n  * Added retry for when we exhaust API limits per minute\n  * Updated end_index tracking that works with Ollama and Gemini when generating JSON results file\n  * **Explore Qwen model from the Nebius platform**","metadata":{}},{"cell_type":"code","source":"# 1. create dirs if they do not exist\nimport os\nos.makedirs('/kaggle/working/src', exist_ok=True)\nos.makedirs('/kaggle/working/prediction', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.497678Z","iopub.execute_input":"2025-07-08T05:00:14.498004Z","iopub.status.idle":"2025-07-08T05:00:14.506812Z","shell.execute_reply.started":"2025-07-08T05:00:14.497980Z","shell.execute_reply":"2025-07-08T05:00:14.505799Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%writefile /kaggle/working/src/setup_ollama.py\nimport os\nimport subprocess\nimport time\nfrom src.config import Config # absolute import\n\n# 1. Install Ollama (if not already installed)\ntry:\n    # Check if Ollama is already installed\n    subprocess.run([\"ollama\", \"--version\"], capture_output=True, check=True)\n    print(\"Ollama is already installed.\")\nexcept FileNotFoundError:\n    print(\"Installing Ollama...\")\n    subprocess.run(\"curl -fsSL https://ollama.com/install.sh  | sh\", shell=True, check=True)\n\n# 2. Start Ollama server in the background\nprint(\"Starting Ollama server...\")\nprocess = subprocess.Popen(\"ollama serve\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# Wait for the server to initialize\ntime.sleep(5)\n\n\n# 3. Pull the model\nmodel_name = Config.model_name\nprint(f\"Pulling {model_name} model...\")\nsubprocess.run([\"ollama\", \"pull\", model_name], check=True)\n\n# 4. Install Python client\nsubprocess.run([\"pip\", \"install\", \"ollama\"], check=True)\n\nprint(\"Ollama setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.508491Z","iopub.execute_input":"2025-07-08T05:00:14.508855Z","iopub.status.idle":"2025-07-08T05:00:14.544675Z","shell.execute_reply.started":"2025-07-08T05:00:14.508825Z","shell.execute_reply":"2025-07-08T05:00:14.543377Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/setup_ollama.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile requirements.txt\npandas\npydantic\ntyping\nhuggingface-hub\n# google-genai # only used for gemini model\nopenai # used for openrouter's gemini model\ntenacity # for gemini model retries\n# numpy\n# enum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.546052Z","iopub.execute_input":"2025-07-08T05:00:14.546441Z","iopub.status.idle":"2025-07-08T05:00:14.561778Z","shell.execute_reply.started":"2025-07-08T05:00:14.546411Z","shell.execute_reply":"2025-07-08T05:00:14.560791Z"}},"outputs":[{"name":"stdout","text":"Writing requirements.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile /kaggle/working/src/__init__.py\n# folder for config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.563883Z","iopub.execute_input":"2025-07-08T05:00:14.564166Z","iopub.status.idle":"2025-07-08T05:00:14.582138Z","shell.execute_reply.started":"2025-07-08T05:00:14.564145Z","shell.execute_reply":"2025-07-08T05:00:14.581164Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/__init__.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile /kaggle/working/src/config.py\nclass Config:\n    #######################################################\n    # working directory for files\n    #######################################################\n    target_dir = '/kaggle/working/data' # data directory to clone into\n    cloned_data_dir = target_dir + '/data'\n    prediction_dir = target_dir + '/prediction'\n    #######################################################\n    # dataset and model\n    #######################################################\n    dataset_name = 'stackoverflow' # UPDATE options: 'banking', 'stackoverflow', 'oos'\n    idx2label_target_dir = '/kaggle/working/idx2label'\n    idx2label_filename_hf = 'stackoverflow_idx2label.csv' # UPDATE options: banking77_idx2label.csv, stackoverflow_idx2label.csv, clinc150_oos_idx2label.csv\n    fewshot_examples_dir = '/kaggle/working/fewshot'\n    fewshot_subdir = '/fewshot-5examples-per-nonoos/'\n    fewshot_examples_filename = 'stackoverflow_25perc_oos.txt' # UPDATE options: banking_25perc_oos.txt, stackoverflow_25perc_oos.txt, oos_25perc_oos.txt\n    list_oos_idx = [0, 3, 10, 12, 14] # UPDATE gathered from within the team - for reproducible, comparable results with other open intent classification approaches\n    model_name = 'Qwen3-30B-A3B' # 'gemma-2-9b-it-fast'\n    start_index=0 # eg: 0, 10001, 11851\n    end_index=None # eg: 10, 10000, 11850 or None (use end_index=None to process the full dataset)\n    log_every_n_examples=10 # 2\n    force_oos = True  # NEW: Add flag to force dataset to contain 'oos' class for the last class value (sorted alphabetically), if 'oos' class does not exist in the original dataset\n    #######################################################\n    # evaluate threshold when 'oos' recall drops\n    #######################################################\n    filter_oos_qns_only = False # True (when you are testing 'oos' recall threshold), False\n    n_oos_qns = 100\n    first_class_banking = 'activate_my_card' # following idx2label\n    first_class_stackoverflow = 'wordpress' # following idx2label\n    first_class_oos = 'oos'\n    #######################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.583371Z","iopub.execute_input":"2025-07-08T05:00:14.583969Z","iopub.status.idle":"2025-07-08T05:00:14.599560Z","shell.execute_reply.started":"2025-07-08T05:00:14.583936Z","shell.execute_reply":"2025-07-08T05:00:14.598527Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/config.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%writefile download_dataset.py\nfrom src.config import Config\nimport os\nimport subprocess\ntarget_dir = Config.target_dir # data directory to clone into\ncloned_data_dir = Config.cloned_data_dir\n\n# Create target directory if it doesn't exist\nos.makedirs(target_dir, exist_ok=True)\n\n# do not clone dataset repo if cloned data folder exists\nif os.path.exists(cloned_data_dir):\n    print(\"Dataset has already been downloaded. If this is incorrect, please delete the Adaptive-Decision-Boundary 'data' folder.\")\nelse:\n    # Clone the repository\n    subprocess.run([\"git\",\n                    \"clone\",\n                    \"https://github.com/thuiar/Adaptive-Decision-Boundary.git\",\n                    target_dir\n                   ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.600677Z","iopub.execute_input":"2025-07-08T05:00:14.601001Z","iopub.status.idle":"2025-07-08T05:00:14.620084Z","shell.execute_reply.started":"2025-07-08T05:00:14.600974Z","shell.execute_reply":"2025-07-08T05:00:14.619226Z"}},"outputs":[{"name":"stdout","text":"Writing download_dataset.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile predict_class.py\nfrom src.config import Config\nimport pandas as pd\nimport os\n# import ollama\nimport json\nimport pickle\nimport time\nfrom pydantic import BaseModel\nfrom typing import Literal\n# from enum import Enum\nfrom huggingface_hub import snapshot_download\n    \n###################\n# Gemini API\n###################\n# from google import genai\n# from google.genai.types import ThinkingConfig\n# from google.api_core import retry\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nfrom kaggle_secrets import UserSecretsClient\n\n\n###################\n\n\n# Config.target_dir\n# Config.cloned_data_dir'\n# Config.dataset_name\n# Config.model_name\n# Config.start_index\n# Config.end_index\n# Config.log_every_n_examples\n\n\n#######################\n# load data\n#######################\ndef load_data(data_dir):\n    \"\"\"Loads train, dev, and test datasets from a specified directory.\"\"\"\n\n    main_df = pd.DataFrame()\n    for split in ['train', 'dev', 'test']:\n        file_path = os.path.join(data_dir, f'{split}.tsv')\n        if os.path.exists(file_path):\n          try:\n            df = pd.read_csv(file_path, sep='\\t')\n            df['dataset'] = os.path.basename(data_dir)\n            df['split'] = split\n            main_df = pd.concat([main_df, df], ignore_index=True)\n          except pd.errors.ParserError as e:\n            print(f\"Error parsing {file_path}: {e}\")\n            # Handle the error appropriately, e.g., skip the file, log the error, etc.\n        else:\n            print(f\"Warning: {split}.tsv not found in {data_dir}\")\n    return main_df\n\n\ndef filter100examples_oos(dataset_name, df):\n    # dont input 'only oos qns to model'\n    if Config.filter_oos_qns_only == False:\n        filtered_df = df\n    # vs\n    # input 'only oos qns to model'\n    else:\n        if dataset_name == 'banking':\n            first_class = Config.first_class_banking\n        elif dataset_name == 'stackoverflow':\n            first_class = Config.first_class_stackoverflow\n        else:\n            first_class = Config.first_class_oos\n    \n        filtered_df = df.copy()\n        filtered_df = filtered_df.loc[filtered_df[\"label\"] == first_class]\n        filtered_df = filtered_df.sample(n=Config.n_oos_qns, random_state=38)\n    return filtered_df\n\n\ndf = pd.DataFrame()\n\ndata_dir = os.path.join(Config.cloned_data_dir, Config.dataset_name)\nif os.path.exists(data_dir):\n  df = load_data(data_dir)\n  print(f\"Loaded dataset into dataframe: {Config.dataset_name}\")\n  print(f\"Dimensions: {df.shape}\")\n  print(f\"Col names: {df.columns}\")\nelse:\n  print(f\"Warning: Directory {data_dir} not found.\")\n#######################\n\n\n\n#######################\n# unique intents\n#######################\nsorted_intent = list(sorted(df.label.unique()))\nprint(\"=\"*80)\nprint(f\"Original dataset intents: {sorted_intent}\")\nprint(f\"Number of original intents: {len(sorted_intent)}\\n\")\n\n\n# 2025.06.03\n# New OOS approach - get 25/50/75% of class indexes for each dataset within the team (for reproducibility and comparable results)\n# Change their class labels to 'oos'\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir=Config.idx2label_target_dir)\nidx2label_filepath = Config.idx2label_target_dir + '/dataset_idx2label/' + Config.idx2label_filename_hf\nidx2label = pd.read_csv(idx2label_filepath)\nidx2label_oos = idx2label[idx2label.index.isin(Config.list_oos_idx)]\nidx2label_oos.reset_index(drop=True, inplace=True)\n\n# 2025.06.17 keep track of non-oos labels, to use in IntentSchema\nnonoos_labels = idx2label[~idx2label.label.isin(Config.list_oos_idx)]['label'].values\nprint(\"=\"*80)\nprint(\"Original intents to convert to OOS class\")\nprint(idx2label_oos)\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\\n\")\n\noos_labels = idx2label_oos['label'].values\nlist_sorted_intent_aft_conversion = ['oos' if intent.lower() in oos_labels else intent for intent in sorted_intent]\nlist_sorted_intent_aft_conversion_deduped = sorted(set(list_sorted_intent_aft_conversion))\nprint(\"=\"*80)\nprint(\"Unique intents after converting some to OOS class\")\nprint(list_sorted_intent_aft_conversion_deduped)\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\\n\")\n\n\n\n# unique intents - from set to bullet points (to use in prompts)\n# bulletpts_intent = \"\\n\".join(f\"- {category}\" for category in set_intent)\n# 2025.06.03: do not show 'oos' in the prompt (to avoid leakage of 'oos' class)\nbulletpts_intent = \"\\n\".join(f\"- {category}\" for category in list_sorted_intent_aft_conversion_deduped if category and (category!='oos'))\n\n# 2025.06.04: fix adjustment if 'oos' is already in the original dataset\nint_oos_in_orig_dataset = int('oos' in idx2label.label.values)\nadjust_if_oos_not_in_orig_dataset = [0 if int_oos_in_orig_dataset == 1 else 1][0]\n\nprint(\"=\"*80)\nprint(\"sanity check\")\nprint(f\"Number of original intents: {len(sorted_intent)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset): {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset}\")\nprint(f\"Number of original intents to convert to OOS class: {len(idx2label_oos)}\")\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\")\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)}\")\nprint(f\"Numbers match: {(len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)) == len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(\"Prepared unique intents\")\n#######################\n\n\n\n\n#######################\n# Enforce schema on the model (e.g. allowed list of predicted categories)\n#######################\n\nclass IntentSchema(BaseModel):\n    # dynamically unpack list of categories for different dataset(s)\n    category: Literal[*list_sorted_intent_aft_conversion_deduped]\n    confidence: float\n    \n#######################\n\n\n\n\n#######################\n# filter after preparing intents\n#######################\ndf = filter100examples_oos(Config.dataset_name, df)\nprint(\"Filtered dataset\")\nprint(f\"Dimensions: {df.shape}\")\nprint(f\"Col names: {df.columns}\")\n#######################\n\n\n\n#######################\n# Prompt\n#######################\n# prompt 2 with less information/compute, improve efficiency\n# 2025.06.10 prompt 3 with 5 few shot examples only - notebook O1H1, O1i1\n# 2025.06.16 prompt 4 with 5 examples per each known intent (ie non-oos intent) - notebook 01J1\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*.txt\", local_dir=Config.fewshot_examples_dir)\nwith open(Config.fewshot_examples_dir + Config.fewshot_subdir + Config.fewshot_examples_filename, 'r') as file:\n    fewshot_examples = file.read()\n\ndef get_prompt(dataset_name, split, question, categories, fewshot_examples):\n    \n    prompt = f'''\nYou are an expert in understanding and identifying what users are asking you.\n\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\n{categories}\n\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\n\nBelow are several examples to guide your classification:\n\n---\n{fewshot_examples}\n---\n\n===============================\n\nNew Question: {question}\n\n===============================\n\nProvide your final classification in **valid JSON format** with the following structure:\n{{\n  \"category\": \"your_chosen_category_name\",\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\n}}\n\n\nEnsure the JSON has:\n- Opening and closing curly braces\n- Double quotes around keys and string values\n- Confidence as a number (not a string), with maximum 2 decimal places\n\nDo not include any explanations or extra text.\n            '''\n    return prompt\n\n\n\n#######################\n\n\n#######################\n# Model on 1 Dataset\n#######################\n# Save a list of dictionaries \n# containing a dictionary for each record's\n# - predicted category\n# - confidence level and\n# - original dataframe values\n\n\n# gemini\nuser_secrets = UserSecretsClient()\nNEBIUS_API_KEY = user_secrets.get_secret(\"NEBIUS_API_KEY\")\nclient = OpenAI(base_url=\"https://api.studio.nebius.com/v1/\",\n                api_key = NEBIUS_API_KEY)\n\n@retry(stop=stop_after_attempt(3), wait=wait_fixed(30))\ndef api_llm(client, prompt):\n    try:\n        print(\"CHECKPOINT_3A\")\n        # gemini_config = {\"temperature\": 0,\n        #                  \"response_mime_type\": \"application/json\",\n        #                  \"response_schema\": IntentSchema.model_json_schema(),\n        #                  \"seed\": 38,\n        #                  # # added for \"gemini-2.5-flash-lite-preview-06-17\" model\n        #                  # \"thinking_config\": ThinkingConfig(thinking_budget=-1, \n        #                  #                    include_thoughts=True)\n        #                 }\n        response = client.beta.chat.completions.parse(model = 'Qwen/'+Config.model_name,\n                                                      messages = [{\"role\": \"user\",\n                                                                  \"content\": prompt}],\n                                                      response_format = IntentSchema,\n                                                      seed = 38,\n                                                      temperature = 0\n                                                      )\n        # print(response)\n        # msg = response.parsed\n        response = response.choices[0].message.content\n        print(\"CHECKPOINT_3B\")\n        return response\n    except:\n        print(f\"CHECKPOINT_4A: Exception Type: {type(e).__name__}\")\n        print(f\"CHECKPOINT_4A: Exception Message: {str(e)}\")\n        \n        # Gemini-specific errors\n        if hasattr(e, 'code'):\n            print(f\"CHECKPOINT_4A: Status Code: {e.code}\")\n        if hasattr(e, 'details'):\n            print(f\"CHECKPOINT_4A: Details: {e.details}\")\n        \n        # raise the exception again so retry can work\n        raise\n\n    \n\ndef predict_intent(model_name, df, categories, start_index=0, end_index=None, log_every_n_examples=100):\n    start_time = time.time()\n    results = []  # Store processed results\n    \n    # Slice DataFrame based on start/end indices\n    if end_index is None:\n        subset_df = df.iloc[start_index:]\n    else:\n        subset_df = df.iloc[start_index:end_index+1]\n    \n    total_rows = len(subset_df)\n    subset_row_count = 0\n\n    \n\n    \n    \n    for row in subset_df.itertuples():\n        subset_row_count+=1\n        prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n        if subset_row_count == 1:\n            print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n            print(prompt)\n\n            print(\"Example of how IntentSchema looks\")\n            print(IntentSchema.model_json_schema())\n        \n        \n        try:\n            print(\"CHECKPOINT_1A\")\n            \n            # response = ollama.chat(model=model_name, \n            #                        messages=[\n            #                                     {'role': 'user', 'content': prompt}\n            #                                 ],\n            #                        format = IntentSchema.model_json_schema(),\n            #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n            #                       )\n            # msg = response['message']['content']\n            # parsed = json.loads(msg)\n            \n            response = api_llm(client, prompt)\n            print(\"CHECKPOINT_1B\")\n            parsed = json.loads(response.text)\n            # parsed = response.parsed\n            print(\"CHECKPOINT_1C\")\n                        \n            # Safely extract keys with defaults - resolve parsing error\n            # maybe LLM did not output a particular key-value pair\n            category = parsed.get('category', 'error')\n            confidence = parsed.get('confidence', 0.0)\n            parsed = {'category': category, 'confidence': confidence}\n        except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(f\"CHECKPOINT_2A: Exception Type: {type(e).__name__}\")\n            print(f\"CHECKPOINT_2A: Exception Message: {str(e)}\")\n            \n            # Gemini-specific errors\n            if hasattr(e, 'code'):\n                print(f\"CHECKPOINT_2A: Status Code: {e.code}\")\n            if hasattr(e, 'details'):\n                print(f\"CHECKPOINT_2A: Details: {e.details}\")\n                \n            parsed = {'category': 'error', 'confidence': 0.0}\n        \n        # Combine original row data with predictions\n        results.append({\n            \"Index\": row.Index,\n            \"text\": row.text,\n            \"label\": row.label,\n            \"dataset\": row.dataset,\n            \"split\": row.split,\n            \"predicted\": parsed['category'],\n            \"confidence\": parsed['confidence']\n        })\n\n        \n        # Log progress\n        if subset_row_count % log_every_n_examples == 0:\n            elapsed_time = time.time() - start_time\n            \n            avg_time_per_row = elapsed_time / subset_row_count\n            remaining_rows = total_rows - subset_row_count\n            eta = avg_time_per_row * remaining_rows\n            \n            print(f\"Processed original df idx {row.Index} (subset row {subset_row_count}) | \"\n                  f\"Elapsed: {elapsed_time:.2f}s | ETA: {eta:.2f}s\")\n    \n    return results  # Return list of dictionaries\n    \n\nprint(f\"Starting intent classification using {Config.model_name}\")\nsubset_results = predict_intent(Config.model_name, \n                                df, \n                                bulletpts_intent, \n                                start_index = Config.start_index, \n                                end_index = Config.end_index,\n                                log_every_n_examples = Config.log_every_n_examples)\n\n\n\n# # previously for Ollama\n# # update end_index for filename (if None is used for the end of the df)\n# # Get the last index of the DataFrame\n# last_index = df.index[-1] \n# # Use last index if Config.end_index is None\n# end_index = Config.end_index if Config.end_index is not None else last_index\n# 2025.07.07\n# now for Ollama AND Gemini\n# Gemini - needs to track 'end_index' for API JSON exports (when daily limits are exhausted)\n# Ollama - reuse this code\nend_index = max(r['Index'] for r in subset_results)\n\n\n\n# 2025.05.23 changed from JSON to PKL\n# because we are saving list of dictionaries\n# Save to PKL\n# 2025.06.04 explore changing back to JSON\n# with open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.pkl', 'wb') as f:\n#     pickle.dump(subset_results, f)\nwith open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.json', 'w') as f:\n    json.dump(subset_results, f, indent=2)\n\nprint(\"Completed intent classification\")\n\n\n#######################\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.704308Z","iopub.execute_input":"2025-07-08T05:00:14.704638Z","iopub.status.idle":"2025-07-08T05:00:14.717471Z","shell.execute_reply.started":"2025-07-08T05:00:14.704584Z","shell.execute_reply":"2025-07-08T05:00:14.716357Z"}},"outputs":[{"name":"stdout","text":"Writing predict_class.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%writefile /kaggle/working/main.py\nimport subprocess\nimport sys\nfrom src.config import Config\n\n\n# 1. Install libraries from requirements.txt\nprint(\"Installing dependencies...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"/kaggle/working/requirements.txt\"], check=True)\n\n\n# # 2. Run setup_ollama.py\n# if 'gemini' not in Config.model_name:\n#     print(\"Starting Ollama setup...\")\n#     # subprocess.run([\"python3\", \"/kaggle/working/src/setup_ollama.py\"], check=True)\n#     print(\"Starting Ollama setup...\")\n#     subprocess.run(\n#         [\"python3\", \"-m\", \"src.setup_ollama\"],  # Run as a module\n#         cwd=\"/kaggle/working\",  # Set working directory to parent of 'src'\n#         check=True\n#     )\n    \n\n# 3. Run download_dataset.py\nprint(\"Downloading dataset...\")\nsubprocess.run([\"python3\", \"/kaggle/working/download_dataset.py\"], check=True)\n\n# 4. Run predict_class.py\nprint(\"Running prediction script...\")\nsubprocess.run([\"python3\", \"/kaggle/working/predict_class.py\"], check=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:14.719050Z","iopub.execute_input":"2025-07-08T05:00:14.719540Z","iopub.status.idle":"2025-07-08T05:00:14.738661Z","shell.execute_reply.started":"2025-07-08T05:00:14.719503Z","shell.execute_reply":"2025-07-08T05:00:14.737695Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/main.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Model on subset of examples","metadata":{}},{"cell_type":"code","source":"!python3 /kaggle/working/main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:42:43.036942Z","iopub.execute_input":"2025-07-07T06:42:43.037254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sanity check folders","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/working/ && ls -la","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/src && ls -la","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/data/data && ls -la","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# idx2label_oos examples","metadata":{}},{"cell_type":"code","source":"pip install huggingface-hub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir='/kaggle/working/idx2label')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nidx2label = pd.read_csv('/kaggle/working/idx2label/dataset_idx2label/banking77_idx2label.csv')\nidx2label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx2label_oos = idx2label[idx2label.index.isin([31,32,33,36])]\nidx2label_oos","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(idx2label_oos)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx2label_oos.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# percentage of OOS classes over ALL classes in the dataset\nlen(idx2label_oos)/len(idx2label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Batch","metadata":{}},{"cell_type":"code","source":"import subprocess\nimport sys\nfrom src.config import Config\n\n\n# 1. Install libraries from requirements.txt\nprint(\"Installing dependencies...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"/kaggle/working/requirements.txt\"], check=True)\n\n\n# # 2. Run setup_ollama.py\n# if 'gemini' not in Config.model_name:\n#     print(\"Starting Ollama setup...\")\n#     # subprocess.run([\"python3\", \"/kaggle/working/src/setup_ollama.py\"], check=True)\n#     print(\"Starting Ollama setup...\")\n#     subprocess.run(\n#         [\"python3\", \"-m\", \"src.setup_ollama\"],  # Run as a module\n#         cwd=\"/kaggle/working\",  # Set working directory to parent of 'src'\n#         check=True\n#     )\n    \n\n# 3. Run download_dataset.py\nprint(\"Downloading dataset...\")\nsubprocess.run([\"python3\", \"/kaggle/working/download_dataset.py\"], check=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:31.514339Z","iopub.execute_input":"2025-07-08T05:00:31.514680Z","iopub.status.idle":"2025-07-08T05:00:40.278572Z","shell.execute_reply.started":"2025-07-08T05:00:31.514656Z","shell.execute_reply":"2025-07-08T05:00:40.277678Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 2)) (2.11.4)\nCollecting typing (from -r /kaggle/working/requirements.txt (line 3))\n  Downloading typing-3.7.4.3.tar.gz (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 3.6 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 4)) (0.31.1)\nRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 6)) (1.70.0)\nRequirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 7)) (9.1.2)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (1.1.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r /kaggle/working/requirements.txt (line 6)) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r /kaggle/working/requirements.txt (line 6)) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r /kaggle/working/requirements.txt (line 6)) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r /kaggle/working/requirements.txt (line 6)) (0.9.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r /kaggle/working/requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai->-r /kaggle/working/requirements.txt (line 6)) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r /kaggle/working/requirements.txt (line 6)) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r /kaggle/working/requirements.txt (line 6)) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r /kaggle/working/requirements.txt (line 6)) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2.4.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nBuilding wheels for collected packages: typing\n  Building wheel for typing (setup.py): started\n  Building wheel for typing (setup.py): finished with status 'done'\n  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=e21696cbc9a250ede0c8cdc003e46f3145bd04cd19284c16907b29b03f24d1fb\n  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\nSuccessfully built typing\nInstalling collected packages: typing\nSuccessfully installed typing-3.7.4.3\nDownloading dataset...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/data'...\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['python3', '/kaggle/working/download_dataset.py'], returncode=0)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from src.config import Config\nimport pandas as pd\nimport os\n# import ollama\nimport json\nimport pickle\nimport time\nfrom pydantic import BaseModel\nfrom typing import Literal\n# from enum import Enum\nfrom huggingface_hub import snapshot_download\n    \n###################\n# Gemini API\n###################\n# from google import genai\n# from google.genai.types import ThinkingConfig\n# from google.api_core import retry\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nfrom kaggle_secrets import UserSecretsClient\n\n\n###################\n\n\n# Config.target_dir\n# Config.cloned_data_dir'\n# Config.dataset_name\n# Config.model_name\n# Config.start_index\n# Config.end_index\n# Config.log_every_n_examples\n\n\n#######################\n# load data\n#######################\ndef load_data(data_dir):\n    \"\"\"Loads train, dev, and test datasets from a specified directory.\"\"\"\n\n    main_df = pd.DataFrame()\n    for split in ['train', 'dev', 'test']:\n        file_path = os.path.join(data_dir, f'{split}.tsv')\n        if os.path.exists(file_path):\n          try:\n            df = pd.read_csv(file_path, sep='\\t')\n            df['dataset'] = os.path.basename(data_dir)\n            df['split'] = split\n            main_df = pd.concat([main_df, df], ignore_index=True)\n          except pd.errors.ParserError as e:\n            print(f\"Error parsing {file_path}: {e}\")\n            # Handle the error appropriately, e.g., skip the file, log the error, etc.\n        else:\n            print(f\"Warning: {split}.tsv not found in {data_dir}\")\n    return main_df\n\n\ndef filter100examples_oos(dataset_name, df):\n    # dont input 'only oos qns to model'\n    if Config.filter_oos_qns_only == False:\n        filtered_df = df\n    # vs\n    # input 'only oos qns to model'\n    else:\n        if dataset_name == 'banking':\n            first_class = Config.first_class_banking\n        elif dataset_name == 'stackoverflow':\n            first_class = Config.first_class_stackoverflow\n        else:\n            first_class = Config.first_class_oos\n    \n        filtered_df = df.copy()\n        filtered_df = filtered_df.loc[filtered_df[\"label\"] == first_class]\n        filtered_df = filtered_df.sample(n=Config.n_oos_qns, random_state=38)\n    return filtered_df\n\n\ndf = pd.DataFrame()\n\ndata_dir = os.path.join(Config.cloned_data_dir, Config.dataset_name)\nif os.path.exists(data_dir):\n  df = load_data(data_dir)\n  print(f\"Loaded dataset into dataframe: {Config.dataset_name}\")\n  print(f\"Dimensions: {df.shape}\")\n  print(f\"Col names: {df.columns}\")\nelse:\n  print(f\"Warning: Directory {data_dir} not found.\")\n#######################\n\n\n\n#######################\n# unique intents\n#######################\nsorted_intent = list(sorted(df.label.unique()))\nprint(\"=\"*80)\nprint(f\"Original dataset intents: {sorted_intent}\")\nprint(f\"Number of original intents: {len(sorted_intent)}\\n\")\n\n\n# 2025.06.03\n# New OOS approach - get 25/50/75% of class indexes for each dataset within the team (for reproducibility and comparable results)\n# Change their class labels to 'oos'\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir=Config.idx2label_target_dir)\nidx2label_filepath = Config.idx2label_target_dir + '/dataset_idx2label/' + Config.idx2label_filename_hf\nidx2label = pd.read_csv(idx2label_filepath)\nidx2label_oos = idx2label[idx2label.index.isin(Config.list_oos_idx)]\nidx2label_oos.reset_index(drop=True, inplace=True)\n\n# 2025.06.17 keep track of non-oos labels, to use in IntentSchema\nnonoos_labels = idx2label[~idx2label.label.isin(Config.list_oos_idx)]['label'].values\nprint(\"=\"*80)\nprint(\"Original intents to convert to OOS class\")\nprint(idx2label_oos)\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\\n\")\n\noos_labels = idx2label_oos['label'].values\nlist_sorted_intent_aft_conversion = ['oos' if intent.lower() in oos_labels else intent for intent in sorted_intent]\nlist_sorted_intent_aft_conversion_deduped = sorted(set(list_sorted_intent_aft_conversion))\nprint(\"=\"*80)\nprint(\"Unique intents after converting some to OOS class\")\nprint(list_sorted_intent_aft_conversion_deduped)\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\\n\")\n\n\n\n# unique intents - from set to bullet points (to use in prompts)\n# bulletpts_intent = \"\\n\".join(f\"- {category}\" for category in set_intent)\n# 2025.06.03: do not show 'oos' in the prompt (to avoid leakage of 'oos' class)\nbulletpts_intent = \"\\n\".join(f\"- {category}\" for category in list_sorted_intent_aft_conversion_deduped if category and (category!='oos'))\n\n# 2025.06.04: fix adjustment if 'oos' is already in the original dataset\nint_oos_in_orig_dataset = int('oos' in idx2label.label.values)\nadjust_if_oos_not_in_orig_dataset = [0 if int_oos_in_orig_dataset == 1 else 1][0]\n\nprint(\"=\"*80)\nprint(\"sanity check\")\nprint(f\"Number of original intents: {len(sorted_intent)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset): {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset}\")\nprint(f\"Number of original intents to convert to OOS class: {len(idx2label_oos)}\")\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\")\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)}\")\nprint(f\"Numbers match: {(len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)) == len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(\"Prepared unique intents\")\n#######################\n\n\n\n\n#######################\n# Enforce schema on the model (e.g. allowed list of predicted categories)\n#######################\n\nclass IntentSchema(BaseModel):\n    # dynamically unpack list of categories for different dataset(s)\n    category: Literal[*list_sorted_intent_aft_conversion_deduped]\n    confidence: float\n    \n#######################\n\n\n\n\n#######################\n# filter after preparing intents\n#######################\ndf = filter100examples_oos(Config.dataset_name, df)\nprint(\"Filtered dataset\")\nprint(f\"Dimensions: {df.shape}\")\nprint(f\"Col names: {df.columns}\")\n#######################\n\n\n\n#######################\n# Prompt\n#######################\n# prompt 2 with less information/compute, improve efficiency\n# 2025.06.10 prompt 3 with 5 few shot examples only - notebook O1H1, O1i1\n# 2025.06.16 prompt 4 with 5 examples per each known intent (ie non-oos intent) - notebook 01J1\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*.txt\", local_dir=Config.fewshot_examples_dir)\nwith open(Config.fewshot_examples_dir + Config.fewshot_subdir + Config.fewshot_examples_filename, 'r') as file:\n    fewshot_examples = file.read()\n\ndef get_prompt(dataset_name, split, question, categories, fewshot_examples):\n    \n    prompt = f'''\nYou are an expert in understanding and identifying what users are asking you.\n\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\n{categories}\n\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\n\nBelow are several examples to guide your classification:\n\n---\n{fewshot_examples}\n---\n\n===============================\n\nNew Question: {question}\n\n===============================\n\nProvide your final classification in **valid JSON format** with the following structure:\n{{\n  \"category\": \"your_chosen_category_name\",\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\n}}\n\n\nEnsure the JSON has:\n- Opening and closing curly braces\n- Double quotes around keys and string values\n- Confidence as a number (not a string), with maximum 2 decimal places\n\nDo not include any explanations or extra text.\n            '''\n    return prompt\n\n\n\n#######################\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:40.280168Z","iopub.execute_input":"2025-07-08T05:00:40.280508Z","iopub.status.idle":"2025-07-08T05:00:46.803508Z","shell.execute_reply.started":"2025-07-08T05:00:40.280479Z","shell.execute_reply":"2025-07-08T05:00:46.801003Z"}},"outputs":[{"name":"stdout","text":"Loaded dataset into dataframe: stackoverflow\nDimensions: (20000, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\n================================================================================\nOriginal dataset intents: ['ajax', 'apache', 'bash', 'cocoa', 'drupal', 'excel', 'haskell', 'hibernate', 'linq', 'magento', 'matlab', 'oracle', 'osx', 'qt', 'scala', 'sharepoint', 'spring', 'svn', 'visual-studio', 'wordpress']\nNumber of original intents: 20\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdfea1a1496947e485bcabcdf9d4d4f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_idx2label.csv:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15200a33ff64f41a177b1eba3ecd469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"clinc150_oos_idx2label.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793e2d02075d4c82bfdebc730f5bd6af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking77_idx2label.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2ca1b96d534fe3b066588deb9d6dc3"}},"metadata":{}},{"name":"stdout","text":"================================================================================\nOriginal intents to convert to OOS class\n   index      label\n0      1  wordpress\n1      4     apache\n2     11     spring\n3     13      scala\n4     15       ajax\nPercentage of original intents to convert to OOS class: 0.25\n\n================================================================================\nUnique intents after converting some to OOS class\n['bash', 'cocoa', 'drupal', 'excel', 'haskell', 'hibernate', 'linq', 'magento', 'matlab', 'oos', 'oracle', 'osx', 'qt', 'sharepoint', 'svn', 'visual-studio']\nNumber of unique intents after converting some to OOS class: 16\n\n================================================================================\nsanity check\nNumber of original intents: 20\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset): 21\nNumber of original intents to convert to OOS class: 5\nPercentage of original intents to convert to OOS class: 0.25\nNumber of unique intents after converting some to OOS class: 16\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: 16\nNumbers match: True\nPrepared unique intents\nFiltered dataset\nDimensions: (20000, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 62 files:   0%|          | 0/62 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ced6eb81d4f54ae6b5dd947fb221d3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only2notoos.txt:   0%|          | 0.00/419 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae980ffd8e7431aaf54aaf494deeea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only15notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf8938619e841e3931265a6e09537e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only35notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c92a66c9c5d4a0d924fd53d74a99d1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only20notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0f534cb9e24b09ac2db329e813b70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only3notoos.txt:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba59dac7b5c94c00bb4f81265c5ec520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only30notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa8f29956794164ba97e6bd2e9fa4e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only1notoos.txt:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f31cd53918483d9ece44af4cdd5d19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only10notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6288239c0ffc43db8cdb44c4d0d12b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only50notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc4b324134a4917954591b41bab2434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only60notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6caaa19487d498ebe300f9ce41c1105"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only5notoos.txt:   0%|          | 0.00/835 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e6cb6fe4ce449abc11994c6e7c06bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only40notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"756eebd1466e47c28767a21179f94b92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only70notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66fe36e4c15d4e47bcee95b266663d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_10notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f62be27d84e54a6ab8981e1d5fde6b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_only4notoos.txt:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f174ce15f347c99ba1dd88e302139a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_100notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbf19b2130234f39948a92330289e1f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_140notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7360a838964c518ce6b2cc99416463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_14notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b561c23bae94713aec1c92073d73804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_13notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9262621eab409f98536e52a2218245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_11notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41fd12e58aa9456896c60e6eeb088947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_12notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315c14c7aac0455c966af163af297d6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_120notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644111e22b604887bb6d543ba3f98e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_15notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4544ff008fe4e3c84610790fb42e780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_1notoos.txt:   0%|          | 0.00/121 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d9e55fdd3c4c43a5ad47ee55e7e280"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_3notoos.txt:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec869faf1a543129af99e0aef77c9b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_30notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea2a1dd77c6472ea52e7b6106b773a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_20notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a7be70ea2d4caf9e06e3f1e91f2281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_40notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"355f486066ad4b1487583c1618a75b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_2notoos.txt:   0%|          | 0.00/259 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee0d6916c0e4920a9a55b34b172d496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_4notoos.txt:   0%|          | 0.00/537 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77bc343ebc24416fb01ba0a0276c20fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_50notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5aacf38bbb946bcaf2d4f6096349962"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_5notoos.txt:   0%|          | 0.00/731 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a768dba94a945f1adc79f6360ee9599"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only10notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93835bdce8c475497b05e2e25cd639a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only12notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f433fa20e2fb4428b9df5e9ed45509ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_75notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3378f69afc304d55b0338b0ccc373009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only2notoos.txt:   0%|          | 0.00/288 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9e66c520d94fc4aa876c46e75f8598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only18notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a0b4ae9f5cb4dce926b63a7f6305926"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only16notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2d9cc2e878c45ada39d641054687ef5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only14notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a80b2d361f254c499bea653185673a60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only1notoos.txt:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112223b3465645f7a440351b8b6655eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only3notoos.txt:   0%|          | 0.00/420 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"863c886e28d940588eaebc381b6420c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only5notoos.txt:   0%|          | 0.00/715 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f1b637b4ba44ee805b0f4668b32720"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only4notoos.txt:   0%|          | 0.00/591 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab859f4bc6b42dc8e03666ab5a81b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"banking_25perc_oos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4f1bf63c9a2416194f7d9f418d4c23f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"oos_25perc_oos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83eb33f6580047208fc2d28f289e4476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only6notoos.txt:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b38cbe68c1b4280b40c9f6af878abe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_25perc_oos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4a92da0084943948eb3a98e853a1d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only8notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec263a33ba214893a1b773ba0c9bd0c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stackoverflow_only2notoos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac241a1ef72c42c284a521054993ce39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"logs_cpu_2025.05.22%20round1.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10b4311366b4e2ba588547ec3b8d646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)5.05.22%20round2%20w%20start-end-idx.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5021418b3b74a0f98709b56c35893c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)u_2025.05.22%20round4%20parallelise2.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519851affd7f46f294100e0b7983b1a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ification_report_llama3.2_3b_banking.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b4ba4fef7a84f5b8cd6b0f9791a3ead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)lassification_report_llama3.2_3b_oos.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a475e71d3b594a6dbb20b9aa7c086f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"logs_cpu_2025.05.22%20round2.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5513df2247474cb683d4aa0a6fdb0cdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)u_2025.05.22%20round3%20parallelise1.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77eb62703de46c2aef5a782d882913f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"logs_gpu_2025.05.22.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5e47a3393f8486c99925c7f391496ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ion_report_llama3.2_3b_stackoverflow.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592814ef96524017bd38a1d06f3e2089"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)tion_report_llama3.2_3b_banking_full.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18afa7482de492392d0b3243a90dddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)eport_llama3.2_3b_stackoverflow_full.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e04637e8b8f42179aedffdbc042d35b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)lama3.2_3b_stackoverflow_only2notoos.txt:   0%|          | 0.00/380 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3366d684823e42b6a6a089e87d9999d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)fication_report_llama3.2_3b_oos_full.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4b86645997456fb34f4caa79f0d668"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## [New Task] Create Batch JSONL file of requests to Nebius' Qwen model\n* https://docs.nebius.com/studio/inference/batch","metadata":{}},{"cell_type":"code","source":"# gemini\nuser_secrets = UserSecretsClient()\nNEBIUS_API_KEY = user_secrets.get_secret(\"NEBIUS_API_KEY\")\nclient = OpenAI(base_url=\"https://api.studio.nebius.com/v1/\",\n                api_key = NEBIUS_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:46.805158Z","iopub.execute_input":"2025-07-08T05:00:46.805866Z","iopub.status.idle":"2025-07-08T05:00:47.345904Z","shell.execute_reply.started":"2025-07-08T05:00:46.805830Z","shell.execute_reply":"2025-07-08T05:00:47.344984Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model_name = Config.model_name\ndf = df\ncategories = bulletpts_intent\nstart_index = Config.start_index\nend_index = Config.end_index\nlog_every_n_examples = Config.log_every_n_examples\n\n\n\nstart_time = time.time()\nresults = []  # Store processed results\n\n# Slice DataFrame based on start/end indices\nif end_index is None:\n    subset_df = df.iloc[start_index:]\nelse:\n    subset_df = df.iloc[start_index:end_index+1]\n\ntotal_rows = len(subset_df)\nsubset_row_count = 0\n\n\n\n\n\nfor row in subset_df.itertuples():\n    subset_row_count+=1\n    prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n    if subset_row_count == 1:\n        print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n        # print(prompt)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:00:50.226477Z","iopub.execute_input":"2025-07-08T05:00:50.227080Z","iopub.status.idle":"2025-07-08T05:00:50.235806Z","shell.execute_reply.started":"2025-07-08T05:00:50.227053Z","shell.execute_reply":"2025-07-08T05:00:50.234680Z"}},"outputs":[{"name":"stdout","text":"Example of how prompt looks, for the 1st example in this subset of data\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def create_batch_file(df, categories):\n    requests = []\n    for row in df.itertuples():\n        # # round 1 - test 10 records\n        # if row.Index < 10:\n        # round 2 - FULL RUN\n        prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n        requests.append({\n            \"custom_id\": row.Index,\n            \"method\": \"POST\",\n            \"url\": \"/v1/chat/completions\",\n            \"body\": {\n                \"model\": f\"Qwen/{Config.model_name}\",\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                \"seed\": 38,\n                \"temperature\": 0,\n                \"extra_body\": {\"guided_json\": IntentSchema.model_json_schema()}\n            }\n        })\n    \n    # Save to JSONL file\n    batch_file_path = f\"/kaggle/working/batch_prompts_{Config.dataset_name}_{Config.start_index}_{Config.end_index}.jsonl\"\n    with open(batch_file_path, 'w') as f:\n        for req in requests:\n            f.write(json.dumps(req) + '\\n')\n    \n    return batch_file_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:01:15.836781Z","iopub.execute_input":"2025-07-08T05:01:15.837171Z","iopub.status.idle":"2025-07-08T05:01:15.847136Z","shell.execute_reply.started":"2025-07-08T05:01:15.837144Z","shell.execute_reply":"2025-07-08T05:01:15.845965Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"start_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:01:05.818940Z","iopub.execute_input":"2025-07-08T05:01:05.819297Z","iopub.status.idle":"2025-07-08T05:01:05.825915Z","shell.execute_reply.started":"2025-07-08T05:01:05.819271Z","shell.execute_reply":"2025-07-08T05:01:05.824544Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"len(subset_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:01:07.621630Z","iopub.execute_input":"2025-07-08T05:01:07.622275Z","iopub.status.idle":"2025-07-08T05:01:07.627894Z","shell.execute_reply.started":"2025-07-08T05:01:07.622250Z","shell.execute_reply":"2025-07-08T05:01:07.626968Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"20000"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:01:09.537909Z","iopub.execute_input":"2025-07-08T05:01:09.538229Z","iopub.status.idle":"2025-07-08T05:01:09.544953Z","shell.execute_reply.started":"2025-07-08T05:01:09.538205Z","shell.execute_reply":"2025-07-08T05:01:09.543881Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"20000"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"batch_file_path = create_batch_file(df, categories)\nbatch_file_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:01:18.574727Z","iopub.execute_input":"2025-07-08T05:01:18.575471Z","iopub.status.idle":"2025-07-08T05:01:26.413394Z","shell.execute_reply.started":"2025-07-08T05:01:18.575435Z","shell.execute_reply":"2025-07-08T05:01:26.412647Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/batch_prompts_stackoverflow_0_None.jsonl'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import json\nlist_prompts = []\n\nwith open(f'/kaggle/working/batch_prompts_{Config.dataset_name}_{Config.start_index}_{Config.end_index}.jsonl', 'r') as f:\n    list_prompts = [json.loads(line) for line in f if line.strip()]\n\nlist_prompts[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:02:38.049450Z","iopub.execute_input":"2025-07-08T05:02:38.049816Z","iopub.status.idle":"2025-07-08T05:02:39.943524Z","shell.execute_reply.started":"2025-07-08T05:02:38.049792Z","shell.execute_reply":"2025-07-08T05:02:39.942401Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'custom_id': 0,\n 'method': 'POST',\n 'url': '/v1/chat/completions',\n 'body': {'model': 'Qwen/Qwen3-30B-A3B',\n  'messages': [{'role': 'user',\n    'content': '\\nYou are an expert in understanding and identifying what users are asking you.\\n\\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\\n- bash\\n- cocoa\\n- drupal\\n- excel\\n- haskell\\n- hibernate\\n- linq\\n- magento\\n- matlab\\n- oracle\\n- osx\\n- qt\\n- sharepoint\\n- svn\\n- visual-studio\\n\\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\\n\\nBelow are several examples to guide your classification:\\n\\n---\\nExample 1:\\nQuestion: \"DO NOT TRY THIS! The following bash command will spawn processes to kernel death. Can you explain the syntax?\"\\nCategory:\\n{{\\n  \"category\": \"bash\",\\n  \"confidence\": 82.28\\n}}\\n\\nExample 2:\\nQuestion: \"bash case statements evaluate to strings\"\\nCategory:\\n{{\\n  \"category\": \"bash\",\\n  \"confidence\": 69.07\\n}}\\n\\nExample 3:\\nQuestion: \"BASH: Test whether string is valid as an integer?\"\\nCategory:\\n{{\\n  \"category\": \"bash\",\\n  \"confidence\": 4.53\\n}}\\n\\nExample 4:\\nQuestion: \"How to run two processes as though they were one in bash?\"\\nCategory:\\n{{\\n  \"category\": \"bash\",\\n  \"confidence\": 98.12\\n}}\\n\\nExample 5:\\nQuestion: \"How to process file names with variables from a list in a file in Bash\"\\nCategory:\\n{{\\n  \"category\": \"bash\",\\n  \"confidence\": 75.48\\n}}\\n\\nExample 6:\\nQuestion: \"Returning a pointer to memory allocated within a function in Cocoa Objective-C.\"\\nCategory:\\n{{\\n  \"category\": \"cocoa\",\\n  \"confidence\": 25.98\\n}}\\n\\nExample 7:\\nQuestion: \"Hot to select items in NSOutlineView without NSTreeController?\"\\nCategory:\\n{{\\n  \"category\": \"cocoa\",\\n  \"confidence\": 29.92\\n}}\\n\\nExample 8:\\nQuestion: \"What\\'s a good way to bind from a shared utility window and the frontmost document window?\"\\nCategory:\\n{{\\n  \"category\": \"cocoa\",\\n  \"confidence\": 72.35\\n}}\\n\\nExample 9:\\nQuestion: \"OSX Audio Hijack style audio recording from other applications (cocoa)\"\\nCategory:\\n{{\\n  \"category\": \"cocoa\",\\n  \"confidence\": 27.41\\n}}\\n\\nExample 10:\\nQuestion: \"CocCoa Application\"\\nCategory:\\n{{\\n  \"category\": \"cocoa\",\\n  \"confidence\": 62.95\\n}}\\n\\nExample 11:\\nQuestion: \"Drupal : adding status field to node\"\\nCategory:\\n{{\\n  \"category\": \"drupal\",\\n  \"confidence\": 81.54\\n}}\\n\\nExample 12:\\nQuestion: \"Drupal theme preprocess function - primary links\"\\nCategory:\\n{{\\n  \"category\": \"drupal\",\\n  \"confidence\": 23.54\\n}}\\n\\nExample 13:\\nQuestion: \"How to develop drupal site on local server or on test server before publishing it\"\\nCategory:\\n{{\\n  \"category\": \"drupal\",\\n  \"confidence\": 84.65\\n}}\\n\\nExample 14:\\nQuestion: \"I want to create blog posts to drupal by sending messages through Outlook. Ideas??\"\\nCategory:\\n{{\\n  \"category\": \"drupal\",\\n  \"confidence\": 44.17\\n}}\\n\\nExample 15:\\nQuestion: \"How do you set up drupal menues?\"\\nCategory:\\n{{\\n  \"category\": \"drupal\",\\n  \"confidence\": 84.5\\n}}\\n\\nExample 16:\\nQuestion: \"Excel problem with deleting CustomProperty in Korean\"\\nCategory:\\n{{\\n  \"category\": \"excel\",\\n  \"confidence\": 30.96\\n}}\\n\\nExample 17:\\nQuestion: \"How to tell if an Excel Workbook is protected\"\\nCategory:\\n{{\\n  \"category\": \"excel\",\\n  \"confidence\": 65.99\\n}}\\n\\nExample 18:\\nQuestion: \"generate excel sheet from a excel template in asp.net using vb.net\"\\nCategory:\\n{{\\n  \"category\": \"excel\",\\n  \"confidence\": 1.84\\n}}\\n\\nExample 19:\\nQuestion: \"Analysing Excel VBA/Macro code\"\\nCategory:\\n{{\\n  \"category\": \"excel\",\\n  \"confidence\": 85.11\\n}}\\n\\nExample 20:\\nQuestion: \"Excel VBA Macro: create a chart from CSV?\"\\nCategory:\\n{{\\n  \"category\": \"excel\",\\n  \"confidence\": 25.48\\n}}\\n\\nExample 21:\\nQuestion: \"Why doesn\\'t the \"$\" function work consistantly?\"\\nCategory:\\n{{\\n  \"category\": \"haskell\",\\n  \"confidence\": 20.55\\n}}\\n\\nExample 22:\\nQuestion: \"Capturing audio input from microphone, with Haskell?\"\\nCategory:\\n{{\\n  \"category\": \"haskell\",\\n  \"confidence\": 22.99\\n}}\\n\\nExample 23:\\nQuestion: \"Is it recommended to always have exhaustive pattern matches in Haskell, even for \"impossible\" cases?\"\\nCategory:\\n{{\\n  \"category\": \"haskell\",\\n  \"confidence\": 2.22\\n}}\\n\\nExample 24:\\nQuestion: \"Implementing a cache\"\\nCategory:\\n{{\\n  \"category\": \"haskell\",\\n  \"confidence\": 27.32\\n}}\\n\\nExample 25:\\nQuestion: \"\"Pattern matching\" of algebraic type data constructors\"\\nCategory:\\n{{\\n  \"category\": \"haskell\",\\n  \"confidence\": 32.59\\n}}\\n\\nExample 26:\\nQuestion: \"How to integrate Hibernate with JBoss 4.2.x server?\"\\nCategory:\\n{{\\n  \"category\": \"hibernate\",\\n  \"confidence\": 60.06\\n}}\\n\\nExample 27:\\nQuestion: \"Hibernate: page results AND know the result size\"\\nCategory:\\n{{\\n  \"category\": \"hibernate\",\\n  \"confidence\": 63.62\\n}}\\n\\nExample 28:\\nQuestion: \"Save blob to DB using hibernate\"\\nCategory:\\n{{\\n  \"category\": \"hibernate\",\\n  \"confidence\": 50.59\\n}}\\n\\nExample 29:\\nQuestion: \"Using an enum as a mapkey results in a RAW in the database\"\\nCategory:\\n{{\\n  \"category\": \"hibernate\",\\n  \"confidence\": 45.02\\n}}\\n\\nExample 30:\\nQuestion: \"class not found exception in hibernate\"\\nCategory:\\n{{\\n  \"category\": \"hibernate\",\\n  \"confidence\": 38.31\\n}}\\n\\nExample 31:\\nQuestion: \"Can I use LINQ to convert a List<MyObjectType> into a DataSet?\"\\nCategory:\\n{{\\n  \"category\": \"linq\",\\n  \"confidence\": 64.98\\n}}\\n\\nExample 32:\\nQuestion: \"IQueryable efficiency\"\\nCategory:\\n{{\\n  \"category\": \"linq\",\\n  \"confidence\": 95.6\\n}}\\n\\nExample 33:\\nQuestion: \"LINQ to SQL - select where text like string array\"\\nCategory:\\n{{\\n  \"category\": \"linq\",\\n  \"confidence\": 93.69\\n}}\\n\\nExample 34:\\nQuestion: \"LINQ UpdateCheck on parent \"LastUpdatedOn\" field while updating children\"\\nCategory:\\n{{\\n  \"category\": \"linq\",\\n  \"confidence\": 16.37\\n}}\\n\\nExample 35:\\nQuestion: \"What is LINQ to events a.k.a RX Framework?\"\\nCategory:\\n{{\\n  \"category\": \"linq\",\\n  \"confidence\": 75.92\\n}}\\n\\nExample 36:\\nQuestion: \"Magento frontend and backend page looks different\"\\nCategory:\\n{{\\n  \"category\": \"magento\",\\n  \"confidence\": 9.1\\n}}\\n\\nExample 37:\\nQuestion: \"magento Baseurl from helper function\"\\nCategory:\\n{{\\n  \"category\": \"magento\",\\n  \"confidence\": 77.88\\n}}\\n\\nExample 38:\\nQuestion: \"Magento AND Prestashop, what better??\"\\nCategory:\\n{{\\n  \"category\": \"magento\",\\n  \"confidence\": 24.08\\n}}\\n\\nExample 39:\\nQuestion: \"Magento Ecommerce\"\\nCategory:\\n{{\\n  \"category\": \"magento\",\\n  \"confidence\": 26.06\\n}}\\n\\nExample 40:\\nQuestion: \"Import button + File browse field in admin product grid in magento\"\\nCategory:\\n{{\\n  \"category\": \"magento\",\\n  \"confidence\": 93.83\\n}}\\n\\nExample 41:\\nQuestion: \"spike in my inverse fourier transform.\"\\nCategory:\\n{{\\n  \"category\": \"matlab\",\\n  \"confidence\": 86.37\\n}}\\n\\nExample 42:\\nQuestion: \"MATLAB runs out of memory during program execution\"\\nCategory:\\n{{\\n  \"category\": \"matlab\",\\n  \"confidence\": 86.99\\n}}\\n\\nExample 43:\\nQuestion: \"Compiling MatLab 2009b applications to Windows Executables\"\\nCategory:\\n{{\\n  \"category\": \"matlab\",\\n  \"confidence\": 55.41\\n}}\\n\\nExample 44:\\nQuestion: \"Is there a better way to declare an empty, typed matrix in MATLAB?\"\\nCategory:\\n{{\\n  \"category\": \"matlab\",\\n  \"confidence\": 18.05\\n}}\\n\\nExample 45:\\nQuestion: \"How to convert a web page into an image using MATLAB?\"\\nCategory:\\n{{\\n  \"category\": \"matlab\",\\n  \"confidence\": 59.2\\n}}\\n\\nExample 46:\\nQuestion: \"Is there a way to enable / disable constraints in db2 v7?\"\\nCategory:\\n{{\\n  \"category\": \"oracle\",\\n  \"confidence\": 54.05\\n}}\\n\\nExample 47:\\nQuestion: \"ORA-00933: SQL command not properly ended\"\\nCategory:\\n{{\\n  \"category\": \"oracle\",\\n  \"confidence\": 29.04\\n}}\\n\\nExample 48:\\nQuestion: \"Joining other tables in oracle tree queries\"\\nCategory:\\n{{\\n  \"category\": \"oracle\",\\n  \"confidence\": 78.23\\n}}\\n\\nExample 49:\\nQuestion: \"What is an effective way to  track, identify and report every \\'error message raised by your application similar to Oracle\\'s ORA-00237 database error codes?\"\\nCategory:\\n{{\\n  \"category\": \"oracle\",\\n  \"confidence\": 40.0\\n}}\\n\\nExample 50:\\nQuestion: \"Oracle: Create table as select from another database?\"\\nCategory:\\n{{\\n  \"category\": \"oracle\",\\n  \"confidence\": 46.96\\n}}\\n\\nExample 51:\\nQuestion: \"backporting NSWindowDelegates windowDidEndLiveResize behaviour in OSX 10.5?\"\\nCategory:\\n{{\\n  \"category\": \"osx\",\\n  \"confidence\": 93.66\\n}}\\n\\nExample 52:\\nQuestion: \"What is the syntax for custom stacks for the OSX Leopard dock?\"\\nCategory:\\n{{\\n  \"category\": \"osx\",\\n  \"confidence\": 56.47\\n}}\\n\\nExample 53:\\nQuestion: \"OS X Mac and writing a twain scanning application.\"\\nCategory:\\n{{\\n  \"category\": \"osx\",\\n  \"confidence\": 57.89\\n}}\\n\\nExample 54:\\nQuestion: \"Mac solution for \"safe\" C/C++ Standard Library functions?\"\\nCategory:\\n{{\\n  \"category\": \"osx\",\\n  \"confidence\": 24.46\\n}}\\n\\nExample 55:\\nQuestion: \"Does anyone use BetterAuthorizationSample?\"\\nCategory:\\n{{\\n  \"category\": \"osx\",\\n  \"confidence\": 48.84\\n}}\\n\\nExample 56:\\nQuestion: \"QT Model/View programming with complicated data structures\"\\nCategory:\\n{{\\n  \"category\": \"qt\",\\n  \"confidence\": 94.04\\n}}\\n\\nExample 57:\\nQuestion: \"Where can I store a QAction(Group) ID?\"\\nCategory:\\n{{\\n  \"category\": \"qt\",\\n  \"confidence\": 70.9\\n}}\\n\\nExample 58:\\nQuestion: \"mingw spitting countless warnings about ignoring \"dll import\" attribute\"\\nCategory:\\n{{\\n  \"category\": \"qt\",\\n  \"confidence\": 44.84\\n}}\\n\\nExample 59:\\nQuestion: \"Phonon VideoWidget error: \"the video widget could not be initialized correctly\"\"\\nCategory:\\n{{\\n  \"category\": \"qt\",\\n  \"confidence\": 24.85\\n}}\\n\\nExample 60:\\nQuestion: \"Libqxt under Qt Creator\"\\nCategory:\\n{{\\n  \"category\": \"qt\",\\n  \"confidence\": 20.67\\n}}\\n\\nExample 61:\\nQuestion: \"SPFarm.Local.Solutions.Add - Exception - \"Access Denied\"\"\\nCategory:\\n{{\\n  \"category\": \"sharepoint\",\\n  \"confidence\": 9.56\\n}}\\n\\nExample 62:\\nQuestion: \"What are the Valid values of the searchboxex AppQueryTerms enum?\"\\nCategory:\\n{{\\n  \"category\": \"sharepoint\",\\n  \"confidence\": 65.55\\n}}\\n\\nExample 63:\\nQuestion: \"Getting all the webpages of a SPWeb and subwebs that have a field with a value in Sharepoint?\"\\nCategory:\\n{{\\n  \"category\": \"sharepoint\",\\n  \"confidence\": 68.53\\n}}\\n\\nExample 64:\\nQuestion: \"What knowledge should a software architect have about SharePoint?\"\\nCategory:\\n{{\\n  \"category\": \"sharepoint\",\\n  \"confidence\": 79.54\\n}}\\n\\nExample 65:\\nQuestion: \"Defaulting WebParts on a Users MySite in Sharepoint\"\\nCategory:\\n{{\\n  \"category\": \"sharepoint\",\\n  \"confidence\": 68.68\\n}}\\n\\nExample 66:\\nQuestion: \"SVN Weirdness: Is It Possible It\\'s Not My Fault\"\\nCategory:\\n{{\\n  \"category\": \"svn\",\\n  \"confidence\": 63.7\\n}}\\n\\nExample 67:\\nQuestion: \"Is there a way to know the URL of the SVN server?\"\\nCategory:\\n{{\\n  \"category\": \"svn\",\\n  \"confidence\": 35.18\\n}}\\n\\nExample 68:\\nQuestion: \"Advice on setting up a server to host source code and other documents...\"\\nCategory:\\n{{\\n  \"category\": \"svn\",\\n  \"confidence\": 9.38\\n}}\\n\\nExample 69:\\nQuestion: \"how do I integrate a branch into a trunk if the folder structure has changed?\"\\nCategory:\\n{{\\n  \"category\": \"svn\",\\n  \"confidence\": 19.52\\n}}\\n\\nExample 70:\\nQuestion: \"What is the best way to make files live using subversion on a production server?\"\\nCategory:\\n{{\\n  \"category\": \"svn\",\\n  \"confidence\": 80.7\\n}}\\n\\nExample 71:\\nQuestion: \"Visual Studio - Prevent stopping debugging from closing Internet Explorer\"\\nCategory:\\n{{\\n  \"category\": \"visual-studio\",\\n  \"confidence\": 48.12\\n}}\\n\\nExample 72:\\nQuestion: \"Optimization settings in VS\"\\nCategory:\\n{{\\n  \"category\": \"visual-studio\",\\n  \"confidence\": 33.56\\n}}\\n\\nExample 73:\\nQuestion: \"Visual Studio 2008: make ctrl-k, ctrl-n (next bookmark) stay within the same file\"\\nCategory:\\n{{\\n  \"category\": \"visual-studio\",\\n  \"confidence\": 7.19\\n}}\\n\\nExample 74:\\nQuestion: \"how can i add two projects..vs2008\"\\nCategory:\\n{{\\n  \"category\": \"visual-studio\",\\n  \"confidence\": 25.83\\n}}\\n\\nExample 75:\\nQuestion: \"Visual Studio Solutions / Multiple project : How to effectively propagate project properties amongst several projects\"\\nCategory:\\n{{\\n  \"category\": \"visual-studio\",\\n  \"confidence\": 74.06\\n}}\\n---\\n\\n===============================\\n\\nNew Question: Scala Regex Multiple Block Capturing\\n\\n===============================\\n\\nProvide your final classification in **valid JSON format** with the following structure:\\n{\\n  \"category\": \"your_chosen_category_name\",\\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\\n}\\n\\n\\nEnsure the JSON has:\\n- Opening and closing curly braces\\n- Double quotes around keys and string values\\n- Confidence as a number (not a string), with maximum 2 decimal places\\n\\nDo not include any explanations or extra text.\\n            '}],\n  'seed': 38,\n  'temperature': 0,\n  'extra_body': {'guided_json': {'properties': {'category': {'enum': ['bash',\n       'cocoa',\n       'drupal',\n       'excel',\n       'haskell',\n       'hibernate',\n       'linq',\n       'magento',\n       'matlab',\n       'oos',\n       'oracle',\n       'osx',\n       'qt',\n       'sharepoint',\n       'svn',\n       'visual-studio'],\n      'title': 'Category',\n      'type': 'string'},\n     'confidence': {'title': 'Confidence', 'type': 'number'}},\n    'required': ['category', 'confidence'],\n    'title': 'IntentSchema',\n    'type': 'object'}}}}"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"len(list_prompts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:02:47.444028Z","iopub.execute_input":"2025-07-08T05:02:47.444351Z","iopub.status.idle":"2025-07-08T05:02:47.449758Z","shell.execute_reply.started":"2025-07-08T05:02:47.444326Z","shell.execute_reply":"2025-07-08T05:02:47.448893Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"20000"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# sanity check min, max custom_id / row.Index for batch requests\nlist_custom_id = []\nfor req in list_prompts:\n    # print(req['custom_id'])  # Example: print custom_id of each request\n    list_custom_id.append(req['custom_id'])\nprint(f\"custom_id. min: {min(list_custom_id)}, max: {max(list_custom_id)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:02:52.044830Z","iopub.execute_input":"2025-07-08T05:02:52.045427Z","iopub.status.idle":"2025-07-08T05:02:52.058126Z","shell.execute_reply.started":"2025-07-08T05:02:52.045399Z","shell.execute_reply":"2025-07-08T05:02:52.056751Z"}},"outputs":[{"name":"stdout","text":"custom_id. min: 0, max: 19999\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Batch API call","metadata":{}},{"cell_type":"code","source":"# upload JSONL file of API requests\nbatch_requests = client.files.create(\n    file=open(batch_file_path, \"rb\"),\n    purpose=\"batch\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:03:00.603405Z","iopub.execute_input":"2025-07-08T05:03:00.603767Z","iopub.status.idle":"2025-07-08T05:03:10.748221Z","shell.execute_reply.started":"2025-07-08T05:03:00.603744Z","shell.execute_reply":"2025-07-08T05:03:10.747330Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"batch_requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:03:10.749646Z","iopub.execute_input":"2025-07-08T05:03:10.749961Z","iopub.status.idle":"2025-07-08T05:03:10.756341Z","shell.execute_reply.started":"2025-07-08T05:03:10.749934Z","shell.execute_reply":"2025-07-08T05:03:10.755179Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"FileObject(id='file-e552ddaf-08ad-4e69-89ab-ce8ef2427350', bytes=275300714, created_at=1751950990, filename='batch_prompts_stackoverflow_0_None.jsonl', object='file', purpose='batch', status=None, expires_at=None, status_details=None)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"batch_requests.__dict__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:03:18.182014Z","iopub.execute_input":"2025-07-08T05:03:18.182337Z","iopub.status.idle":"2025-07-08T05:03:18.188512Z","shell.execute_reply.started":"2025-07-08T05:03:18.182312Z","shell.execute_reply":"2025-07-08T05:03:18.187545Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'id': 'file-e552ddaf-08ad-4e69-89ab-ce8ef2427350',\n 'bytes': 275300714,\n 'created_at': 1751950990,\n 'filename': 'batch_prompts_stackoverflow_0_None.jsonl',\n 'object': 'file',\n 'purpose': 'batch',\n 'status': None,\n 'expires_at': None,\n 'status_details': None,\n '_request_id': None}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# submit batch requests to Nebius Qwen model\nclient.batches.create(\n    input_file_id=batch_requests.id,\n    endpoint=\"/v1/chat/completions\",\n    completion_window=\"24h\",\n    metadata={\n        \"description\": \"Banking77 - Qwen - BatchFull\"\n    }\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:03:20.483206Z","iopub.execute_input":"2025-07-08T05:03:20.483522Z","iopub.status.idle":"2025-07-08T05:03:20.632212Z","shell.execute_reply.started":"2025-07-08T05:03:20.483498Z","shell.execute_reply":"2025-07-08T05:03:20.631313Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Batch(id='batch_a7db8d91-9092-45ab-aada-c8027ea20d68', completion_window='24h', created_at=1751951000, endpoint='/v1/chat/completions', input_file_id='file-e552ddaf-08ad-4e69-89ab-ce8ef2427350', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Banking77 - Qwen - BatchFull'}, output_file_id=None, request_counts=BatchRequestCounts(completed=None, failed=None, total=None))"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# follow up on batch request status\nbatch_id = 'batch_a7db8d91-9092-45ab-aada-c8027ea20d68'\ncompleted_batch = client.batches.retrieve(batch_id)\ncompleted_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:06.765668Z","iopub.execute_input":"2025-07-08T05:13:06.765986Z","iopub.status.idle":"2025-07-08T05:13:07.053342Z","shell.execute_reply.started":"2025-07-08T05:13:06.765963Z","shell.execute_reply":"2025-07-08T05:13:07.052434Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Batch(id='batch_a7db8d91-9092-45ab-aada-c8027ea20d68', completion_window='24h', created_at=1751951000, endpoint='/v1/chat/completions', input_file_id='file-e552ddaf-08ad-4e69-89ab-ce8ef2427350', object='batch', status='done', cancelled_at=None, cancelling_at=None, completed_at=1751951344, error_file_id=None, errors=None, expired_at=None, expires_at=None, failed_at=None, finalizing_at=1751951339, in_progress_at=1751951018, metadata={'description': 'Banking77 - Qwen - BatchFull'}, output_file_id='a4e83330-f9be-4b6f-9548-665b12d7a33f', request_counts=BatchRequestCounts(completed=20000, failed=0, total=20000))"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"completed_batch.__dict__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:11.136963Z","iopub.execute_input":"2025-07-08T05:13:11.137317Z","iopub.status.idle":"2025-07-08T05:13:11.143632Z","shell.execute_reply.started":"2025-07-08T05:13:11.137291Z","shell.execute_reply":"2025-07-08T05:13:11.142772Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'id': 'batch_a7db8d91-9092-45ab-aada-c8027ea20d68',\n 'completion_window': '24h',\n 'created_at': 1751951000,\n 'endpoint': '/v1/chat/completions',\n 'input_file_id': 'file-e552ddaf-08ad-4e69-89ab-ce8ef2427350',\n 'object': 'batch',\n 'status': 'done',\n 'cancelled_at': None,\n 'cancelling_at': None,\n 'completed_at': 1751951344,\n 'error_file_id': None,\n 'errors': None,\n 'expired_at': None,\n 'expires_at': None,\n 'failed_at': None,\n 'finalizing_at': 1751951339,\n 'in_progress_at': 1751951018,\n 'metadata': {'description': 'Banking77 - Qwen - BatchFull'},\n 'output_file_id': 'a4e83330-f9be-4b6f-9548-665b12d7a33f',\n 'request_counts': BatchRequestCounts(completed=20000, failed=0, total=20000),\n '_request_id': None}"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# retrieve results using uploaded JSONL 'file id'\n\n# DO NOT RETRIEVE INPUT FILE from 'batch_requests.id'!\n# batch_result = client.files.content(batch_requests.id)\n\n# INSTEAD, PLEASE RETRIEVE file using 'output_file_id'!!!\nbatch_result = client.files.content('a4e83330-f9be-4b6f-9548-665b12d7a33f')\n# print 1st 1k characters\nprint(batch_result.text[:1000])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:23.819392Z","iopub.execute_input":"2025-07-08T05:13:23.819730Z","iopub.status.idle":"2025-07-08T05:13:25.068044Z","shell.execute_reply.started":"2025-07-08T05:13:23.819708Z","shell.execute_reply":"2025-07-08T05:13:25.067128Z"}},"outputs":[{"name":"stdout","text":"{\"id\": \"batch_req_f2e54888-46f1-4b56-895c-172a0aa092d0\", \"custom_id\": \"2425\", \"response\": {\"id\": \"chatcmpl-739d19f798b34947a446c81a15ca3c87\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"category\\\":\\\"oos\\\",\\\"confidence\\\":99.99}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": [], \"reasoning_content\": null}, \"stop_reason\": null}], \"created\": 1751951057, \"model\": \"Qwen/Qwen3-30B-A3B\", \"object\": \"chat.completion\", \"service_tier\": null, \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 15, \"prompt_tokens\": 3561, \"total_tokens\": 3576, \"completion_tokens_details\": null, \"prompt_tokens_details\": null}, \"prompt_logprobs\": null}, \"error\": null}\n{\"id\": \"batch_req_b4e8c7f8-5bca-4fea-98bd-06b0f859aef9\", \"custom_id\": \"2744\", \"response\": {\"id\": \"chatcmpl-f909003b61384a2fb422046ba7a3eab7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"category\\\": \\\"qt\\\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"type(batch_result.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:28.508160Z","iopub.execute_input":"2025-07-08T05:13:28.508555Z","iopub.status.idle":"2025-07-08T05:13:28.514502Z","shell.execute_reply.started":"2025-07-08T05:13:28.508524Z","shell.execute_reply":"2025-07-08T05:13:28.513685Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import json\n\n# from 1 string of ALL dictionary lines -> to list of 1 string per dictionary line\nlines = [line.strip() for line in batch_result.text.splitlines() if line.strip()]\n# from list of string 'dictionary lines' -> to list of dictionary objects\njson_objects = [json.loads(line) for line in lines]\n# sort LLM 'response' dictionaries based on row.Index (ie custom_id)\nsorted_objects = sorted(json_objects, \n                        key = lambda x: int(x[\"custom_id\"]))\n\n# 1st 5 dictionaries\nsorted_objects[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:34.549273Z","iopub.execute_input":"2025-07-08T05:13:34.550191Z","iopub.status.idle":"2025-07-08T05:13:35.088031Z","shell.execute_reply.started":"2025-07-08T05:13:34.550157Z","shell.execute_reply":"2025-07-08T05:13:35.087163Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[{'id': 'batch_req_57a0e922-7214-49e6-9408-bac7bc92a2df',\n  'custom_id': '0',\n  'response': {'id': 'chatcmpl-51a5a2554f944c9492c534f02943810b',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\":\"oos\",\"confidence\":99.99}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 15,\n    'prompt_tokens': 3557,\n    'total_tokens': 3572,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_33fa54e8-4059-4d85-8092-fffa0f99defe',\n  'custom_id': '1',\n  'response': {'id': 'chatcmpl-ddaea598332b498386a41bb033a8f727',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oracle\", \"confidence\": 75.05}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3559,\n    'total_tokens': 3576,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_31b1bdaa-e33a-44d3-828e-fe86daff7b01',\n  'custom_id': '2',\n  'response': {'id': 'chatcmpl-eaedb4dbf20847ee8a565e398224512f',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oos\", \"confidence\": 0.00}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3560,\n    'total_tokens': 3577,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_2226c803-f263-4f5d-83d8-b40de6d5602c',\n  'custom_id': '3',\n  'response': {'id': 'chatcmpl-bc54b9bde5dc48d4a18cd95adc15f685',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\":\"oos\",\"confidence\":99.99}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 15,\n    'prompt_tokens': 3557,\n    'total_tokens': 3572,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_0ee95da6-5ebe-47c6-a927-e6fc6082722e',\n  'custom_id': '4',\n  'response': {'id': 'chatcmpl-822c79beba98492b9c3c8143c91a1245',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oos\", \"confidence\": 0.00}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3554,\n    'total_tokens': 3571,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None}]"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Save to JSONL file\nwith open(f\"batch_outputs_{Config.dataset_name}_{Config.start_index}_{Config.end_index}.jsonl\", \"w\") as f:\n    for obj in sorted_objects:\n        f.write(json.dumps(obj) + \"\\n\")  # Write each JSON object as a single line","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:13:39.756934Z","iopub.execute_input":"2025-07-08T05:13:39.757288Z","iopub.status.idle":"2025-07-08T05:13:40.035999Z","shell.execute_reply.started":"2025-07-08T05:13:39.757264Z","shell.execute_reply":"2025-07-08T05:13:40.034784Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import json\nbatchfull = []\n\n# Load as a list of dictionaries\nwith open(f\"batch_outputs_{Config.dataset_name}_{Config.start_index}_{Config.end_index}.jsonl\", \"r\") as f:\n    # batchof10 = [json.loads(line) for line in f if line.strip()]\n    batchfull = [json.loads(line) for line in f]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:14:04.506313Z","iopub.execute_input":"2025-07-08T05:14:04.506649Z","iopub.status.idle":"2025-07-08T05:14:05.085541Z","shell.execute_reply.started":"2025-07-08T05:14:04.506590Z","shell.execute_reply":"2025-07-08T05:14:05.084282Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"batchfull[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:14:08.236761Z","iopub.execute_input":"2025-07-08T05:14:08.237059Z","iopub.status.idle":"2025-07-08T05:14:08.245470Z","shell.execute_reply.started":"2025-07-08T05:14:08.237038Z","shell.execute_reply":"2025-07-08T05:14:08.244795Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[{'id': 'batch_req_57a0e922-7214-49e6-9408-bac7bc92a2df',\n  'custom_id': '0',\n  'response': {'id': 'chatcmpl-51a5a2554f944c9492c534f02943810b',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\":\"oos\",\"confidence\":99.99}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 15,\n    'prompt_tokens': 3557,\n    'total_tokens': 3572,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_33fa54e8-4059-4d85-8092-fffa0f99defe',\n  'custom_id': '1',\n  'response': {'id': 'chatcmpl-ddaea598332b498386a41bb033a8f727',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oracle\", \"confidence\": 75.05}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3559,\n    'total_tokens': 3576,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_31b1bdaa-e33a-44d3-828e-fe86daff7b01',\n  'custom_id': '2',\n  'response': {'id': 'chatcmpl-eaedb4dbf20847ee8a565e398224512f',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oos\", \"confidence\": 0.00}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3560,\n    'total_tokens': 3577,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_2226c803-f263-4f5d-83d8-b40de6d5602c',\n  'custom_id': '3',\n  'response': {'id': 'chatcmpl-bc54b9bde5dc48d4a18cd95adc15f685',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\":\"oos\",\"confidence\":99.99}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 15,\n    'prompt_tokens': 3557,\n    'total_tokens': 3572,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None},\n {'id': 'batch_req_0ee95da6-5ebe-47c6-a927-e6fc6082722e',\n  'custom_id': '4',\n  'response': {'id': 'chatcmpl-822c79beba98492b9c3c8143c91a1245',\n   'choices': [{'finish_reason': 'stop',\n     'index': 0,\n     'logprobs': None,\n     'message': {'content': '{\"category\": \"oos\", \"confidence\": 0.00}',\n      'refusal': None,\n      'role': 'assistant',\n      'audio': None,\n      'function_call': None,\n      'tool_calls': [],\n      'reasoning_content': None},\n     'stop_reason': None}],\n   'created': 1751951019,\n   'model': 'Qwen/Qwen3-30B-A3B',\n   'object': 'chat.completion',\n   'service_tier': None,\n   'system_fingerprint': None,\n   'usage': {'completion_tokens': 17,\n    'prompt_tokens': 3554,\n    'total_tokens': 3571,\n    'completion_tokens_details': None,\n    'prompt_tokens_details': None},\n   'prompt_logprobs': None},\n  'error': None}]"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"type(batchfull[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:14:13.085061Z","iopub.execute_input":"2025-07-08T05:14:13.085430Z","iopub.status.idle":"2025-07-08T05:14:13.091785Z","shell.execute_reply.started":"2025-07-08T05:14:13.085407Z","shell.execute_reply":"2025-07-08T05:14:13.090904Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"dict"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"dict0 = batchfull[0]\ndict0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:14:14.339553Z","iopub.execute_input":"2025-07-08T05:14:14.339909Z","iopub.status.idle":"2025-07-08T05:14:14.346441Z","shell.execute_reply.started":"2025-07-08T05:14:14.339886Z","shell.execute_reply":"2025-07-08T05:14:14.345670Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'id': 'batch_req_57a0e922-7214-49e6-9408-bac7bc92a2df',\n 'custom_id': '0',\n 'response': {'id': 'chatcmpl-51a5a2554f944c9492c534f02943810b',\n  'choices': [{'finish_reason': 'stop',\n    'index': 0,\n    'logprobs': None,\n    'message': {'content': '{\"category\":\"oos\",\"confidence\":99.99}',\n     'refusal': None,\n     'role': 'assistant',\n     'audio': None,\n     'function_call': None,\n     'tool_calls': [],\n     'reasoning_content': None},\n    'stop_reason': None}],\n  'created': 1751951019,\n  'model': 'Qwen/Qwen3-30B-A3B',\n  'object': 'chat.completion',\n  'service_tier': None,\n  'system_fingerprint': None,\n  'usage': {'completion_tokens': 15,\n   'prompt_tokens': 3557,\n   'total_tokens': 3572,\n   'completion_tokens_details': None,\n   'prompt_tokens_details': None},\n  'prompt_logprobs': None},\n 'error': None}"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"dict0response = json.loads(dict0[\"response\"][\"choices\"][0][\"message\"][\"content\"])\ndict0response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T05:14:15.561684Z","iopub.execute_input":"2025-07-08T05:14:15.561964Z","iopub.status.idle":"2025-07-08T05:14:15.568064Z","shell.execute_reply.started":"2025-07-08T05:14:15.561944Z","shell.execute_reply":"2025-07-08T05:14:15.567203Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'category': 'oos', 'confidence': 99.99}"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"## Individual API Call Workings","metadata":{}},{"cell_type":"code","source":"\n#######################\n# Model on 1 Dataset\n#######################\n# Save a list of dictionaries \n# containing a dictionary for each record's\n# - predicted category\n# - confidence level and\n# - original dataframe values\n\n\n# gemini\nuser_secrets = UserSecretsClient()\nNEBIUS_API_KEY = user_secrets.get_secret(\"NEBIUS_API_KEY\")\nclient = OpenAI(base_url=\"https://api.studio.nebius.com/v1/\",\n                api_key = NEBIUS_API_KEY)\n\n@retry(stop=stop_after_attempt(3), wait=wait_fixed(30))\ndef api_llm(client, prompt):\n    try:\n        print(\"CHECKPOINT_3A\")\n        # gemini_config = {\"temperature\": 0,\n        #                  \"response_mime_type\": \"application/json\",\n        #                  \"response_schema\": IntentSchema.model_json_schema(),\n        #                  \"seed\": 38,\n        #                  # # added for \"gemini-2.5-flash-lite-preview-06-17\" model\n        #                  # \"thinking_config\": ThinkingConfig(thinking_budget=-1, \n        #                  #                    include_thoughts=True)\n        #                 }\n        response = client.beta.chat.completions.parse(model = 'Qwen/'+Config.model_name,\n                                                      messages = [{\"role\": \"user\",\n                                                                  \"content\": prompt}],\n                                                      response_format = IntentSchema,\n                                                      seed = 38,\n                                                      temperature = 0\n                                                      )\n        # print(response)\n        # msg = response.parsed\n        response = response.choices[0].message.content\n        print(\"CHECKPOINT_3B\")\n        return response\n    except:\n        print(f\"CHECKPOINT_4A: Exception Type: {type(e).__name__}\")\n        print(f\"CHECKPOINT_4A: Exception Message: {str(e)}\")\n        \n        # Gemini-specific errors\n        if hasattr(e, 'code'):\n            print(f\"CHECKPOINT_4A: Status Code: {e.code}\")\n        if hasattr(e, 'details'):\n            print(f\"CHECKPOINT_4A: Details: {e.details}\")\n        \n        # raise the exception again so retry can work\n        raise\n\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T02:28:29.290722Z","iopub.execute_input":"2025-07-08T02:28:29.291061Z","iopub.status.idle":"2025-07-08T02:28:29.790215Z","shell.execute_reply.started":"2025-07-08T02:28:29.291036Z","shell.execute_reply":"2025-07-08T02:28:29.789327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from src.config import Config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:05:41.973871Z","iopub.execute_input":"2025-07-07T13:05:41.974414Z","iopub.status.idle":"2025-07-07T13:05:41.979297Z","shell.execute_reply.started":"2025-07-07T13:05:41.974379Z","shell.execute_reply":"2025-07-07T13:05:41.978387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Config.end_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:16:52.889806Z","iopub.execute_input":"2025-07-07T14:16:52.890098Z","iopub.status.idle":"2025-07-07T14:16:52.895479Z","shell.execute_reply.started":"2025-07-07T14:16:52.890077Z","shell.execute_reply":"2025-07-07T14:16:52.894686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = Config.model_name\ndf = df\ncategories = bulletpts_intent\nstart_index = Config.start_index\nend_index = Config.end_index\nlog_every_n_examples = Config.log_every_n_examples\n\n\n\nstart_time = time.time()\nresults = []  # Store processed results\n\n# Slice DataFrame based on start/end indices\nif end_index is None:\n    subset_df = df.iloc[start_index:]\nelse:\n    subset_df = df.iloc[start_index:end_index+1]\n\ntotal_rows = len(subset_df)\nsubset_row_count = 0\n\n\n\n\n\nfor row in subset_df.itertuples():\n    subset_row_count+=1\n    prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n    if subset_row_count == 1:\n        print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n        # print(prompt)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T02:28:37.79143Z","iopub.execute_input":"2025-07-08T02:28:37.791717Z","iopub.status.idle":"2025-07-08T02:28:37.800178Z","shell.execute_reply.started":"2025-07-08T02:28:37.791699Z","shell.execute_reply":"2025-07-08T02:28:37.799149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = api_llm(client, prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T08:25:07.625516Z","iopub.execute_input":"2025-07-07T08:25:07.626404Z","iopub.status.idle":"2025-07-07T08:25:47.225781Z","shell.execute_reply.started":"2025-07-07T08:25:07.626373Z","shell.execute_reply":"2025-07-07T08:25:47.224544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = client.beta.chat.completions.parse(model = 'Qwen/'+Config.model_name,\n                                              messages = [{\"role\": \"user\",\n                                                          \"content\": prompt}],\n                                              response_format = IntentSchema,\n                                              seed = 38,\n                                              temperature = 0\n                                              )\nresponse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:08:54.89788Z","iopub.execute_input":"2025-07-07T14:08:54.898163Z","iopub.status.idle":"2025-07-07T14:08:57.314335Z","shell.execute_reply.started":"2025-07-07T14:08:54.898142Z","shell.execute_reply":"2025-07-07T14:08:57.313648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response2 = client.chat.completions.create(model = 'Qwen/'+Config.model_name,\n                                              messages = [{\"role\": \"user\",\n                                                          \"content\": prompt}],\n                                              seed = 38,\n                                              temperature = 0,\n                                              extra_body = {\"guided_json\": IntentSchema.model_json_schema()}\n                                              )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:53:02.503392Z","iopub.execute_input":"2025-07-07T14:53:02.504454Z","iopub.status.idle":"2025-07-07T14:53:04.505864Z","shell.execute_reply.started":"2025-07-07T14:53:02.504416Z","shell.execute_reply":"2025-07-07T14:53:04.504866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# response2\n# ChatCompletion(id='chatcmpl-f6f492a52fc447d198ee34318e5c1801', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"category\":\"oos\",\"confidence\":0.00}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1751899983, model='Qwen/Qwen3-30B-A3B', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=14, prompt_tokens=14012, total_tokens=14026, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)\n\n# response2.choices[0].message.content\n# '{\"category\":\"oos\",\"confidence\":0.00}'\n\n# json.loads(response2.choices[0].message.content)\n# {'category': 'oos', 'confidence': 0.0}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:54:04.527542Z","iopub.execute_input":"2025-07-07T14:54:04.527857Z","iopub.status.idle":"2025-07-07T14:54:04.533676Z","shell.execute_reply.started":"2025-07-07T14:54:04.527797Z","shell.execute_reply":"2025-07-07T14:54:04.532858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IntentSchema","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:48:56.886024Z","iopub.execute_input":"2025-07-07T14:48:56.88638Z","iopub.status.idle":"2025-07-07T14:48:56.892198Z","shell.execute_reply.started":"2025-07-07T14:48:56.886357Z","shell.execute_reply":"2025-07-07T14:48:56.891313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IntentSchema.model_json_schema()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:49:20.016628Z","iopub.execute_input":"2025-07-07T14:49:20.017021Z","iopub.status.idle":"2025-07-07T14:49:20.030741Z","shell.execute_reply.started":"2025-07-07T14:49:20.016992Z","shell.execute_reply":"2025-07-07T14:49:20.029796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# response.__dict__\n\"\"\"\n{'id': 'chatcmpl-20151be35483463a9136d12957c6e0ec',\n 'choices': [ParsedChoice[IntentSchema](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[IntentSchema](content='{\"category\":\"oos\",\"confidence\":0.00}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=IntentSchema(category='oos', confidence=0.0), reasoning_content=None), stop_reason=None)],\n 'created': 1751897335,\n 'model': 'Qwen/Qwen3-30B-A3B',\n 'object': 'chat.completion',\n 'service_tier': None,\n 'system_fingerprint': None,\n 'usage': CompletionUsage(completion_tokens=14, prompt_tokens=14012, total_tokens=14026, completion_tokens_details=None, prompt_tokens_details=None),\n '_request_id': None}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:09:15.334007Z","iopub.execute_input":"2025-07-07T14:09:15.334843Z","iopub.status.idle":"2025-07-07T14:09:15.339838Z","shell.execute_reply.started":"2025-07-07T14:09:15.334817Z","shell.execute_reply":"2025-07-07T14:09:15.339067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# response.choices\n# [ParsedChoice[IntentSchema](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[IntentSchema](content='{\"category\":\"oos\",\"confidence\":0.00}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=IntentSchema(category='oos', confidence=0.0), reasoning_content=None), stop_reason=None)]\n\n# response.choices[0]\n# ParsedChoice[IntentSchema](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[IntentSchema](content='{\"category\":\"oos\",\"confidence\":0.00}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=IntentSchema(category='oos', confidence=0.0), reasoning_content=None), stop_reason=None)\n\n# response.choices[0].__dict__\n# \"\"\"\n# {'finish_reason': 'stop',\n#  'index': 0,\n#  'logprobs': None,\n#  'message': ParsedChatCompletionMessage[IntentSchema](content='{\"category\":\"oos\",\"confidence\":0.00}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=IntentSchema(category='oos', confidence=0.0), reasoning_content=None)}\n# \"\"\"\n\n# response.choices[0].message.content\n# '{\"category\":\"oos\",\"confidence\":0.00}'\n\n# type(response.choices[0].message.content)\n# str\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:10:02.430919Z","iopub.execute_input":"2025-07-07T14:10:02.431216Z","iopub.status.idle":"2025-07-07T14:10:02.436803Z","shell.execute_reply.started":"2025-07-07T14:10:02.431188Z","shell.execute_reply":"2025-07-07T14:10:02.435646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef predict_intent(model_name, df, categories, start_index=0, end_index=None, log_every_n_examples=100):\n    start_time = time.time()\n    results = []  # Store processed results\n    \n    # Slice DataFrame based on start/end indices\n    if end_index is None:\n        subset_df = df.iloc[start_index:]\n    else:\n        subset_df = df.iloc[start_index:end_index+1]\n    \n    total_rows = len(subset_df)\n    subset_row_count = 0\n\n    \n\n    \n    \n    for row in subset_df.itertuples():\n        subset_row_count+=1\n        prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n        if subset_row_count == 1:\n            print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n            print(prompt)\n\n            print(\"Example of how IntentSchema looks\")\n            print(IntentSchema.model_json_schema())\n        \n        \n        try:\n            print(\"CHECKPOINT_1A\")\n            \n            # response = ollama.chat(model=model_name, \n            #                        messages=[\n            #                                     {'role': 'user', 'content': prompt}\n            #                                 ],\n            #                        format = IntentSchema.model_json_schema(),\n            #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n            #                       )\n            # msg = response['message']['content']\n            # parsed = json.loads(msg)\n            \n            response = api_llm(_client, prompt)\n            print(\"CHECKPOINT_1B\")\n            parsed = json.loads(response.text)\n            # parsed = response.parsed\n            print(\"CHECKPOINT_1C\")\n                        \n            # Safely extract keys with defaults - resolve parsing error\n            # maybe LLM did not output a particular key-value pair\n            category = parsed.get('category', 'error')\n            confidence = parsed.get('confidence', 0.0)\n            parsed = {'category': category, 'confidence': confidence}\n        except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(f\"CHECKPOINT_2A: Exception Type: {type(e).__name__}\")\n            print(f\"CHECKPOINT_2A: Exception Message: {str(e)}\")\n            \n            # Gemini-specific errors\n            if hasattr(e, 'code'):\n                print(f\"CHECKPOINT_2A: Status Code: {e.code}\")\n            if hasattr(e, 'details'):\n                print(f\"CHECKPOINT_2A: Details: {e.details}\")\n                \n            parsed = {'category': 'error', 'confidence': 0.0}\n        \n        # Combine original row data with predictions\n        results.append({\n            \"Index\": row.Index,\n            \"text\": row.text,\n            \"label\": row.label,\n            \"dataset\": row.dataset,\n            \"split\": row.split,\n            \"predicted\": parsed['category'],\n            \"confidence\": parsed['confidence']\n        })\n\n        \n        # Log progress\n        if subset_row_count % log_every_n_examples == 0:\n            elapsed_time = time.time() - start_time\n            \n            avg_time_per_row = elapsed_time / subset_row_count\n            remaining_rows = total_rows - subset_row_count\n            eta = avg_time_per_row * remaining_rows\n            \n            print(f\"Processed original df idx {row.Index} (subset row {subset_row_count}) | \"\n                  f\"Elapsed: {elapsed_time:.2f}s | ETA: {eta:.2f}s\")\n    \n    return results  # Return list of dictionaries\n    \n\nprint(f\"Starting intent classification using {Config.model_name}\")\nsubset_results = predict_intent(Config.model_name, \n                                df, \n                                bulletpts_intent, \n                                start_index = Config.start_index, \n                                end_index = Config.end_index,\n                                log_every_n_examples = Config.log_every_n_examples)\n\n\n\n# # previously for Ollama\n# # update end_index for filename (if None is used for the end of the df)\n# # Get the last index of the DataFrame\n# last_index = df.index[-1] \n# # Use last index if Config.end_index is None\n# end_index = Config.end_index if Config.end_index is not None else last_index\n# 2025.07.07\n# now for Ollama AND Gemini\n# Gemini - needs to track 'end_index' for API JSON exports (when daily limits are exhausted)\n# Ollama - reuse this code\nend_index = max(r['Index'] for r in subset_results)\n\n\n\n# 2025.05.23 changed from JSON to PKL\n# because we are saving list of dictionaries\n# Save to PKL\n# 2025.06.04 explore changing back to JSON\n# with open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.pkl', 'wb') as f:\n#     pickle.dump(subset_results, f)\nwith open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.json', 'w') as f:\n    json.dump(subset_results, f, indent=2)\n\nprint(\"Completed intent classification\")\n\n\n#######################\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
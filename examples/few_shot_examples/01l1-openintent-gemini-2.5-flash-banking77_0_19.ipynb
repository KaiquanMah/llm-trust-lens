{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Refactored code for\n* Setting up and running Ollama in Kaggle\n* Downloading THUIAR dataset\n* Zero-Shot Prompt\n* Use LLM to classify intent from an input 'question' dataset\n* To configure your file/folder paths, LLM, dataset, start_index and end_index for each run, please update the config.py file\n\nThis notebook will also be used as the base to test any fixes to the LLM intent classification pipeline.\n* 2025.05.26: Updated results output file from JSON to Pickle, to store list of dictionaries. 1 dictionary contains the results for each record. Lists of dictionaries can be downloaded from multiple notebooks, then concatenated for analysis\n* 2025.05.30: Update prompt and bulletpts_intent.\n  * Check if dataset contains 'oos' (out of scope) category\n  * If dataset has no 'oos' (out of scope) category, turn 1 category into 'oos'. Use updated categories in bulletpts_intent. Also update prompt instructions on when to classify an example as 'oos'\n  * **This force_oos fix is implemented in [notebook 01E](https://www.kaggle.com/code/kaiquanmah/01e-kaggle-ollama-llama3-2-w-force-oos?scriptVersionId=242648764)**\n* 2025.05.30: Add pydantic schema with enums\n  * From an analysis of errors, the model previously had a 45% average accuracy rate across categories. The model predicted a set of categories outside of what we gave it in 'bulletpts_intent'\n  * To fix this, we will try to implement a pydantic schema solution for the model to only predict categories from the allowed list of categories ('bulletpts_intent')\n* 2025.05.30: Set Ollama chat temperature to 0\n  * Previously, we used the default temperature of 0.8, which might have caused the model to predict categories we did not provide to it ([Reading](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html))\n  * **The pydantic schema and temperature fixes are implemented in [notebook 01F](https://www.kaggle.com/code/kaiquanmah/01f-kaggle-ollama-llama3-2-w-pydantic-schema)**\n* 2025.06.03:\n  1. **Remove 'oos' from `bulletpts_intent` input into prompt**, to be consistent with the team's approach when exploring embedding approaches to classify 'oos' examples. **Keep 'oos' in pydantic enums/Literal (for LLM to output 'oos' as an allowed class value)**\n  2. **Remove 0.99 when defining the prompt format - to avoid anchoring LLM on outputting confidence of 0.99**\n  3. **Added ability for user to define which classes are 'oos'**\n  * **These 3 fixes are in [notebook 01G](https://www.kaggle.com/code/kaiquanmah/01g-kaggle-ollama-llama3-2-oos-update)**\n* 2025.06.10:\n  * From an error analysis earlier, **models can get confused between similar intent classes**\n  * Therefore **we will analyse similar intent classes/labels -> get their indexes -> put them into 'oos' in [notebook 01H](https://www.kaggle.com/code/kaiquanmah/01h1-openintent-ollama-llama3-2-3b-banking77)**\n  * **Going from zero-shot prompt previously, to few-shot prompt (with 5 examples) from known intents**. These 5 examples were **non-oos, and misclassified previously**. This 'fix' is in **[notebook 01i](https://www.kaggle.com/code/kaiquanmah/01i1-openintent-ollama-llama3-2-3b-banking77)**\n* 2025.06.16:\n  * For known intents (ie not in the 'oos' class), give 5 examples each in the few-shot prompt **[notebook 01J](https://www.kaggle.com/code/kaiquanmah/01j1-openintent-ollama-llama3-2-3b-banking77)**\n* 2025.06.17:\n  * Now we explore how changing the number of known intent classes affects the recall of oos in **[notebook 01K](https://www.kaggle.com/code/kaiquanmah/01k1-openintent-ollama-llama3-2-3b-banking77)**\n  * For quick experimentation, we implement (1) fewshot prompt with 1 example per known intent class, (2) changing number of known intent classes in various notebook runs, (3) 100 oos sentences for the model to classify (taking from first class for banking77 and stackoverflow dataset, or the oos class for CLINC150 oos dataset)\n    * For (3) - Added 'first_class' variable for each dataset to Config\n    * For (3) - Created new fn to filter and keep 100 records from 'first/oos class' to input to the model to classify\n* 2025.07.07:\n  * Explore free, rate-limited API model (such as Gemini) in **[notebook 01L](https://www.kaggle.com/code/kaiquanmah/01l1-openintent-gemini-banking77-explore)**\n  * Added retry for when we exhaust API limits per minute\n  * Updated end_index tracking that works with Ollama and Gemini when generating JSON results file","metadata":{}},{"cell_type":"code","source":"# 1. create dirs if they do not exist\nimport os\nos.makedirs('/kaggle/working/src', exist_ok=True)\nos.makedirs('/kaggle/working/prediction', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T02:36:37.270547Z","iopub.execute_input":"2025-07-07T02:36:37.270878Z","iopub.status.idle":"2025-07-07T02:36:37.280319Z","shell.execute_reply.started":"2025-07-07T02:36:37.270849Z","shell.execute_reply":"2025-07-07T02:36:37.279142Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%writefile /kaggle/working/src/setup_ollama.py\nimport os\nimport subprocess\nimport time\nfrom src.config import Config # absolute import\n\n# 1. Install Ollama (if not already installed)\ntry:\n    # Check if Ollama is already installed\n    subprocess.run([\"ollama\", \"--version\"], capture_output=True, check=True)\n    print(\"Ollama is already installed.\")\nexcept FileNotFoundError:\n    print(\"Installing Ollama...\")\n    subprocess.run(\"curl -fsSL https://ollama.com/install.sh  | sh\", shell=True, check=True)\n\n# 2. Start Ollama server in the background\nprint(\"Starting Ollama server...\")\nprocess = subprocess.Popen(\"ollama serve\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# Wait for the server to initialize\ntime.sleep(5)\n\n\n# 3. Pull the model\nmodel_name = Config.model_name\nprint(f\"Pulling {model_name} model...\")\nsubprocess.run([\"ollama\", \"pull\", model_name], check=True)\n\n# 4. Install Python client\nsubprocess.run([\"pip\", \"install\", \"ollama\"], check=True)\n\nprint(\"Ollama setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T02:36:38.877929Z","iopub.execute_input":"2025-07-07T02:36:38.878351Z","iopub.status.idle":"2025-07-07T02:36:38.885972Z","shell.execute_reply.started":"2025-07-07T02:36:38.878323Z","shell.execute_reply":"2025-07-07T02:36:38.884953Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/setup_ollama.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile requirements.txt\npandas\npydantic\ntyping\nhuggingface-hub\ngoogle-genai # only used for gemini model\ntenacity # for gemini model retries\n# numpy\n# enum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T02:36:41.205340Z","iopub.execute_input":"2025-07-07T02:36:41.205889Z","iopub.status.idle":"2025-07-07T02:36:41.213557Z","shell.execute_reply.started":"2025-07-07T02:36:41.205847Z","shell.execute_reply":"2025-07-07T02:36:41.212359Z"}},"outputs":[{"name":"stdout","text":"Writing requirements.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile /kaggle/working/src/__init__.py\n# folder for config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T02:36:43.069063Z","iopub.execute_input":"2025-07-07T02:36:43.069418Z","iopub.status.idle":"2025-07-07T02:36:43.076095Z","shell.execute_reply.started":"2025-07-07T02:36:43.069394Z","shell.execute_reply":"2025-07-07T02:36:43.074893Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/src/__init__.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile /kaggle/working/src/config.py\nclass Config:\n    #######################################################\n    # working directory for files\n    #######################################################\n    target_dir = '/kaggle/working/data' # data directory to clone into\n    cloned_data_dir = target_dir + '/data'\n    prediction_dir = target_dir + '/prediction'\n    #######################################################\n    # dataset and model\n    #######################################################\n    dataset_name = 'banking' # UPDATE options: 'banking', 'stackoverflow', 'oos'\n    idx2label_target_dir = '/kaggle/working/idx2label'\n    idx2label_filename_hf = 'banking77_idx2label.csv' # UPDATE options: banking77_idx2label.csv, stackoverflow_idx2label.csv, clinc150_oos_idx2label.csv\n    fewshot_examples_dir = '/kaggle/working/fewshot'\n    fewshot_subdir = '/fewshot-5examples-per-nonoos/'\n    fewshot_examples_filename = 'banking_25perc_oos.txt' # UPDATE options: banking_25perc_oos.txt, stackoverflow_25perc_oos.txt, oos_25perc_oos.txt\n    list_oos_idx = [2, 10, 14, 15, 16, 17, 19, 25, 31, 32, 33, 34, 36, 52, 53, 54, 57, 73, 76] # UPDATE gathered from within the team - for reproducible, comparable results with other open intent classification approaches\n    model_name = 'gemini-2.5-flash-preview-05-20'\n    start_index=0 # eg: 0, 10001, 11851\n    end_index=19 # eg: 10, 10000, 11850 or None (use end_index=None to process the full dataset)\n    log_every_n_examples=2 # 2\n    force_oos = True  # NEW: Add flag to force dataset to contain 'oos' class for the last class value (sorted alphabetically), if 'oos' class does not exist in the original dataset\n    #######################################################\n    # evaluate threshold when 'oos' recall drops\n    #######################################################\n    filter_oos_qns_only = False # True (when you are testing 'oos' recall threshold), False\n    n_oos_qns = 100\n    first_class_banking = 'activate_my_card' # following idx2label\n    first_class_stackoverflow = 'wordpress' # following idx2label\n    first_class_oos = 'oos'\n    #######################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:40:01.866711Z","iopub.execute_input":"2025-07-07T04:40:01.867086Z","iopub.status.idle":"2025-07-07T04:40:01.874874Z","shell.execute_reply.started":"2025-07-07T04:40:01.867055Z","shell.execute_reply":"2025-07-07T04:40:01.873853Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/src/config.py\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"%%writefile download_dataset.py\nfrom src.config import Config\nimport os\nimport subprocess\ntarget_dir = Config.target_dir # data directory to clone into\ncloned_data_dir = Config.cloned_data_dir\n\n# Create target directory if it doesn't exist\nos.makedirs(target_dir, exist_ok=True)\n\n# do not clone dataset repo if cloned data folder exists\nif os.path.exists(cloned_data_dir):\n    print(\"Dataset has already been downloaded. If this is incorrect, please delete the Adaptive-Decision-Boundary 'data' folder.\")\nelse:\n    # Clone the repository\n    subprocess.run([\"git\",\n                    \"clone\",\n                    \"https://github.com/thuiar/Adaptive-Decision-Boundary.git\",\n                    target_dir\n                   ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T02:36:47.669589Z","iopub.execute_input":"2025-07-07T02:36:47.670014Z","iopub.status.idle":"2025-07-07T02:36:47.677138Z","shell.execute_reply.started":"2025-07-07T02:36:47.669981Z","shell.execute_reply":"2025-07-07T02:36:47.676043Z"}},"outputs":[{"name":"stdout","text":"Writing download_dataset.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile predict_class.py\nfrom src.config import Config\nimport pandas as pd\nimport os\n# import ollama\nimport json\nimport pickle\nimport time\nfrom pydantic import BaseModel\nfrom typing import Literal\n# from enum import Enum\nfrom huggingface_hub import snapshot_download\n    \n###################\n# Gemini API\n###################\nfrom google import genai\n# from google.api_core import retry\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nfrom kaggle_secrets import UserSecretsClient\n\n# # allow retries\n# is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n# genai.models.Models.generate_content = retry.Retry(\n#     predicate=is_retriable)(genai.models.Models.generate_content)\n###################\n\n\n# Config.target_dir\n# Config.cloned_data_dir'\n# Config.dataset_name\n# Config.model_name\n# Config.start_index\n# Config.end_index\n# Config.log_every_n_examples\n\n\n#######################\n# load data\n#######################\ndef load_data(data_dir):\n    \"\"\"Loads train, dev, and test datasets from a specified directory.\"\"\"\n\n    main_df = pd.DataFrame()\n    for split in ['train', 'dev', 'test']:\n        file_path = os.path.join(data_dir, f'{split}.tsv')\n        if os.path.exists(file_path):\n          try:\n            df = pd.read_csv(file_path, sep='\\t')\n            df['dataset'] = os.path.basename(data_dir)\n            df['split'] = split\n            main_df = pd.concat([main_df, df], ignore_index=True)\n          except pd.errors.ParserError as e:\n            print(f\"Error parsing {file_path}: {e}\")\n            # Handle the error appropriately, e.g., skip the file, log the error, etc.\n        else:\n            print(f\"Warning: {split}.tsv not found in {data_dir}\")\n    return main_df\n\n\ndef filter100examples_oos(dataset_name, df):\n    # dont input 'only oos qns to model'\n    if Config.filter_oos_qns_only == False:\n        filtered_df = df\n    # vs\n    # input 'only oos qns to model'\n    else:\n        if dataset_name == 'banking':\n            first_class = Config.first_class_banking\n        elif dataset_name == 'stackoverflow':\n            first_class = Config.first_class_stackoverflow\n        else:\n            first_class = Config.first_class_oos\n    \n        filtered_df = df.copy()\n        filtered_df = filtered_df.loc[filtered_df[\"label\"] == first_class]\n        filtered_df = filtered_df.sample(n=Config.n_oos_qns, random_state=38)\n    return filtered_df\n\n\ndf = pd.DataFrame()\n\ndata_dir = os.path.join(Config.cloned_data_dir, Config.dataset_name)\nif os.path.exists(data_dir):\n  df = load_data(data_dir)\n  print(f\"Loaded dataset into dataframe: {Config.dataset_name}\")\n  print(f\"Dimensions: {df.shape}\")\n  print(f\"Col names: {df.columns}\")\nelse:\n  print(f\"Warning: Directory {data_dir} not found.\")\n#######################\n\n\n\n#######################\n# unique intents\n#######################\nsorted_intent = list(sorted(df.label.unique()))\nprint(\"=\"*80)\nprint(f\"Original dataset intents: {sorted_intent}\")\nprint(f\"Number of original intents: {len(sorted_intent)}\\n\")\n\n\n# 2025.06.03\n# New OOS approach - get 25/50/75% of class indexes for each dataset within the team (for reproducibility and comparable results)\n# Change their class labels to 'oos'\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir=Config.idx2label_target_dir)\nidx2label_filepath = Config.idx2label_target_dir + '/dataset_idx2label/' + Config.idx2label_filename_hf\nidx2label = pd.read_csv(idx2label_filepath)\nidx2label_oos = idx2label[idx2label.index.isin(Config.list_oos_idx)]\nidx2label_oos.reset_index(drop=True, inplace=True)\n\n# 2025.06.17 keep track of non-oos labels, to use in IntentSchema\nnonoos_labels = idx2label[~idx2label.label.isin(Config.list_oos_idx)]['label'].values\nprint(\"=\"*80)\nprint(\"Original intents to convert to OOS class\")\nprint(idx2label_oos)\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\\n\")\n\noos_labels = idx2label_oos['label'].values\nlist_sorted_intent_aft_conversion = ['oos' if intent.lower() in oos_labels else intent for intent in sorted_intent]\nlist_sorted_intent_aft_conversion_deduped = sorted(set(list_sorted_intent_aft_conversion))\nprint(\"=\"*80)\nprint(\"Unique intents after converting some to OOS class\")\nprint(list_sorted_intent_aft_conversion_deduped)\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\\n\")\n\n\n\n# unique intents - from set to bullet points (to use in prompts)\n# bulletpts_intent = \"\\n\".join(f\"- {category}\" for category in set_intent)\n# 2025.06.03: do not show 'oos' in the prompt (to avoid leakage of 'oos' class)\nbulletpts_intent = \"\\n\".join(f\"- {category}\" for category in list_sorted_intent_aft_conversion_deduped if category and (category!='oos'))\n\n# 2025.06.04: fix adjustment if 'oos' is already in the original dataset\nint_oos_in_orig_dataset = int('oos' in idx2label.label.values)\nadjust_if_oos_not_in_orig_dataset = [0 if int_oos_in_orig_dataset == 1 else 1][0]\n\nprint(\"=\"*80)\nprint(\"sanity check\")\nprint(f\"Number of original intents: {len(sorted_intent)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset): {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset}\")\nprint(f\"Number of original intents to convert to OOS class: {len(idx2label_oos)}\")\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\")\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)}\")\nprint(f\"Numbers match: {(len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)) == len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(\"Prepared unique intents\")\n#######################\n\n\n\n\n#######################\n# Enforce schema on the model (e.g. allowed list of predicted categories)\n#######################\n\nclass IntentSchema(BaseModel):\n    # dynamically unpack list of categories for different dataset(s)\n    category: Literal[*list_sorted_intent_aft_conversion_deduped]\n    confidence: float\n    \n#######################\n\n\n\n\n#######################\n# filter after preparing intents\n#######################\ndf = filter100examples_oos(Config.dataset_name, df)\nprint(\"Filtered dataset\")\nprint(f\"Dimensions: {df.shape}\")\nprint(f\"Col names: {df.columns}\")\n#######################\n\n\n\n#######################\n# Prompt\n#######################\n# prompt 2 with less information/compute, improve efficiency\n# 2025.06.10 prompt 3 with 5 few shot examples only - notebook O1H1, O1i1\n# 2025.06.16 prompt 4 with 5 examples per each known intent (ie non-oos intent) - notebook 01J1\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*.txt\", local_dir=Config.fewshot_examples_dir)\nwith open(Config.fewshot_examples_dir + Config.fewshot_subdir + Config.fewshot_examples_filename, 'r') as file:\n    fewshot_examples = file.read()\n\ndef get_prompt(dataset_name, split, question, categories, fewshot_examples):\n    \n    prompt = f'''\nYou are an expert in understanding and identifying what users are asking you.\n\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\n{categories}\n\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\n\nBelow are several examples to guide your classification:\n\n---\n{fewshot_examples}\n---\n\n===============================\n\nNew Question: {question}\n\n===============================\n\nProvide your final classification in **valid JSON format** with the following structure:\n{{\n  \"category\": \"your_chosen_category_name\",\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\n}}\n\n\nEnsure the JSON has:\n- Opening and closing curly braces\n- Double quotes around keys and string values\n- Confidence as a number (not a string), with maximum 2 decimal places\n\nDo not include any explanations or extra text.\n            '''\n    return prompt\n\n\n\n#######################\n\n\n#######################\n# Model on 1 Dataset\n#######################\n# Save a list of dictionaries \n# containing a dictionary for each record's\n# - predicted category\n# - confidence level and\n# - original dataframe values\n\n\n# gemini\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\ngemini_client = genai.Client(api_key = GOOGLE_API_KEY)\n\n@retry(stop=stop_after_attempt(3), wait=wait_fixed(30))\ndef gemini_llm(gemini_client, prompt):\n    gemini_config = {\"temperature\": 0,\n                     \"response_mime_type\": \"application/json\",\n                     \"response_schema\": IntentSchema.model_json_schema()}\n    response = gemini_client.models.generate_content(model = Config.model_name,\n                                   contents = prompt,\n                                   config = gemini_config \n                                  )    \n    # print(response)\n    # msg = response.parsed\n    return response\n    \n\ndef predict_intent(model_name, df, categories, start_index=0, end_index=None, log_every_n_examples=100):\n    start_time = time.time()\n    results = []  # Store processed results\n    \n    # Slice DataFrame based on start/end indices\n    if end_index is None:\n        subset_df = df.iloc[start_index:]\n    else:\n        subset_df = df.iloc[start_index:end_index+1]\n    \n    total_rows = len(subset_df)\n    subset_row_count = 0\n\n    \n\n    \n    \n    for row in subset_df.itertuples():\n        subset_row_count+=1\n        prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n        if subset_row_count == 1:\n            print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n            print(prompt)\n\n            print(\"Example of how IntentSchema looks\")\n            print(IntentSchema.model_json_schema())\n        \n        \n        try:\n            print(\"EXIT_1A\")\n            \n            # response = ollama.chat(model=model_name, \n            #                        messages=[\n            #                                     {'role': 'user', 'content': prompt}\n            #                                 ],\n            #                        format = IntentSchema.model_json_schema(),\n            #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n            #                       )\n            # msg = response['message']['content']\n            # parsed = json.loads(msg)\n            \n            response = gemini_llm(gemini_client, prompt)\n            print(\"EXIT_1b\")\n            # parsed = json.loads(response.text)\n            parsed = response.parsed\n            print(\"EXIT_1c\")\n                        \n            # Safely extract keys with defaults - resolve parsing error\n            # maybe LLM did not output a particular key-value pair\n            category = parsed.get('category', 'error')\n            confidence = parsed.get('confidence', 0.0)\n            parsed = {'category': category, 'confidence': confidence}\n        except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(\"EXIT_2A\")\n            parsed = {'category': 'error', 'confidence': 0.0}\n        \n        # Combine original row data with predictions\n        results.append({\n            \"Index\": row.Index,\n            \"text\": row.text,\n            \"label\": row.label,\n            \"dataset\": row.dataset,\n            \"split\": row.split,\n            \"predicted\": parsed['category'],\n            \"confidence\": parsed['confidence']\n        })\n\n        \n        # Log progress\n        if subset_row_count % log_every_n_examples == 0:\n            elapsed_time = time.time() - start_time\n            \n            avg_time_per_row = elapsed_time / subset_row_count\n            remaining_rows = total_rows - subset_row_count\n            eta = avg_time_per_row * remaining_rows\n            \n            print(f\"Processed original df idx {row.Index} (subset row {subset_row_count}) | \"\n                  f\"Elapsed: {elapsed_time:.2f}s | ETA: {eta:.2f}s\")\n    \n    return results  # Return list of dictionaries\n    \n\nprint(f\"Starting intent classification using {Config.model_name}\")\nsubset_results = predict_intent(Config.model_name, \n                                df, \n                                bulletpts_intent, \n                                start_index = Config.start_index, \n                                end_index = Config.end_index,\n                                log_every_n_examples = Config.log_every_n_examples)\n\n\n\n# # previously for Ollama\n# # update end_index for filename (if None is used for the end of the df)\n# # Get the last index of the DataFrame\n# last_index = df.index[-1] \n# # Use last index if Config.end_index is None\n# end_index = Config.end_index if Config.end_index is not None else last_index\n# 2025.07.07\n# now for Ollama AND Gemini\n# Gemini - needs to track 'end_index' for API JSON exports (when daily limits are exhausted)\n# Ollama - reuse this code\nend_index = max(r['Index'] for r in subset_results)\n\n\n\n# 2025.05.23 changed from JSON to PKL\n# because we are saving list of dictionaries\n# Save to PKL\n# 2025.06.04 explore changing back to JSON\n# with open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.pkl', 'wb') as f:\n#     pickle.dump(subset_results, f)\nwith open(f'results_{Config.model_name}_{Config.dataset_name}_{Config.start_index}_{end_index}.json', 'w') as f:\n    json.dump(subset_results, f, indent=2)\n\nprint(\"Completed intent classification\")\n\n\n#######################\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:40:09.135247Z","iopub.execute_input":"2025-07-07T04:40:09.135598Z","iopub.status.idle":"2025-07-07T04:40:09.149372Z","shell.execute_reply.started":"2025-07-07T04:40:09.135573Z","shell.execute_reply":"2025-07-07T04:40:09.148188Z"}},"outputs":[{"name":"stdout","text":"Overwriting predict_class.py\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"%%writefile /kaggle/working/main.py\nimport subprocess\nimport sys\nfrom src.config import Config\n\n\n# 1. Install libraries from requirements.txt\nprint(\"Installing dependencies...\")\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"/kaggle/working/requirements.txt\"], check=True)\n\n\n# 2. Run setup_ollama.py\nif 'gemini' not in Config.model_name:\n    print(\"Starting Ollama setup...\")\n    # subprocess.run([\"python3\", \"/kaggle/working/src/setup_ollama.py\"], check=True)\n    print(\"Starting Ollama setup...\")\n    subprocess.run(\n        [\"python3\", \"-m\", \"src.setup_ollama\"],  # Run as a module\n        cwd=\"/kaggle/working\",  # Set working directory to parent of 'src'\n        check=True\n    )\n    \n\n# 3. Run download_dataset.py\nprint(\"Downloading dataset...\")\nsubprocess.run([\"python3\", \"/kaggle/working/download_dataset.py\"], check=True)\n\n# 4. Run predict_class.py\nprint(\"Running prediction script...\")\nsubprocess.run([\"python3\", \"/kaggle/working/predict_class.py\"], check=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:55:13.589763Z","iopub.execute_input":"2025-07-07T03:55:13.590662Z","iopub.status.idle":"2025-07-07T03:55:13.597244Z","shell.execute_reply.started":"2025-07-07T03:55:13.590626Z","shell.execute_reply":"2025-07-07T03:55:13.596172Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/main.py\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"# Model on subset of examples","metadata":{}},{"cell_type":"code","source":"!python3 /kaggle/working/main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:40:23.397683Z","iopub.execute_input":"2025-07-07T04:40:23.398087Z","iopub.status.idle":"2025-07-07T04:42:14.241163Z","shell.execute_reply.started":"2025-07-07T04:40:23.398057Z","shell.execute_reply":"2025-07-07T04:42:14.239770Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 2)) (2.11.4)\nRequirement already satisfied: typing in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 3)) (3.7.4.3)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 4)) (0.31.1)\nRequirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 5)) (1.9.0)\nRequirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/requirements.txt (line 6)) (9.1.2)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r /kaggle/working/requirements.txt (line 2)) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (1.1.0)\nRequirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai->-r /kaggle/working/requirements.txt (line 5)) (4.9.0)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai->-r /kaggle/working/requirements.txt (line 5)) (2.40.1)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai->-r /kaggle/working/requirements.txt (line 5)) (0.28.1)\nRequirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai->-r /kaggle/working/requirements.txt (line 5)) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r /kaggle/working/requirements.txt (line 5)) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r /kaggle/working/requirements.txt (line 5)) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (4.9.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->-r /kaggle/working/requirements.txt (line 4)) (2.4.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai->-r /kaggle/working/requirements.txt (line 5)) (0.6.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/requirements.txt (line 1)) (2024.2.0)\nDownloading dataset...\nDataset has already been downloaded. If this is incorrect, please delete the Adaptive-Decision-Boundary 'data' folder.\nRunning prediction script...\nLoaded dataset into dataframe: banking\nDimensions: (13083, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\n================================================================================\nOriginal dataset intents: ['Refund_not_showing_up', 'activate_my_card', 'age_limit', 'apple_pay_or_google_pay', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_acceptance', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_not_working', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'card_swallowed', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_card_payment', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'exchange_charge', 'exchange_rate', 'exchange_via_app', 'extra_charge_on_statement', 'failed_transfer', 'fiat_currency_support', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'request_refund', 'reverted_card_payment?', 'supported_cards_and_currencies', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_card_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'visa_or_mastercard', 'why_verify_identity', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\nNumber of original intents: 77\n\nFetching 3 files: 100%|█████████████████████████| 3/3 [00:00<00:00, 1684.46it/s]\n================================================================================\nOriginal intents to convert to OOS class\n    index                                    label\n0       2                  apple_pay_or_google_pay\n1      10                          card_acceptance\n2      14                         card_not_working\n3      15                 card_payment_fee_charged\n4      16              card_payment_not_recognised\n5      17         card_payment_wrong_exchange_rate\n6      19                   cash_withdrawal_charge\n7      25                    declined_card_payment\n8      31                          exchange_charge\n9      32                            exchange_rate\n10     33                         exchange_via_app\n11     34                extra_charge_on_statement\n12     36                    fiat_currency_support\n13     52                           request_refund\n14     53                   reverted_card_payment?\n15     54           supported_cards_and_currencies\n16     57                    top_up_by_card_charge\n17     73                       visa_or_mastercard\n18     76  wrong_exchange_rate_for_cash_withdrawal\nPercentage of original intents to convert to OOS class: 0.24675324675324675\n\n================================================================================\nUnique intents after converting some to OOS class\n['Refund_not_showing_up', 'activate_my_card', 'age_limit', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_swallowed', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'failed_transfer', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'oos', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'why_verify_identity', 'wrong_amount_of_cash_received']\nNumber of unique intents after converting some to OOS class: 59\n\n================================================================================\nsanity check\nNumber of original intents: 77\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset): 78\nNumber of original intents to convert to OOS class: 19\nPercentage of original intents to convert to OOS class: 0.24675324675324675\nNumber of unique intents after converting some to OOS class: 59\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: 59\nNumbers match: True\nPrepared unique intents\nFiltered dataset\nDimensions: (13083, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\nFetching 62 files: 100%|███████████████████████| 62/62 [00:00<00:00, 838.08it/s]\nStarting intent classification using gemini-2.5-flash-preview-05-20\nExample of how prompt looks, for the 1st example in this subset of data\n\nYou are an expert in understanding and identifying what users are asking you.\n\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\n- Refund_not_showing_up\n- activate_my_card\n- age_limit\n- atm_support\n- automatic_top_up\n- balance_not_updated_after_bank_transfer\n- balance_not_updated_after_cheque_or_cash_deposit\n- beneficiary_not_allowed\n- cancel_transfer\n- card_about_to_expire\n- card_arrival\n- card_delivery_estimate\n- card_linking\n- card_swallowed\n- cash_withdrawal_not_recognised\n- change_pin\n- compromised_card\n- contactless_not_working\n- country_support\n- declined_cash_withdrawal\n- declined_transfer\n- direct_debit_payment_not_recognised\n- disposable_card_limits\n- edit_personal_details\n- failed_transfer\n- get_disposable_virtual_card\n- get_physical_card\n- getting_spare_card\n- getting_virtual_card\n- lost_or_stolen_card\n- lost_or_stolen_phone\n- order_physical_card\n- passcode_forgotten\n- pending_card_payment\n- pending_cash_withdrawal\n- pending_top_up\n- pending_transfer\n- pin_blocked\n- receiving_money\n- terminate_account\n- top_up_by_bank_transfer_charge\n- top_up_by_cash_or_cheque\n- top_up_failed\n- top_up_limits\n- top_up_reverted\n- topping_up_by_card\n- transaction_charged_twice\n- transfer_fee_charged\n- transfer_into_account\n- transfer_not_received_by_recipient\n- transfer_timing\n- unable_to_verify_identity\n- verify_my_identity\n- verify_source_of_funds\n- verify_top_up\n- virtual_card_not_working\n- why_verify_identity\n- wrong_amount_of_cash_received\n\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\n\nBelow are several examples to guide your classification:\n\n---\nExample 1:\nQuestion: \"I am planning activating my card was it possible?\"\nCategory:\n{{\n  \"category\": \"activate_my_card\",\n  \"confidence\": 7.45\n}}\n\nExample 2:\nQuestion: \"Where can I activate my card?\"\nCategory:\n{{\n  \"category\": \"activate_my_card\",\n  \"confidence\": 93.66\n}}\n\nExample 3:\nQuestion: \"Can I get some help to get me card activated?\"\nCategory:\n{{\n  \"category\": \"activate_my_card\",\n  \"confidence\": 56.33\n}}\n\nExample 4:\nQuestion: \"I just got a new card, and I want to know how to activate.\"\nCategory:\n{{\n  \"category\": \"activate_my_card\",\n  \"confidence\": 45.5\n}}\n\nExample 5:\nQuestion: \"How do I activate a card I received?\"\nCategory:\n{{\n  \"category\": \"activate_my_card\",\n  \"confidence\": 90.2\n}}\n\nExample 6:\nQuestion: \"Is there a limit for age?\"\nCategory:\n{{\n  \"category\": \"age_limit\",\n  \"confidence\": 26.75\n}}\n\nExample 7:\nQuestion: \"Do you offer services for children to have money saving experience?\"\nCategory:\n{{\n  \"category\": \"age_limit\",\n  \"confidence\": 89.21\n}}\n\nExample 8:\nQuestion: \"What age do you have to be to open an account?\"\nCategory:\n{{\n  \"category\": \"age_limit\",\n  \"confidence\": 57.4\n}}\n\nExample 9:\nQuestion: \"How old do you have to be to be able to open an account?\"\nCategory:\n{{\n  \"category\": \"age_limit\",\n  \"confidence\": 30.96\n}}\n\nExample 10:\nQuestion: \"At what age can I open an account?\"\nCategory:\n{{\n  \"category\": \"age_limit\",\n  \"confidence\": 29.02\n}}\n\nExample 11:\nQuestion: \"I need help from someone in your department with finding my nearest ATM.\"\nCategory:\n{{\n  \"category\": \"atm_support\",\n  \"confidence\": 88.36\n}}\n\nExample 12:\nQuestion: \"Which ATMs accept this placard ?\"\nCategory:\n{{\n  \"category\": \"atm_support\",\n  \"confidence\": 46.25\n}}\n\nExample 13:\nQuestion: \"Is the closest ATM to me within 2 miles?\"\nCategory:\n{{\n  \"category\": \"atm_support\",\n  \"confidence\": 11.84\n}}\n\nExample 14:\nQuestion: \"Where are the ATMs that accept this card?\"\nCategory:\n{{\n  \"category\": \"atm_support\",\n  \"confidence\": 66.18\n}}\n\nExample 15:\nQuestion: \"Can I use my card to withdraw from my account?\"\nCategory:\n{{\n  \"category\": \"atm_support\",\n  \"confidence\": 92.06\n}}\n\nExample 16:\nQuestion: \"Does auto top-up have a limit?\"\nCategory:\n{{\n  \"category\": \"automatic_top_up\",\n  \"confidence\": 4.24\n}}\n\nExample 17:\nQuestion: \"Is there an auto top up option?\"\nCategory:\n{{\n  \"category\": \"automatic_top_up\",\n  \"confidence\": 24.46\n}}\n\nExample 18:\nQuestion: \"Can I have my account add money automatically in certain intervals?\"\nCategory:\n{{\n  \"category\": \"automatic_top_up\",\n  \"confidence\": 22.97\n}}\n\nExample 19:\nQuestion: \"Can it automatically top up my account?\"\nCategory:\n{{\n  \"category\": \"automatic_top_up\",\n  \"confidence\": 32.13\n}}\n\nExample 20:\nQuestion: \"can you top up your account automatically\"\nCategory:\n{{\n  \"category\": \"automatic_top_up\",\n  \"confidence\": 71.62\n}}\n\nExample 21:\nQuestion: \"I was wondering if international transfers take longer than normal because I made a transfer from France a couple of days ago and nothing has happened yet?\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_bank_transfer\",\n  \"confidence\": 21.12\n}}\n\nExample 22:\nQuestion: \"Hi. A couple hours ago I make a transfer from my UK bank account, but it hasn't shown up. Please, would you see what the delay is?\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_bank_transfer\",\n  \"confidence\": 52.15\n}}\n\nExample 23:\nQuestion: \"I did a money transfer to my account and it is not showing there.\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_bank_transfer\",\n  \"confidence\": 33.65\n}}\n\nExample 24:\nQuestion: \"Although I transferred some money, it has not as of yet, arrived.\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_bank_transfer\",\n  \"confidence\": 42.76\n}}\n\nExample 25:\nQuestion: \"What happened to the transfer I did?\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_bank_transfer\",\n  \"confidence\": 46.34\n}}\n\nExample 26:\nQuestion: \"I have paid money into my account but it doesn't show.\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\n  \"confidence\": 10.5\n}}\n\nExample 27:\nQuestion: \"I made a deposit this morning but it is still pending?\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\n  \"confidence\": 52.75\n}}\n\nExample 28:\nQuestion: \"Where is my deposit?\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\n  \"confidence\": 94.17\n}}\n\nExample 29:\nQuestion: \"My cheque is slow to cash\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\n  \"confidence\": 40.84\n}}\n\nExample 30:\nQuestion: \"Why isn't my cash deposit showing up in my account? I deposited it this morning.\"\nCategory:\n{{\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\n  \"confidence\": 92.51\n}}\n\nExample 31:\nQuestion: \"My account transfer was blocked.\"\nCategory:\n{{\n  \"category\": \"beneficiary_not_allowed\",\n  \"confidence\": 14.94\n}}\n\nExample 32:\nQuestion: \"Why can't you allow my beneficiary?\"\nCategory:\n{{\n  \"category\": \"beneficiary_not_allowed\",\n  \"confidence\": 98.01\n}}\n\nExample 33:\nQuestion: \"I have been trying to exchange this for crypto but the app won't work could you please help me?\"\nCategory:\n{{\n  \"category\": \"beneficiary_not_allowed\",\n  \"confidence\": 88.17\n}}\n\nExample 34:\nQuestion: \"why didnt a transfer to my account process\"\nCategory:\n{{\n  \"category\": \"beneficiary_not_allowed\",\n  \"confidence\": 10.32\n}}\n\nExample 35:\nQuestion: \"Explain why I can't do a transfer to an account.\"\nCategory:\n{{\n  \"category\": \"beneficiary_not_allowed\",\n  \"confidence\": 23.16\n}}\n\nExample 36:\nQuestion: \"I'm really upset because I made a typo during a transfer and now I've sent money to the wrong account.  I can't fix this with the app.  Please help me immediately!\"\nCategory:\n{{\n  \"category\": \"cancel_transfer\",\n  \"confidence\": 18.39\n}}\n\nExample 37:\nQuestion: \"My morning transaction needs to be canceled.\"\nCategory:\n{{\n  \"category\": \"cancel_transfer\",\n  \"confidence\": 43.78\n}}\n\nExample 38:\nQuestion: \"What do I have to do to cancel a transfer?\"\nCategory:\n{{\n  \"category\": \"cancel_transfer\",\n  \"confidence\": 78.59\n}}\n\nExample 39:\nQuestion: \"Can you help me to quickly cancel a transaction I accidentally did to the wrong account?\"\nCategory:\n{{\n  \"category\": \"cancel_transfer\",\n  \"confidence\": 24.34\n}}\n\nExample 40:\nQuestion: \"How do I cancel my transfer?\"\nCategory:\n{{\n  \"category\": \"cancel_transfer\",\n  \"confidence\": 59.32\n}}\n\nExample 41:\nQuestion: \"What would the price be for an expired card replacement and how long will it take me to get it?\"\nCategory:\n{{\n  \"category\": \"card_about_to_expire\",\n  \"confidence\": 76.01\n}}\n\nExample 42:\nQuestion: \"How do I go about ordering a new bank card?\"\nCategory:\n{{\n  \"category\": \"card_about_to_expire\",\n  \"confidence\": 21.71\n}}\n\nExample 43:\nQuestion: \"If I am in China, can I still order a new card and if so, how?\"\nCategory:\n{{\n  \"category\": \"card_about_to_expire\",\n  \"confidence\": 46.12\n}}\n\nExample 44:\nQuestion: \"How do I replace my card?\"\nCategory:\n{{\n  \"category\": \"card_about_to_expire\",\n  \"confidence\": 91.57\n}}\n\nExample 45:\nQuestion: \"Can I have a new card shipped to China?\"\nCategory:\n{{\n  \"category\": \"card_about_to_expire\",\n  \"confidence\": 59.63\n}}\n\nExample 46:\nQuestion: \"What is the tracking number for the card you sent?\"\nCategory:\n{{\n  \"category\": \"card_arrival\",\n  \"confidence\": 6.94\n}}\n\nExample 47:\nQuestion: \"If I ordered my new card last week, how much longer should I wait to receive it?\"\nCategory:\n{{\n  \"category\": \"card_arrival\",\n  \"confidence\": 79.25\n}}\n\nExample 48:\nQuestion: \"When will I get my new card?\"\nCategory:\n{{\n  \"category\": \"card_arrival\",\n  \"confidence\": 62.02\n}}\n\nExample 49:\nQuestion: \"How do I track my card?\"\nCategory:\n{{\n  \"category\": \"card_arrival\",\n  \"confidence\": 79.06\n}}\n\nExample 50:\nQuestion: \"Can you tell me why I haven't received my new card?\"\nCategory:\n{{\n  \"category\": \"card_arrival\",\n  \"confidence\": 92.47\n}}\n\nExample 51:\nQuestion: \"Can I have it by a certain date?\"\nCategory:\n{{\n  \"category\": \"card_delivery_estimate\",\n  \"confidence\": 62.13\n}}\n\nExample 52:\nQuestion: \"When will it be delivered to the US?\"\nCategory:\n{{\n  \"category\": \"card_delivery_estimate\",\n  \"confidence\": 85.56\n}}\n\nExample 53:\nQuestion: \"Send my card as soon as you are able to.\"\nCategory:\n{{\n  \"category\": \"card_delivery_estimate\",\n  \"confidence\": 23.63\n}}\n\nExample 54:\nQuestion: \"Does delivery to the US take long?\"\nCategory:\n{{\n  \"category\": \"card_delivery_estimate\",\n  \"confidence\": 61.13\n}}\n\nExample 55:\nQuestion: \"Can I get my card expedited?\"\nCategory:\n{{\n  \"category\": \"card_delivery_estimate\",\n  \"confidence\": 32.67\n}}\n\nExample 56:\nQuestion: \"Hey, I have my card, how do I get it to show in the app?\"\nCategory:\n{{\n  \"category\": \"card_linking\",\n  \"confidence\": 1.95\n}}\n\nExample 57:\nQuestion: \"Can I reactivate my lost card that I found this morning in my jacket pocket?\"\nCategory:\n{{\n  \"category\": \"card_linking\",\n  \"confidence\": 13.77\n}}\n\nExample 58:\nQuestion: \"Where in the app do I link a new card?\"\nCategory:\n{{\n  \"category\": \"card_linking\",\n  \"confidence\": 5.53\n}}\n\nExample 59:\nQuestion: \"Could I reactivate my card please, I couldn't find it but it turns out it was in my jacket pocket.\"\nCategory:\n{{\n  \"category\": \"card_linking\",\n  \"confidence\": 47.37\n}}\n\nExample 60:\nQuestion: \"How do I view the card I received in the app?\"\nCategory:\n{{\n  \"category\": \"card_linking\",\n  \"confidence\": 11.31\n}}\n\nExample 61:\nQuestion: \"Why would an ATM swallow my card?\"\nCategory:\n{{\n  \"category\": \"card_swallowed\",\n  \"confidence\": 3.54\n}}\n\nExample 62:\nQuestion: \"I need a new card because the ATM took mine.\"\nCategory:\n{{\n  \"category\": \"card_swallowed\",\n  \"confidence\": 72.33\n}}\n\nExample 63:\nQuestion: \"My card got stuck in an ATM.\"\nCategory:\n{{\n  \"category\": \"card_swallowed\",\n  \"confidence\": 61.32\n}}\n\nExample 64:\nQuestion: \"atm ate my card\"\nCategory:\n{{\n  \"category\": \"card_swallowed\",\n  \"confidence\": 6.07\n}}\n\nExample 65:\nQuestion: \"Why did the ATM take my card and keep it?\"\nCategory:\n{{\n  \"category\": \"card_swallowed\",\n  \"confidence\": 98.36\n}}\n\nExample 66:\nQuestion: \"Cash I did not get showed up in my account\"\nCategory:\n{{\n  \"category\": \"cash_withdrawal_not_recognised\",\n  \"confidence\": 65.95\n}}\n\nExample 67:\nQuestion: \"I am seeing unathorized transactions in the app, on my account.\"\nCategory:\n{{\n  \"category\": \"cash_withdrawal_not_recognised\",\n  \"confidence\": 69.96\n}}\n\nExample 68:\nQuestion: \"There is a suspicious cash withdraw on the account.\"\nCategory:\n{{\n  \"category\": \"cash_withdrawal_not_recognised\",\n  \"confidence\": 73.58\n}}\n\nExample 69:\nQuestion: \"What is the strange cash withdrawal on my statement?\"\nCategory:\n{{\n  \"category\": \"cash_withdrawal_not_recognised\",\n  \"confidence\": 1.93\n}}\n\nExample 70:\nQuestion: \"A cash withdrawal that I didn't authorize is shown on my account - can you please cancel my card as soon as possible?\"\nCategory:\n{{\n  \"category\": \"cash_withdrawal_not_recognised\",\n  \"confidence\": 16.0\n}}\n\nExample 71:\nQuestion: \"I need a new Pin how do I go about that?\"\nCategory:\n{{\n  \"category\": \"change_pin\",\n  \"confidence\": 7.01\n}}\n\nExample 72:\nQuestion: \"Are their certain cash machines where I can change my pin?\"\nCategory:\n{{\n  \"category\": \"change_pin\",\n  \"confidence\": 17.78\n}}\n\nExample 73:\nQuestion: \"Do I have to go into the bank to change my PIN?\"\nCategory:\n{{\n  \"category\": \"change_pin\",\n  \"confidence\": 15.93\n}}\n\nExample 74:\nQuestion: \"May I receive a different card pin\"\nCategory:\n{{\n  \"category\": \"change_pin\",\n  \"confidence\": 11.63\n}}\n\nExample 75:\nQuestion: \"If I wanted to change my PIN, how would I do that?\"\nCategory:\n{{\n  \"category\": \"change_pin\",\n  \"confidence\": 62.49\n}}\n\nExample 76:\nQuestion: \"Someone besides me might be using my card.\"\nCategory:\n{{\n  \"category\": \"compromised_card\",\n  \"confidence\": 61.67\n}}\n\nExample 77:\nQuestion: \"I froze my account, but how do I order a replacement card?\"\nCategory:\n{{\n  \"category\": \"compromised_card\",\n  \"confidence\": 53.3\n}}\n\nExample 78:\nQuestion: \"Somebody used my card without my knowledge!\"\nCategory:\n{{\n  \"category\": \"compromised_card\",\n  \"confidence\": 29.56\n}}\n\nExample 79:\nQuestion: \"What can I do if my card details where stolen from my car? I think they used my card to buy gas.\"\nCategory:\n{{\n  \"category\": \"compromised_card\",\n  \"confidence\": 14.33\n}}\n\nExample 80:\nQuestion: \"Questionable transactions on my account.\"\nCategory:\n{{\n  \"category\": \"compromised_card\",\n  \"confidence\": 79.01\n}}\n\nExample 81:\nQuestion: \"I wanted to use my contactless at the metro today but it didn't accept it!\"\nCategory:\n{{\n  \"category\": \"contactless_not_working\",\n  \"confidence\": 11.22\n}}\n\nExample 82:\nQuestion: \"What can I do if contactless doesn't work?\"\nCategory:\n{{\n  \"category\": \"contactless_not_working\",\n  \"confidence\": 50.44\n}}\n\nExample 83:\nQuestion: \"Contactless payments need to be enabled for my card.\"\nCategory:\n{{\n  \"category\": \"contactless_not_working\",\n  \"confidence\": 27.04\n}}\n\nExample 84:\nQuestion: \"Are my contactless settings correct? I tried to use it today but it wasn't working.\"\nCategory:\n{{\n  \"category\": \"contactless_not_working\",\n  \"confidence\": 49.23\n}}\n\nExample 85:\nQuestion: \"Why is my contactless not working?\"\nCategory:\n{{\n  \"category\": \"contactless_not_working\",\n  \"confidence\": 15.08\n}}\n\nExample 86:\nQuestion: \"Can you tell me the countries you provide support for.\"\nCategory:\n{{\n  \"category\": \"country_support\",\n  \"confidence\": 94.13\n}}\n\nExample 87:\nQuestion: \"Can an American resident apply to get a card?\"\nCategory:\n{{\n  \"category\": \"country_support\",\n  \"confidence\": 40.7\n}}\n\nExample 88:\nQuestion: \"Where in the European Union can I get a card?\"\nCategory:\n{{\n  \"category\": \"country_support\",\n  \"confidence\": 84.51\n}}\n\nExample 89:\nQuestion: \"Which countries do you operate in\"\nCategory:\n{{\n  \"category\": \"country_support\",\n  \"confidence\": 57.22\n}}\n\nExample 90:\nQuestion: \"Are cards available in the EU?\"\nCategory:\n{{\n  \"category\": \"country_support\",\n  \"confidence\": 86.23\n}}\n\nExample 91:\nQuestion: \"I can't get cash from the ATM!\"\nCategory:\n{{\n  \"category\": \"declined_cash_withdrawal\",\n  \"confidence\": 79.47\n}}\n\nExample 92:\nQuestion: \"When I went to get cash, it was declined!\"\nCategory:\n{{\n  \"category\": \"declined_cash_withdrawal\",\n  \"confidence\": 72.98\n}}\n\nExample 93:\nQuestion: \"This morning I wanted to make a withdrawal before work, but my card was declined! Please double check it for me as this is the first time it was declined.\"\nCategory:\n{{\n  \"category\": \"declined_cash_withdrawal\",\n  \"confidence\": 84.1\n}}\n\nExample 94:\nQuestion: \"my card was frozen due to putting in the wrong pin too much.  how many tries do i have\"\nCategory:\n{{\n  \"category\": \"declined_cash_withdrawal\",\n  \"confidence\": 7.8\n}}\n\nExample 95:\nQuestion: \"totally unacceptable.  I'm stranded with no cash because the ATM wouldn't give me any money!\"\nCategory:\n{{\n  \"category\": \"declined_cash_withdrawal\",\n  \"confidence\": 29.81\n}}\n\nExample 96:\nQuestion: \"Seems like my transfer was declined how come?\"\nCategory:\n{{\n  \"category\": \"declined_transfer\",\n  \"confidence\": 92.76\n}}\n\nExample 97:\nQuestion: \"I tried to buy something online yesterday but it wouldn't stop saying declined. Tried again today but same thing happened. What's Broken?\"\nCategory:\n{{\n  \"category\": \"declined_transfer\",\n  \"confidence\": 36.97\n}}\n\nExample 98:\nQuestion: \"why did i get declined transfer\"\nCategory:\n{{\n  \"category\": \"declined_transfer\",\n  \"confidence\": 38.12\n}}\n\nExample 99:\nQuestion: \"Transfer was declined.\"\nCategory:\n{{\n  \"category\": \"declined_transfer\",\n  \"confidence\": 23.5\n}}\n\nExample 100:\nQuestion: \"My transfer has been declined.\"\nCategory:\n{{\n  \"category\": \"declined_transfer\",\n  \"confidence\": 13.51\n}}\n\nExample 101:\nQuestion: \"Is it possible to dispute a debit payment from a couple of months ago.\"\nCategory:\n{{\n  \"category\": \"direct_debit_payment_not_recognised\",\n  \"confidence\": 11.7\n}}\n\nExample 102:\nQuestion: \"Why is there a direct debit payment on my statement that I didn't do?\"\nCategory:\n{{\n  \"category\": \"direct_debit_payment_not_recognised\",\n  \"confidence\": 74.39\n}}\n\nExample 103:\nQuestion: \"I found a direct debit I would like to dispute\"\nCategory:\n{{\n  \"category\": \"direct_debit_payment_not_recognised\",\n  \"confidence\": 46.61\n}}\n\nExample 104:\nQuestion: \"It seems there is an incorrect listing of a direct debit payment on my app that I did not make\"\nCategory:\n{{\n  \"category\": \"direct_debit_payment_not_recognised\",\n  \"confidence\": 40.38\n}}\n\nExample 105:\nQuestion: \"what is this charge on my account\"\nCategory:\n{{\n  \"category\": \"direct_debit_payment_not_recognised\",\n  \"confidence\": 76.46\n}}\n\nExample 106:\nQuestion: \"How many transactions can be made with a disposable card?\"\nCategory:\n{{\n  \"category\": \"disposable_card_limits\",\n  \"confidence\": 9.43\n}}\n\nExample 107:\nQuestion: \"How many disposable cards per person?\"\nCategory:\n{{\n  \"category\": \"disposable_card_limits\",\n  \"confidence\": 30.27\n}}\n\nExample 108:\nQuestion: \"How many disposable cards can I have?\"\nCategory:\n{{\n  \"category\": \"disposable_card_limits\",\n  \"confidence\": 92.09\n}}\n\nExample 109:\nQuestion: \"What is the limit on disposable cards?\"\nCategory:\n{{\n  \"category\": \"disposable_card_limits\",\n  \"confidence\": 46.19\n}}\n\nExample 110:\nQuestion: \"Is there a limit on making disposable cards?\"\nCategory:\n{{\n  \"category\": \"disposable_card_limits\",\n  \"confidence\": 49.96\n}}\n\nExample 111:\nQuestion: \"My address has changed. How do I report it?\"\nCategory:\n{{\n  \"category\": \"edit_personal_details\",\n  \"confidence\": 49.77\n}}\n\nExample 112:\nQuestion: \"My address details have changed and I want to update them\"\nCategory:\n{{\n  \"category\": \"edit_personal_details\",\n  \"confidence\": 17.45\n}}\n\nExample 113:\nQuestion: \"Where can I go to modify my detail?\"\nCategory:\n{{\n  \"category\": \"edit_personal_details\",\n  \"confidence\": 79.41\n}}\n\nExample 114:\nQuestion: \"I would like to edit my personal information .\"\nCategory:\n{{\n  \"category\": \"edit_personal_details\",\n  \"confidence\": 77.87\n}}\n\nExample 115:\nQuestion: \"How can I modify my details?\"\nCategory:\n{{\n  \"category\": \"edit_personal_details\",\n  \"confidence\": 30.62\n}}\n\nExample 116:\nQuestion: \"dont understand why transfer failed\"\nCategory:\n{{\n  \"category\": \"failed_transfer\",\n  \"confidence\": 74.34\n}}\n\nExample 117:\nQuestion: \"I have made 5 attempts to make a very standard survey, yet I can't get it to work. What is the problem? Is there an issue related to your system?\"\nCategory:\n{{\n  \"category\": \"failed_transfer\",\n  \"confidence\": 6.0\n}}\n\nExample 118:\nQuestion: \"I tried to do a transfer and it hasn't worked!\"\nCategory:\n{{\n  \"category\": \"failed_transfer\",\n  \"confidence\": 77.73\n}}\n\nExample 119:\nQuestion: \"I've now been trying to do a really standard transfer 5 times already. What's going on, is your system broken or something?!\"\nCategory:\n{{\n  \"category\": \"failed_transfer\",\n  \"confidence\": 38.02\n}}\n\nExample 120:\nQuestion: \"Why hasn't my transfer gone through\"\nCategory:\n{{\n  \"category\": \"failed_transfer\",\n  \"confidence\": 65.82\n}}\n\nExample 121:\nQuestion: \"Is there a disposable virtual card I can order?\"\nCategory:\n{{\n  \"category\": \"get_disposable_virtual_card\",\n  \"confidence\": 95.97\n}}\n\nExample 122:\nQuestion: \"How do I create a disposable virtual card?\"\nCategory:\n{{\n  \"category\": \"get_disposable_virtual_card\",\n  \"confidence\": 62.05\n}}\n\nExample 123:\nQuestion: \"Can you tell me where to go to get a disposable virtual card?\"\nCategory:\n{{\n  \"category\": \"get_disposable_virtual_card\",\n  \"confidence\": 69.44\n}}\n\nExample 124:\nQuestion: \"Will I be able to get a disposable virtual card as well?\"\nCategory:\n{{\n  \"category\": \"get_disposable_virtual_card\",\n  \"confidence\": 47.68\n}}\n\nExample 125:\nQuestion: \"What is the disposable card for?\"\nCategory:\n{{\n  \"category\": \"get_disposable_virtual_card\",\n  \"confidence\": 80.29\n}}\n\nExample 126:\nQuestion: \"my pin hasn't arrived in the post! How do I cancel it or get a new one?\"\nCategory:\n{{\n  \"category\": \"get_physical_card\",\n  \"confidence\": 48.19\n}}\n\nExample 127:\nQuestion: \"Are PIN separately?\"\nCategory:\n{{\n  \"category\": \"get_physical_card\",\n  \"confidence\": 46.9\n}}\n\nExample 128:\nQuestion: \"How do I find my card PIN?\"\nCategory:\n{{\n  \"category\": \"get_physical_card\",\n  \"confidence\": 48.55\n}}\n\nExample 129:\nQuestion: \"How do I get a PIN?\"\nCategory:\n{{\n  \"category\": \"get_physical_card\",\n  \"confidence\": 87.53\n}}\n\nExample 130:\nQuestion: \"Where is my pin? I don't have it yet\"\nCategory:\n{{\n  \"category\": \"get_physical_card\",\n  \"confidence\": 26.01\n}}\n\nExample 131:\nQuestion: \"Can I order extra cards?\"\nCategory:\n{{\n  \"category\": \"getting_spare_card\",\n  \"confidence\": 33.63\n}}\n\nExample 132:\nQuestion: \"Are there restrictions for ordering extra cards?\"\nCategory:\n{{\n  \"category\": \"getting_spare_card\",\n  \"confidence\": 12.84\n}}\n\nExample 133:\nQuestion: \"My child needs a card, how can I add them to the account I currently have?\"\nCategory:\n{{\n  \"category\": \"getting_spare_card\",\n  \"confidence\": 12.63\n}}\n\nExample 134:\nQuestion: \"How do I get a spare card?\"\nCategory:\n{{\n  \"category\": \"getting_spare_card\",\n  \"confidence\": 64.49\n}}\n\nExample 135:\nQuestion: \"How many active cards can I have?\"\nCategory:\n{{\n  \"category\": \"getting_spare_card\",\n  \"confidence\": 11.73\n}}\n\nExample 136:\nQuestion: \"I haven't received my virtual card yet, do yo know why?\"\nCategory:\n{{\n  \"category\": \"getting_virtual_card\",\n  \"confidence\": 98.8\n}}\n\nExample 137:\nQuestion: \"Where can i find the virtual card?\"\nCategory:\n{{\n  \"category\": \"getting_virtual_card\",\n  \"confidence\": 63.26\n}}\n\nExample 138:\nQuestion: \"Where can I sign up for a virtual card?\"\nCategory:\n{{\n  \"category\": \"getting_virtual_card\",\n  \"confidence\": 16.84\n}}\n\nExample 139:\nQuestion: \"I need to order a new card, can you please direct me to the virtual cards?\"\nCategory:\n{{\n  \"category\": \"getting_virtual_card\",\n  \"confidence\": 93.33\n}}\n\nExample 140:\nQuestion: \"I want one of the virtual cards!\"\nCategory:\n{{\n  \"category\": \"getting_virtual_card\",\n  \"confidence\": 40.67\n}}\n\nExample 141:\nQuestion: \"I believe my card has been stolen, what can I do about this situation? It's urgent.\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_card\",\n  \"confidence\": 4.77\n}}\n\nExample 142:\nQuestion: \"Help! I lost my card!\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_card\",\n  \"confidence\": 47.41\n}}\n\nExample 143:\nQuestion: \"My card has gone missing.\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_card\",\n  \"confidence\": 70.32\n}}\n\nExample 144:\nQuestion: \"Is there any way for you to find my card?\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_card\",\n  \"confidence\": 55.46\n}}\n\nExample 145:\nQuestion: \"I cannot find my credit card.\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_card\",\n  \"confidence\": 93.99\n}}\n\nExample 146:\nQuestion: \"Can you tell me what i steps i should take since my card was stolen?\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_phone\",\n  \"confidence\": 62.04\n}}\n\nExample 147:\nQuestion: \"Help!  I think my phone may be stolen or lost!\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_phone\",\n  \"confidence\": 17.81\n}}\n\nExample 148:\nQuestion: \"Someone stole my phone yesterday :( is there anything I need to do?\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_phone\",\n  \"confidence\": 66.1\n}}\n\nExample 149:\nQuestion: \"How can I access my account when I have lost my phone?\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_phone\",\n  \"confidence\": 7.15\n}}\n\nExample 150:\nQuestion: \"Hi, I lost my phone yesterday, what can I do to stop someone using my account on it?\"\nCategory:\n{{\n  \"category\": \"lost_or_stolen_phone\",\n  \"confidence\": 55.56\n}}\n\nExample 151:\nQuestion: \"Where are cards delivered to?\"\nCategory:\n{{\n  \"category\": \"order_physical_card\",\n  \"confidence\": 2.58\n}}\n\nExample 152:\nQuestion: \"Are physical card available?\"\nCategory:\n{{\n  \"category\": \"order_physical_card\",\n  \"confidence\": 76.48\n}}\n\nExample 153:\nQuestion: \"I need to get hold of a physical card?\"\nCategory:\n{{\n  \"category\": \"order_physical_card\",\n  \"confidence\": 46.92\n}}\n\nExample 154:\nQuestion: \"I would like to have a physical card to carry around and use. How can I get one?\"\nCategory:\n{{\n  \"category\": \"order_physical_card\",\n  \"confidence\": 31.6\n}}\n\nExample 155:\nQuestion: \"how do i get a new card\"\nCategory:\n{{\n  \"category\": \"order_physical_card\",\n  \"confidence\": 49.31\n}}\n\nExample 156:\nQuestion: \"what is going on, i have entered my passcode and its not working\"\nCategory:\n{{\n  \"category\": \"passcode_forgotten\",\n  \"confidence\": 55.95\n}}\n\nExample 157:\nQuestion: \"What are the steps to reset my passcode?\"\nCategory:\n{{\n  \"category\": \"passcode_forgotten\",\n  \"confidence\": 16.88\n}}\n\nExample 158:\nQuestion: \"I don't know my password anymore.\"\nCategory:\n{{\n  \"category\": \"passcode_forgotten\",\n  \"confidence\": 90.28\n}}\n\nExample 159:\nQuestion: \"What do I do if I forgot my passcode?\"\nCategory:\n{{\n  \"category\": \"passcode_forgotten\",\n  \"confidence\": 66.43\n}}\n\nExample 160:\nQuestion: \"I used to know my password, but not anymore.\"\nCategory:\n{{\n  \"category\": \"passcode_forgotten\",\n  \"confidence\": 29.93\n}}\n\nExample 161:\nQuestion: \"I have waited 15 days, but my payment still hasn't cleared.\"\nCategory:\n{{\n  \"category\": \"pending_card_payment\",\n  \"confidence\": 1.16\n}}\n\nExample 162:\nQuestion: \"Hi, status of one of my card payment is still pending from a while. Please let e know how much time it will take to complete.\"\nCategory:\n{{\n  \"category\": \"pending_card_payment\",\n  \"confidence\": 4.46\n}}\n\nExample 163:\nQuestion: \"How long does it take for a purchase to go from pending to authorised?\"\nCategory:\n{{\n  \"category\": \"pending_card_payment\",\n  \"confidence\": 13.84\n}}\n\nExample 164:\nQuestion: \"My card payment has been pending for a long time now. Why is it taking so long to take. It should have already made it through.\"\nCategory:\n{{\n  \"category\": \"pending_card_payment\",\n  \"confidence\": 62.03\n}}\n\nExample 165:\nQuestion: \"After making a payment with my card it doesn't seem to have worked. It's just showing to be pending. When will this actually be going through?\"\nCategory:\n{{\n  \"category\": \"pending_card_payment\",\n  \"confidence\": 41.56\n}}\n\nExample 166:\nQuestion: \"Why is the cash withdraw I made shown as pending?\"\nCategory:\n{{\n  \"category\": \"pending_cash_withdrawal\",\n  \"confidence\": 10.37\n}}\n\nExample 167:\nQuestion: \"I tried to take money from my card, but it didn't work. Later I saw that the transaction is still in progress. What's goign on?\"\nCategory:\n{{\n  \"category\": \"pending_cash_withdrawal\",\n  \"confidence\": 28.62\n}}\n\nExample 168:\nQuestion: \"I didn't receive my money earlier and it says the transaction is still in progress. Can you fix it?\"\nCategory:\n{{\n  \"category\": \"pending_cash_withdrawal\",\n  \"confidence\": 14.31\n}}\n\nExample 169:\nQuestion: \"Why has my deposit in the ATM not cleared yet?\"\nCategory:\n{{\n  \"category\": \"pending_cash_withdrawal\",\n  \"confidence\": 53.96\n}}\n\nExample 170:\nQuestion: \"My cash withdrawal says pending, why?\"\nCategory:\n{{\n  \"category\": \"pending_cash_withdrawal\",\n  \"confidence\": 47.94\n}}\n\nExample 171:\nQuestion: \"What's taking my top-up so long?\"\nCategory:\n{{\n  \"category\": \"pending_top_up\",\n  \"confidence\": 34.65\n}}\n\nExample 172:\nQuestion: \"Why hasn't my top-up finished pending yet?\"\nCategory:\n{{\n  \"category\": \"pending_top_up\",\n  \"confidence\": 39.17\n}}\n\nExample 173:\nQuestion: \"Seems like my top-up has not gone through\"\nCategory:\n{{\n  \"category\": \"pending_top_up\",\n  \"confidence\": 76.49\n}}\n\nExample 174:\nQuestion: \"What is the reason my top-up is still pending?\"\nCategory:\n{{\n  \"category\": \"pending_top_up\",\n  \"confidence\": 66.19\n}}\n\nExample 175:\nQuestion: \"I have been waiting for my top-up to complete and it still hasn't gone through.\"\nCategory:\n{{\n  \"category\": \"pending_top_up\",\n  \"confidence\": 3.74\n}}\n\nExample 176:\nQuestion: \"Why is my transfer still pending?\"\nCategory:\n{{\n  \"category\": \"pending_transfer\",\n  \"confidence\": 38.35\n}}\n\nExample 177:\nQuestion: \"Hello. How long does it usually take to transfer money to another country? I've made sure all the information is correct, but the transfer still says that it's \"pending.\"\"\nCategory:\n{{\n  \"category\": \"pending_transfer\",\n  \"confidence\": 2.2\n}}\n\nExample 178:\nQuestion: \"How long does it take for pending to go through\"\nCategory:\n{{\n  \"category\": \"pending_transfer\",\n  \"confidence\": 30.47\n}}\n\nExample 179:\nQuestion: \"Transfers may show up as pending for up to one business day while they are processed, and then they'll depart for the beneficiary accounts. Please confirm that you have correctly entered your account details. SEPA transfers typically take up to two working days, while SWIFT transfers can take up to five working days.\"\nCategory:\n{{\n  \"category\": \"pending_transfer\",\n  \"confidence\": 67.82\n}}\n\nExample 180:\nQuestion: \"Pending still shows on this transfer, why?\"\nCategory:\n{{\n  \"category\": \"pending_transfer\",\n  \"confidence\": 61.36\n}}\n\nExample 181:\nQuestion: \"I was blocked by using the wrong pin too many times, can you help me?\"\nCategory:\n{{\n  \"category\": \"pin_blocked\",\n  \"confidence\": 97.28\n}}\n\nExample 182:\nQuestion: \"How do I reset my PIN?\"\nCategory:\n{{\n  \"category\": \"pin_blocked\",\n  \"confidence\": 34.29\n}}\n\nExample 183:\nQuestion: \"How do I deal with a blocked PIN?\"\nCategory:\n{{\n  \"category\": \"pin_blocked\",\n  \"confidence\": 92.4\n}}\n\nExample 184:\nQuestion: \"Can you assist me with unblocking my PIN? I put it in wrong too many times.\"\nCategory:\n{{\n  \"category\": \"pin_blocked\",\n  \"confidence\": 55.89\n}}\n\nExample 185:\nQuestion: \"Can I unblock my PIN in the app?\"\nCategory:\n{{\n  \"category\": \"pin_blocked\",\n  \"confidence\": 55.94\n}}\n\nExample 186:\nQuestion: \"Is it possible for a friend to personally send me a payment?\"\nCategory:\n{{\n  \"category\": \"receiving_money\",\n  \"confidence\": 34.05\n}}\n\nExample 187:\nQuestion: \"Can I transfer my payroll to the bank?\"\nCategory:\n{{\n  \"category\": \"receiving_money\",\n  \"confidence\": 77.89\n}}\n\nExample 188:\nQuestion: \"What are the ways for others to transfer me money?\"\nCategory:\n{{\n  \"category\": \"receiving_money\",\n  \"confidence\": 66.45\n}}\n\nExample 189:\nQuestion: \"My friend wants to send me money, can she?\"\nCategory:\n{{\n  \"category\": \"receiving_money\",\n  \"confidence\": 43.95\n}}\n\nExample 190:\nQuestion: \"My salary is deposited in GBP. Do I need to choose the currency?\"\nCategory:\n{{\n  \"category\": \"receiving_money\",\n  \"confidence\": 59.46\n}}\n\nExample 191:\nQuestion: \"I want to terminate my account\"\nCategory:\n{{\n  \"category\": \"terminate_account\",\n  \"confidence\": 82.09\n}}\n\nExample 192:\nQuestion: \"Can you remove my account please?\"\nCategory:\n{{\n  \"category\": \"terminate_account\",\n  \"confidence\": 24.23\n}}\n\nExample 193:\nQuestion: \"make my account go away\"\nCategory:\n{{\n  \"category\": \"terminate_account\",\n  \"confidence\": 94.18\n}}\n\nExample 194:\nQuestion: \"I want to inactivate my account.\"\nCategory:\n{{\n  \"category\": \"terminate_account\",\n  \"confidence\": 93.93\n}}\n\nExample 195:\nQuestion: \"This company isn't good, I would like to delete my account.\"\nCategory:\n{{\n  \"category\": \"terminate_account\",\n  \"confidence\": 67.8\n}}\n\nExample 196:\nQuestion: \"Are there topping up fees if I have to transfer?\"\nCategory:\n{{\n  \"category\": \"top_up_by_bank_transfer_charge\",\n  \"confidence\": 6.14\n}}\n\nExample 197:\nQuestion: \"Do I pay a fee for SEPA transfers?\"\nCategory:\n{{\n  \"category\": \"top_up_by_bank_transfer_charge\",\n  \"confidence\": 69.0\n}}\n\nExample 198:\nQuestion: \"Does this program take SWIFT transfers?\"\nCategory:\n{{\n  \"category\": \"top_up_by_bank_transfer_charge\",\n  \"confidence\": 5.49\n}}\n\nExample 199:\nQuestion: \"What is the charge for receiving a SEPA transfer?\"\nCategory:\n{{\n  \"category\": \"top_up_by_bank_transfer_charge\",\n  \"confidence\": 45.63\n}}\n\nExample 200:\nQuestion: \"Is there a fee for transfer top-up?\"\nCategory:\n{{\n  \"category\": \"top_up_by_bank_transfer_charge\",\n  \"confidence\": 41.67\n}}\n\nExample 201:\nQuestion: \"Can I top up my balance with a cheque?\"\nCategory:\n{{\n  \"category\": \"top_up_by_cash_or_cheque\",\n  \"confidence\": 95.98\n}}\n\nExample 202:\nQuestion: \"Is it possible to top up with cash? If so how do I do it?\"\nCategory:\n{{\n  \"category\": \"top_up_by_cash_or_cheque\",\n  \"confidence\": 11.46\n}}\n\nExample 203:\nQuestion: \"Is there an option to top up a with cheque?\"\nCategory:\n{{\n  \"category\": \"top_up_by_cash_or_cheque\",\n  \"confidence\": 80.27\n}}\n\nExample 204:\nQuestion: \"I got a cheque that I want to top up with?\"\nCategory:\n{{\n  \"category\": \"top_up_by_cash_or_cheque\",\n  \"confidence\": 29.77\n}}\n\nExample 205:\nQuestion: \"I can't find how to top up my account with a check.  Where is that?\"\nCategory:\n{{\n  \"category\": \"top_up_by_cash_or_cheque\",\n  \"confidence\": 84.79\n}}\n\nExample 206:\nQuestion: \"I don't know why my credit card was declined while I was trying to top-up. Was it something on my end or was there something wrong with the top-up function?\"\nCategory:\n{{\n  \"category\": \"top_up_failed\",\n  \"confidence\": 86.37\n}}\n\nExample 207:\nQuestion: \"My top up was denied in the app.\"\nCategory:\n{{\n  \"category\": \"top_up_failed\",\n  \"confidence\": 31.94\n}}\n\nExample 208:\nQuestion: \"I've been trying to transfer funds to top-up my card, but the transaction is not going through.  Is there something I'm doing wrong?\"\nCategory:\n{{\n  \"category\": \"top_up_failed\",\n  \"confidence\": 61.04\n}}\n\nExample 209:\nQuestion: \"I don't think my top up is working correctly\"\nCategory:\n{{\n  \"category\": \"top_up_failed\",\n  \"confidence\": 12.32\n}}\n\nExample 210:\nQuestion: \"Why isn't my topup working?\"\nCategory:\n{{\n  \"category\": \"top_up_failed\",\n  \"confidence\": 30.74\n}}\n\nExample 211:\nQuestion: \"I want to know if there is a maximum I can top up.\"\nCategory:\n{{\n  \"category\": \"top_up_limits\",\n  \"confidence\": 36.65\n}}\n\nExample 212:\nQuestion: \"need to know if there is a maximum i can top up\"\nCategory:\n{{\n  \"category\": \"top_up_limits\",\n  \"confidence\": 24.58\n}}\n\nExample 213:\nQuestion: \"What is maximum top up?\"\nCategory:\n{{\n  \"category\": \"top_up_limits\",\n  \"confidence\": 0.46\n}}\n\nExample 214:\nQuestion: \"Do you have any top-up limits?\"\nCategory:\n{{\n  \"category\": \"top_up_limits\",\n  \"confidence\": 2.56\n}}\n\nExample 215:\nQuestion: \"How much can I top up in a day?\"\nCategory:\n{{\n  \"category\": \"top_up_limits\",\n  \"confidence\": 97.06\n}}\n\nExample 216:\nQuestion: \"How do I tell if my top up was reverted?\"\nCategory:\n{{\n  \"category\": \"top_up_reverted\",\n  \"confidence\": 83.62\n}}\n\nExample 217:\nQuestion: \"My top-up has been reverted and I would like to know why.\"\nCategory:\n{{\n  \"category\": \"top_up_reverted\",\n  \"confidence\": 27.5\n}}\n\nExample 218:\nQuestion: \"Why didn't my top up work?\"\nCategory:\n{{\n  \"category\": \"top_up_reverted\",\n  \"confidence\": 38.52\n}}\n\nExample 219:\nQuestion: \"The app reverted after I topped-up\"\nCategory:\n{{\n  \"category\": \"top_up_reverted\",\n  \"confidence\": 96.61\n}}\n\nExample 220:\nQuestion: \"I'm having an issue with transaction. I topped up my account and saw it went through, but that was a few days ago and the money isn't in my account any more. What's up with that?\"\nCategory:\n{{\n  \"category\": \"top_up_reverted\",\n  \"confidence\": 33.57\n}}\n\nExample 221:\nQuestion: \"How do my friends top up my account\"\nCategory:\n{{\n  \"category\": \"topping_up_by_card\",\n  \"confidence\": 39.23\n}}\n\nExample 222:\nQuestion: \"How can I use my credit card to transfer money?\"\nCategory:\n{{\n  \"category\": \"topping_up_by_card\",\n  \"confidence\": 26.95\n}}\n\nExample 223:\nQuestion: \"How can I transfer money using my credit card?\"\nCategory:\n{{\n  \"category\": \"topping_up_by_card\",\n  \"confidence\": 27.81\n}}\n\nExample 224:\nQuestion: \"How do I top up my card using your app? I'm new to this.\"\nCategory:\n{{\n  \"category\": \"topping_up_by_card\",\n  \"confidence\": 8.32\n}}\n\nExample 225:\nQuestion: \"I don't see me 'top up' in my wallet\"\nCategory:\n{{\n  \"category\": \"topping_up_by_card\",\n  \"confidence\": 36.15\n}}\n\nExample 226:\nQuestion: \"Can you help me? I have a duplicate transaction on my account and I don't understand why.\"\nCategory:\n{{\n  \"category\": \"transaction_charged_twice\",\n  \"confidence\": 78.33\n}}\n\nExample 227:\nQuestion: \"A transaction is repeated several times on my account.\"\nCategory:\n{{\n  \"category\": \"transaction_charged_twice\",\n  \"confidence\": 86.07\n}}\n\nExample 228:\nQuestion: \"Why would I be charged more than once for the same transaction?\"\nCategory:\n{{\n  \"category\": \"transaction_charged_twice\",\n  \"confidence\": 38.01\n}}\n\nExample 229:\nQuestion: \"I have been charged twice\"\nCategory:\n{{\n  \"category\": \"transaction_charged_twice\",\n  \"confidence\": 18.06\n}}\n\nExample 230:\nQuestion: \"I was charged twice.\"\nCategory:\n{{\n  \"category\": \"transaction_charged_twice\",\n  \"confidence\": 58.08\n}}\n\nExample 231:\nQuestion: \"This isn't fair! I thought transfers could be made for free. I just made  a purchase online from abroad and now see some strange fee that I've never seen before.\"\nCategory:\n{{\n  \"category\": \"transfer_fee_charged\",\n  \"confidence\": 33.46\n}}\n\nExample 232:\nQuestion: \"I had an unexpected fee\"\nCategory:\n{{\n  \"category\": \"transfer_fee_charged\",\n  \"confidence\": 21.95\n}}\n\nExample 233:\nQuestion: \"Where did my extra fee for the transfer come from?\"\nCategory:\n{{\n  \"category\": \"transfer_fee_charged\",\n  \"confidence\": 10.6\n}}\n\nExample 234:\nQuestion: \"Why was I charged a fee for transferring money\"\nCategory:\n{{\n  \"category\": \"transfer_fee_charged\",\n  \"confidence\": 41.84\n}}\n\nExample 235:\nQuestion: \"Why is there a charge for my transfer?\"\nCategory:\n{{\n  \"category\": \"transfer_fee_charged\",\n  \"confidence\": 50.63\n}}\n\nExample 236:\nQuestion: \"Tell me how to top up my account using bank transfer.\"\nCategory:\n{{\n  \"category\": \"transfer_into_account\",\n  \"confidence\": 73.85\n}}\n\nExample 237:\nQuestion: \"How can I transfer money from an outside bank?\"\nCategory:\n{{\n  \"category\": \"transfer_into_account\",\n  \"confidence\": 63.62\n}}\n\nExample 238:\nQuestion: \"How do I go forth on transferring money into my account?\"\nCategory:\n{{\n  \"category\": \"transfer_into_account\",\n  \"confidence\": 87.89\n}}\n\nExample 239:\nQuestion: \"How can I move money from an account at another bank to this one?\"\nCategory:\n{{\n  \"category\": \"transfer_into_account\",\n  \"confidence\": 40.19\n}}\n\nExample 240:\nQuestion: \"How can I fund my top-up account using my bank account?\"\nCategory:\n{{\n  \"category\": \"transfer_into_account\",\n  \"confidence\": 58.49\n}}\n\nExample 241:\nQuestion: \"I transferred some money and it didint arrive\"\nCategory:\n{{\n  \"category\": \"transfer_not_received_by_recipient\",\n  \"confidence\": 55.73\n}}\n\nExample 242:\nQuestion: \"How long will it take to receive my money from my transfer transaction?\"\nCategory:\n{{\n  \"category\": \"transfer_not_received_by_recipient\",\n  \"confidence\": 2.07\n}}\n\nExample 243:\nQuestion: \"I did a money transaction and the recipient doesn't see it\"\nCategory:\n{{\n  \"category\": \"transfer_not_received_by_recipient\",\n  \"confidence\": 54.3\n}}\n\nExample 244:\nQuestion: \"I sent some money and the receiver can't access it.\"\nCategory:\n{{\n  \"category\": \"transfer_not_received_by_recipient\",\n  \"confidence\": 45.46\n}}\n\nExample 245:\nQuestion: \"How much time do transfers take? I sent money to a friend who needs it fast. It's been hours, and the money has not gone through.\"\nCategory:\n{{\n  \"category\": \"transfer_not_received_by_recipient\",\n  \"confidence\": 74.52\n}}\n\nExample 246:\nQuestion: \"Why hasn't my transfer from Europe gone through?\"\nCategory:\n{{\n  \"category\": \"transfer_timing\",\n  \"confidence\": 18.29\n}}\n\nExample 247:\nQuestion: \"I must quickly transfer something from China, and I need to know how long it will take.\"\nCategory:\n{{\n  \"category\": \"transfer_timing\",\n  \"confidence\": 12.13\n}}\n\nExample 248:\nQuestion: \"I have to transfer something to China as fast as I can. How long will it take to arrive in China?\"\nCategory:\n{{\n  \"category\": \"transfer_timing\",\n  \"confidence\": 94.56\n}}\n\nExample 249:\nQuestion: \"How many days until my US transfer arrives?\"\nCategory:\n{{\n  \"category\": \"transfer_timing\",\n  \"confidence\": 32.4\n}}\n\nExample 250:\nQuestion: \"How fast can I transfer something from China?\"\nCategory:\n{{\n  \"category\": \"transfer_timing\",\n  \"confidence\": 1.82\n}}\n\nExample 251:\nQuestion: \"Why am I having trouble verifying my id?\"\nCategory:\n{{\n  \"category\": \"unable_to_verify_identity\",\n  \"confidence\": 25.63\n}}\n\nExample 252:\nQuestion: \"Hearing about your verification results from us may take anywhere from 10 minutes to approximately one hour.  If this verification has in fact, failed, double-check to make sure that your images are clear.  Also make sure that your document photos have no blur or glare. They need to be readable.  You must also be 18 years of age or older and be a resident of Switzerland or the European Economic Area to open an account.\"\nCategory:\n{{\n  \"category\": \"unable_to_verify_identity\",\n  \"confidence\": 58.19\n}}\n\nExample 253:\nQuestion: \"The app won't let me log in as myself.\"\nCategory:\n{{\n  \"category\": \"unable_to_verify_identity\",\n  \"confidence\": 7.3\n}}\n\nExample 254:\nQuestion: \"I don't have a way to prove my identity.\"\nCategory:\n{{\n  \"category\": \"unable_to_verify_identity\",\n  \"confidence\": 61.97\n}}\n\nExample 255:\nQuestion: \"The app doesn't believe that I am myself\"\nCategory:\n{{\n  \"category\": \"unable_to_verify_identity\",\n  \"confidence\": 18.41\n}}\n\nExample 256:\nQuestion: \"Please tell me how I verify my identity.\"\nCategory:\n{{\n  \"category\": \"verify_my_identity\",\n  \"confidence\": 56.46\n}}\n\nExample 257:\nQuestion: \"Which documents do I need for this identity check?\"\nCategory:\n{{\n  \"category\": \"verify_my_identity\",\n  \"confidence\": 85.09\n}}\n\nExample 258:\nQuestion: \"Can I get information on the identity checks?\"\nCategory:\n{{\n  \"category\": \"verify_my_identity\",\n  \"confidence\": 32.77\n}}\n\nExample 259:\nQuestion: \"What forms of ID do you need for identity verification?\"\nCategory:\n{{\n  \"category\": \"verify_my_identity\",\n  \"confidence\": 91.07\n}}\n\nExample 260:\nQuestion: \"What proof of identification is needed?\"\nCategory:\n{{\n  \"category\": \"verify_my_identity\",\n  \"confidence\": 7.72\n}}\n\nExample 261:\nQuestion: \"Can I verify the source of my funds?\"\nCategory:\n{{\n  \"category\": \"verify_source_of_funds\",\n  \"confidence\": 42.64\n}}\n\nExample 262:\nQuestion: \"What do I do to verify my source of funds?\"\nCategory:\n{{\n  \"category\": \"verify_source_of_funds\",\n  \"confidence\": 71.51\n}}\n\nExample 263:\nQuestion: \"Can you tell me where my funds come from?\"\nCategory:\n{{\n  \"category\": \"verify_source_of_funds\",\n  \"confidence\": 60.64\n}}\n\nExample 264:\nQuestion: \"What kind of security protects my money?\"\nCategory:\n{{\n  \"category\": \"verify_source_of_funds\",\n  \"confidence\": 56.79\n}}\n\nExample 265:\nQuestion: \"Are there steps to see where my funds come from?\"\nCategory:\n{{\n  \"category\": \"verify_source_of_funds\",\n  \"confidence\": 22.22\n}}\n\nExample 266:\nQuestion: \"Where do I find the top-up verification code?\"\nCategory:\n{{\n  \"category\": \"verify_top_up\",\n  \"confidence\": 99.87\n}}\n\nExample 267:\nQuestion: \"Where's the verification code for the top-up card?\"\nCategory:\n{{\n  \"category\": \"verify_top_up\",\n  \"confidence\": 45.97\n}}\n\nExample 268:\nQuestion: \"Why do the top-ups need to be verified?\"\nCategory:\n{{\n  \"category\": \"verify_top_up\",\n  \"confidence\": 2.49\n}}\n\nExample 269:\nQuestion: \"For what reason must I authenticate the top up?\"\nCategory:\n{{\n  \"category\": \"verify_top_up\",\n  \"confidence\": 55.38\n}}\n\nExample 270:\nQuestion: \"Why do I need to verify a top-up?\"\nCategory:\n{{\n  \"category\": \"verify_top_up\",\n  \"confidence\": 99.99\n}}\n\nExample 271:\nQuestion: \"My virtual car is not working.\"\nCategory:\n{{\n  \"category\": \"virtual_card_not_working\",\n  \"confidence\": 34.86\n}}\n\nExample 272:\nQuestion: \"My disposable virtual card won't work.\"\nCategory:\n{{\n  \"category\": \"virtual_card_not_working\",\n  \"confidence\": 21.68\n}}\n\nExample 273:\nQuestion: \"I cannot get my virtual card to function.\"\nCategory:\n{{\n  \"category\": \"virtual_card_not_working\",\n  \"confidence\": 41.79\n}}\n\nExample 274:\nQuestion: \"My virtual card won't work.\"\nCategory:\n{{\n  \"category\": \"virtual_card_not_working\",\n  \"confidence\": 9.31\n}}\n\nExample 275:\nQuestion: \"What do I do if my disposable virtual card doesn't work?\"\nCategory:\n{{\n  \"category\": \"virtual_card_not_working\",\n  \"confidence\": 33.83\n}}\n\nExample 276:\nQuestion: \"I don't want to use this method to identify myself.\"\nCategory:\n{{\n  \"category\": \"why_verify_identity\",\n  \"confidence\": 26.4\n}}\n\nExample 277:\nQuestion: \"I am afraid to give you all my identify details.\"\nCategory:\n{{\n  \"category\": \"why_verify_identity\",\n  \"confidence\": 45.61\n}}\n\nExample 278:\nQuestion: \"Why am I being asked to have an identity check\"\nCategory:\n{{\n  \"category\": \"why_verify_identity\",\n  \"confidence\": 15.22\n}}\n\nExample 279:\nQuestion: \"Am I supposed to verify my identity?\"\nCategory:\n{{\n  \"category\": \"why_verify_identity\",\n  \"confidence\": 46.04\n}}\n\nExample 280:\nQuestion: \"What is the purpose for the identity check\"\nCategory:\n{{\n  \"category\": \"why_verify_identity\",\n  \"confidence\": 81.02\n}}\n\nExample 281:\nQuestion: \"I did not get enough cash\"\nCategory:\n{{\n  \"category\": \"wrong_amount_of_cash_received\",\n  \"confidence\": 72.85\n}}\n\nExample 282:\nQuestion: \"I requested $100 but only got $20\"\nCategory:\n{{\n  \"category\": \"wrong_amount_of_cash_received\",\n  \"confidence\": 72.98\n}}\n\nExample 283:\nQuestion: \"Cash withdrawal was incorrect at ATM.\"\nCategory:\n{{\n  \"category\": \"wrong_amount_of_cash_received\",\n  \"confidence\": 87.03\n}}\n\nExample 284:\nQuestion: \"The ATM is messed up. It gave me less than I wanted.\"\nCategory:\n{{\n  \"category\": \"wrong_amount_of_cash_received\",\n  \"confidence\": 95.11\n}}\n\nExample 285:\nQuestion: \"ATM is broken. It did not give me the full amount (30 pounds.)  I'm standing here with only 10 pounds and it's telling me it gave me 30 pounds. I need assistance now!\"\nCategory:\n{{\n  \"category\": \"wrong_amount_of_cash_received\",\n  \"confidence\": 11.21\n}}\n---\n\n===============================\n\nNew Question: Could you help my figure out the exchange fee?\n\n===============================\n\nProvide your final classification in **valid JSON format** with the following structure:\n{\n  \"category\": \"your_chosen_category_name\",\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\n}\n\n\nEnsure the JSON has:\n- Opening and closing curly braces\n- Double quotes around keys and string values\n- Confidence as a number (not a string), with maximum 2 decimal places\n\nDo not include any explanations or extra text.\n            \nExample of how IntentSchema looks\n{'properties': {'category': {'enum': ['Refund_not_showing_up', 'activate_my_card', 'age_limit', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_swallowed', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'failed_transfer', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'oos', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'why_verify_identity', 'wrong_amount_of_cash_received'], 'title': 'Category', 'type': 'string'}, 'confidence': {'title': 'Confidence', 'type': 'number'}}, 'required': ['category', 'confidence'], 'title': 'IntentSchema', 'type': 'object'}\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 1 (subset row 2) | Elapsed: 7.87s | ETA: 70.83s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 3 (subset row 4) | Elapsed: 13.88s | ETA: 55.53s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 5 (subset row 6) | Elapsed: 16.47s | ETA: 38.44s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 7 (subset row 8) | Elapsed: 26.68s | ETA: 40.01s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 9 (subset row 10) | Elapsed: 33.11s | ETA: 33.11s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 11 (subset row 12) | Elapsed: 37.55s | ETA: 25.03s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 13 (subset row 14) | Elapsed: 39.62s | ETA: 16.98s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 15 (subset row 16) | Elapsed: 76.43s | ETA: 19.11s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 17 (subset row 18) | Elapsed: 91.80s | ETA: 10.20s\nEXIT_1A\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_1b\nEXIT_1c\nProcessed original df idx 19 (subset row 20) | Elapsed: 103.89s | ETA: 0.00s\nCompleted intent classification\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"# Sanity check folders","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/working/ && ls -la","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:43:52.635907Z","iopub.execute_input":"2025-07-07T04:43:52.636327Z","iopub.status.idle":"2025-07-07T04:43:52.774458Z","shell.execute_reply.started":"2025-07-07T04:43:52.636293Z","shell.execute_reply":"2025-07-07T04:43:52.773189Z"}},"outputs":[{"name":"stdout","text":"total 68\ndrwxr-xr-x 8 root root  4096 Jul  7 04:42 .\ndrwxr-xr-x 5 root root  4096 Jul  7 02:36 ..\ndrwxr-xr-x 7 root root  4096 Jul  7 02:37 data\n-rw-r--r-- 1 root root   695 Jul  7 02:36 download_dataset.py\ndrwxr-xr-x 7 root root  4096 Jul  7 02:41 fewshot\ndrwxr-xr-x 4 root root  4096 Jul  7 02:41 idx2label\n-rw-r--r-- 1 root root   952 Jul  7 03:55 main.py\n-rw-r--r-- 1 root root 13799 Jul  7 04:40 predict_class.py\ndrwxr-xr-x 2 root root  4096 Jul  7 02:36 prediction\n-rw-r--r-- 1 root root   132 Jul  7 02:36 requirements.txt\n-rw-r--r-- 1 root root  4869 Jul  7 04:42 results_gemini-2.5-flash-preview-05-20_banking_0_19.json\ndrwxr-xr-x 3 root root  4096 Jul  7 02:37 src\ndrwxr-xr-x 2 root root  4096 Jul  7 02:36 .virtual_documents\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"!cd /kaggle/working/src && ls -la","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:43:54.607760Z","iopub.execute_input":"2025-07-07T04:43:54.608178Z","iopub.status.idle":"2025-07-07T04:43:54.743041Z","shell.execute_reply.started":"2025-07-07T04:43:54.608147Z","shell.execute_reply":"2025-07-07T04:43:54.741612Z"}},"outputs":[{"name":"stdout","text":"total 24\ndrwxr-xr-x 3 root root 4096 Jul  7 02:37 .\ndrwxr-xr-x 8 root root 4096 Jul  7 04:42 ..\n-rw-r--r-- 1 root root 2142 Jul  7 04:40 config.py\n-rw-r--r-- 1 root root   20 Jul  7 02:36 __init__.py\ndrwxr-xr-x 2 root root 4096 Jul  7 04:40 __pycache__\n-rw-r--r-- 1 root root  965 Jul  7 02:36 setup_ollama.py\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"!cd /kaggle/working/data/data && ls -la","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:43:56.551933Z","iopub.execute_input":"2025-07-07T04:43:56.552366Z","iopub.status.idle":"2025-07-07T04:43:56.689140Z","shell.execute_reply.started":"2025-07-07T04:43:56.552327Z","shell.execute_reply":"2025-07-07T04:43:56.687779Z"}},"outputs":[{"name":"stdout","text":"total 20\ndrwxr-xr-x 5 root root 4096 Jul  7 02:37 .\ndrwxr-xr-x 7 root root 4096 Jul  7 02:37 ..\ndrwxr-xr-x 2 root root 4096 Jul  7 02:37 banking\ndrwxr-xr-x 2 root root 4096 Jul  7 02:37 oos\ndrwxr-xr-x 2 root root 4096 Jul  7 02:37 stackoverflow\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"# idx2label_oos examples","metadata":{}},{"cell_type":"code","source":"pip install huggingface-hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:13.367024Z","iopub.execute_input":"2025-07-07T04:44:13.367463Z","iopub.status.idle":"2025-07-07T04:44:17.261973Z","shell.execute_reply.started":"2025-07-07T04:44:13.367434Z","shell.execute_reply":"2025-07-07T04:44:17.260905Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2025.4.26)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir='/kaggle/working/idx2label')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:18.779852Z","iopub.execute_input":"2025-07-07T04:44:18.780266Z","iopub.status.idle":"2025-07-07T04:44:18.914079Z","shell.execute_reply.started":"2025-07-07T04:44:18.780228Z","shell.execute_reply":"2025-07-07T04:44:18.912609Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81346f124da04cdd8bfba0b3c453e92a"}},"metadata":{}},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/idx2label'"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"import pandas as pd\nidx2label = pd.read_csv('/kaggle/working/idx2label/dataset_idx2label/banking77_idx2label.csv')\nidx2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:19.880515Z","iopub.execute_input":"2025-07-07T04:44:19.880918Z","iopub.status.idle":"2025-07-07T04:44:19.910465Z","shell.execute_reply.started":"2025-07-07T04:44:19.880889Z","shell.execute_reply":"2025-07-07T04:44:19.909358Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"    index                                    label\n0       0                         activate_my_card\n1       1                                age_limit\n2       2                  apple_pay_or_google_pay\n3       3                              atm_support\n4       4                         automatic_top_up\n..    ...                                      ...\n72     72                 virtual_card_not_working\n73     73                       visa_or_mastercard\n74     74                      why_verify_identity\n75     75            wrong_amount_of_cash_received\n76     76  wrong_exchange_rate_for_cash_withdrawal\n\n[77 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>activate_my_card</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>age_limit</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>apple_pay_or_google_pay</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>atm_support</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>automatic_top_up</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>72</td>\n      <td>virtual_card_not_working</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>73</td>\n      <td>visa_or_mastercard</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>74</td>\n      <td>why_verify_identity</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>75</td>\n      <td>wrong_amount_of_cash_received</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>76</td>\n      <td>wrong_exchange_rate_for_cash_withdrawal</td>\n    </tr>\n  </tbody>\n</table>\n<p>77 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"idx2label_oos = idx2label[idx2label.index.isin([31,32,33,36])]\nidx2label_oos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:20.980043Z","iopub.execute_input":"2025-07-07T04:44:20.980485Z","iopub.status.idle":"2025-07-07T04:44:20.990857Z","shell.execute_reply.started":"2025-07-07T04:44:20.980452Z","shell.execute_reply":"2025-07-07T04:44:20.989897Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"    index                  label\n31     31        exchange_charge\n32     32          exchange_rate\n33     33       exchange_via_app\n36     36  fiat_currency_support","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>exchange_charge</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>exchange_rate</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>exchange_via_app</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>fiat_currency_support</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"print(idx2label_oos)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:23.747564Z","iopub.execute_input":"2025-07-07T04:44:23.747987Z","iopub.status.idle":"2025-07-07T04:44:23.754959Z","shell.execute_reply.started":"2025-07-07T04:44:23.747960Z","shell.execute_reply":"2025-07-07T04:44:23.754053Z"}},"outputs":[{"name":"stdout","text":"    index                  label\n31     31        exchange_charge\n32     32          exchange_rate\n33     33       exchange_via_app\n36     36  fiat_currency_support\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"idx2label_oos.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:28.721999Z","iopub.execute_input":"2025-07-07T04:44:28.722464Z","iopub.status.idle":"2025-07-07T04:44:28.729106Z","shell.execute_reply.started":"2025-07-07T04:44:28.722426Z","shell.execute_reply":"2025-07-07T04:44:28.727994Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(4, 2)"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"# percentage of OOS classes over ALL classes in the dataset\nlen(idx2label_oos)/len(idx2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:44:30.661843Z","iopub.execute_input":"2025-07-07T04:44:30.662165Z","iopub.status.idle":"2025-07-07T04:44:30.668218Z","shell.execute_reply.started":"2025-07-07T04:44:30.662142Z","shell.execute_reply":"2025-07-07T04:44:30.667083Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0.05194805194805195"},"metadata":{}}],"execution_count":74},{"cell_type":"markdown","source":"# Test 1 example with Gemini","metadata":{}},{"cell_type":"code","source":"from src.config import Config\nimport pandas as pd\nimport os\n# import ollama\nimport json\nimport pickle\nimport time\nfrom pydantic import BaseModel\nfrom typing import Literal\n# from enum import Enum\nfrom huggingface_hub import snapshot_download\n    \n###################\n# Gemini API\n###################\nfrom google import genai\n# from google.api_core import retry\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nfrom kaggle_secrets import UserSecretsClient\n\n# # allow retries\n# is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n# genai.models.Models.generate_content = retry.Retry(\n#     predicate=is_retriable)(genai.models.Models.generate_content)\n###################\n\n\n# Config.target_dir\n# Config.cloned_data_dir'\n# Config.dataset_name\n# Config.model_name\n# Config.start_index\n# Config.end_index\n# Config.log_every_n_examples\n\n\n#######################\n# load data\n#######################\ndef load_data(data_dir):\n    \"\"\"Loads train, dev, and test datasets from a specified directory.\"\"\"\n\n    main_df = pd.DataFrame()\n    for split in ['train', 'dev', 'test']:\n        file_path = os.path.join(data_dir, f'{split}.tsv')\n        if os.path.exists(file_path):\n          try:\n            df = pd.read_csv(file_path, sep='\\t')\n            df['dataset'] = os.path.basename(data_dir)\n            df['split'] = split\n            main_df = pd.concat([main_df, df], ignore_index=True)\n          except pd.errors.ParserError as e:\n            print(f\"Error parsing {file_path}: {e}\")\n            # Handle the error appropriately, e.g., skip the file, log the error, etc.\n        else:\n            print(f\"Warning: {split}.tsv not found in {data_dir}\")\n    return main_df\n\n\ndef filter100examples_oos(dataset_name, df):\n    # dont input 'only oos qns to model'\n    if Config.filter_oos_qns_only == False:\n        filtered_df = df\n    # vs\n    # input 'only oos qns to model'\n    else:\n        if dataset_name == 'banking':\n            first_class = Config.first_class_banking\n        elif dataset_name == 'stackoverflow':\n            first_class = Config.first_class_stackoverflow\n        else:\n            first_class = Config.first_class_oos\n    \n        filtered_df = df.copy()\n        filtered_df = filtered_df.loc[filtered_df[\"label\"] == first_class]\n        filtered_df = filtered_df.sample(n=Config.n_oos_qns, random_state=38)\n    return filtered_df\n\n\ndf = pd.DataFrame()\n\ndata_dir = os.path.join(Config.cloned_data_dir, Config.dataset_name)\nif os.path.exists(data_dir):\n  df = load_data(data_dir)\n  print(f\"Loaded dataset into dataframe: {Config.dataset_name}\")\n  print(f\"Dimensions: {df.shape}\")\n  print(f\"Col names: {df.columns}\")\nelse:\n  print(f\"Warning: Directory {data_dir} not found.\")\n#######################\n\n\n\n#######################\n# unique intents\n#######################\nsorted_intent = list(sorted(df.label.unique()))\nprint(\"=\"*80)\nprint(f\"Original dataset intents: {sorted_intent}\")\nprint(f\"Number of original intents: {len(sorted_intent)}\\n\")\n\n\n# 2025.06.03\n# New OOS approach - get 25/50/75% of class indexes for each dataset within the team (for reproducibility and comparable results)\n# Change their class labels to 'oos'\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*_idx2label.csv\", local_dir=Config.idx2label_target_dir)\nidx2label_filepath = Config.idx2label_target_dir + '/dataset_idx2label/' + Config.idx2label_filename_hf\nidx2label = pd.read_csv(idx2label_filepath)\nidx2label_oos = idx2label[idx2label.index.isin(Config.list_oos_idx)]\nidx2label_oos.reset_index(drop=True, inplace=True)\n\n# 2025.06.17 keep track of non-oos labels, to use in IntentSchema\nnonoos_labels = idx2label[~idx2label.label.isin(Config.list_oos_idx)]['label'].values\nprint(\"=\"*80)\nprint(\"Original intents to convert to OOS class\")\nprint(idx2label_oos)\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\\n\")\n\noos_labels = idx2label_oos['label'].values\nlist_sorted_intent_aft_conversion = ['oos' if intent.lower() in oos_labels else intent for intent in sorted_intent]\nlist_sorted_intent_aft_conversion_deduped = sorted(set(list_sorted_intent_aft_conversion))\nprint(\"=\"*80)\nprint(\"Unique intents after converting some to OOS class\")\nprint(list_sorted_intent_aft_conversion_deduped)\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\\n\")\n\n\n\n# unique intents - from set to bullet points (to use in prompts)\n# bulletpts_intent = \"\\n\".join(f\"- {category}\" for category in set_intent)\n# 2025.06.03: do not show 'oos' in the prompt (to avoid leakage of 'oos' class)\nbulletpts_intent = \"\\n\".join(f\"- {category}\" for category in list_sorted_intent_aft_conversion_deduped if category and (category!='oos'))\n\n# 2025.06.04: fix adjustment if 'oos' is already in the original dataset\nint_oos_in_orig_dataset = int('oos' in idx2label.label.values)\nadjust_if_oos_not_in_orig_dataset = [0 if int_oos_in_orig_dataset == 1 else 1][0]\n\nprint(\"=\"*80)\nprint(\"sanity check\")\nprint(f\"Number of original intents: {len(sorted_intent)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset): {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset}\")\nprint(f\"Number of original intents to convert to OOS class: {len(idx2label_oos)}\")\nprint(f\"Percentage of original intents to convert to OOS class: {len(idx2label_oos)/len(idx2label)}\")\nprint(f\"Number of unique intents after converting some to OOS class: {len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(f\"Number of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: {len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)}\")\nprint(f\"Numbers match: {(len(sorted_intent) + adjust_if_oos_not_in_orig_dataset - len(idx2label_oos)) == len(list_sorted_intent_aft_conversion_deduped)}\")\nprint(\"Prepared unique intents\")\n#######################\n\n\n\n\n#######################\n# Enforce schema on the model (e.g. allowed list of predicted categories)\n#######################\n\nclass IntentSchema(BaseModel):\n    # dynamically unpack list of categories for different dataset(s)\n    category: Literal[*list_sorted_intent_aft_conversion_deduped]\n    confidence: float\n    \n#######################\n\n\n\n\n#######################\n# filter after preparing intents\n#######################\ndf = filter100examples_oos(Config.dataset_name, df)\nprint(\"Filtered dataset\")\nprint(f\"Dimensions: {df.shape}\")\nprint(f\"Col names: {df.columns}\")\n#######################\n\n\n\n#######################\n# Prompt\n#######################\n# prompt 2 with less information/compute, improve efficiency\n# 2025.06.10 prompt 3 with 5 few shot examples only - notebook O1H1, O1i1\n# 2025.06.16 prompt 4 with 5 examples per each known intent (ie non-oos intent) - notebook 01J1\nsnapshot_download(repo_id=\"KaiquanMah/open-intent-query-classification\", repo_type=\"space\", allow_patterns=\"*.txt\", local_dir=Config.fewshot_examples_dir)\nwith open(Config.fewshot_examples_dir + Config.fewshot_subdir + Config.fewshot_examples_filename, 'r') as file:\n    fewshot_examples = file.read()\n\ndef get_prompt(dataset_name, split, question, categories, fewshot_examples):\n    \n    prompt = f'''\nYou are an expert in understanding and identifying what users are asking you.\n\nYour task is to analyze an input query from a user and assign the most appropriate category from the following list:\n{categories}\n\nOnly classify as \"oos\" (out of scope category) if none of the other categories apply.\n\nBelow are several examples to guide your classification:\n\n---\n{fewshot_examples}\n---\n\n===============================\n\nNew Question: {question}\n\n===============================\n\nProvide your final classification in **valid JSON format** with the following structure:\n{{\n  \"category\": \"your_chosen_category_name\",\n  \"confidence\": confidence_level_rounded_to_the_nearest_2_decimal_places\n}}\n\n\nEnsure the JSON has:\n- Opening and closing curly braces\n- Double quotes around keys and string values\n- Confidence as a number (not a string), with maximum 2 decimal places\n\nDo not include any explanations or extra text.\n            '''\n    return prompt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:08:37.879994Z","iopub.execute_input":"2025-07-07T03:08:37.880410Z","iopub.status.idle":"2025-07-07T03:08:38.389060Z","shell.execute_reply.started":"2025-07-07T03:08:37.880371Z","shell.execute_reply":"2025-07-07T03:08:38.387731Z"}},"outputs":[{"name":"stdout","text":"Loaded dataset into dataframe: banking\nDimensions: (13083, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\n================================================================================\nOriginal dataset intents: ['Refund_not_showing_up', 'activate_my_card', 'age_limit', 'apple_pay_or_google_pay', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_acceptance', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_not_working', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'card_swallowed', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_card_payment', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'exchange_charge', 'exchange_rate', 'exchange_via_app', 'extra_charge_on_statement', 'failed_transfer', 'fiat_currency_support', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'request_refund', 'reverted_card_payment?', 'supported_cards_and_currencies', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_card_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'visa_or_mastercard', 'why_verify_identity', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\nNumber of original intents: 77\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1842e30274a4817808ad8fdb33f8941"}},"metadata":{}},{"name":"stdout","text":"================================================================================\nOriginal intents to convert to OOS class\n    index                                    label\n0       2                  apple_pay_or_google_pay\n1      10                          card_acceptance\n2      14                         card_not_working\n3      15                 card_payment_fee_charged\n4      16              card_payment_not_recognised\n5      17         card_payment_wrong_exchange_rate\n6      19                   cash_withdrawal_charge\n7      25                    declined_card_payment\n8      31                          exchange_charge\n9      32                            exchange_rate\n10     33                         exchange_via_app\n11     34                extra_charge_on_statement\n12     36                    fiat_currency_support\n13     52                           request_refund\n14     53                   reverted_card_payment?\n15     54           supported_cards_and_currencies\n16     57                    top_up_by_card_charge\n17     73                       visa_or_mastercard\n18     76  wrong_exchange_rate_for_cash_withdrawal\nPercentage of original intents to convert to OOS class: 0.24675324675324675\n\n================================================================================\nUnique intents after converting some to OOS class\n['Refund_not_showing_up', 'activate_my_card', 'age_limit', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_swallowed', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'failed_transfer', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'oos', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'why_verify_identity', 'wrong_amount_of_cash_received']\nNumber of unique intents after converting some to OOS class: 59\n\n================================================================================\nsanity check\nNumber of original intents: 77\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset): 78\nNumber of original intents to convert to OOS class: 19\nPercentage of original intents to convert to OOS class: 0.24675324675324675\nNumber of unique intents after converting some to OOS class: 59\nNumber of original intents + 1 OOS class (if doesnt exist in original dataset) - converted classes: 59\nNumbers match: True\nPrepared unique intents\nFiltered dataset\nDimensions: (13083, 4)\nCol names: Index(['text', 'label', 'dataset', 'split'], dtype='object')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 62 files:   0%|          | 0/62 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2b273a669444c658634488a9853a565"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model_name = Config.model_name\ndf = df\ncategories = bulletpts_intent\nstart_index = Config.start_index\nend_index = Config.end_index\nlog_every_n_examples = Config.log_every_n_examples\n\n\nstart_time = time.time()\nresults = []  # Store processed results\n\n# Slice DataFrame based on start/end indices\nif end_index is None:\n    subset_df = df.iloc[start_index:]\nelse:\n    subset_df = df.iloc[start_index:end_index+1]\n\ntotal_rows = len(subset_df)\nsubset_row_count = 0\n\n\n# gemini\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\ngemini_client = genai.Client(api_key = GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:51:36.076652Z","iopub.execute_input":"2025-07-07T03:51:36.078282Z","iopub.status.idle":"2025-07-07T03:51:36.339560Z","shell.execute_reply.started":"2025-07-07T03:51:36.078231Z","shell.execute_reply":"2025-07-07T03:51:36.338227Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"@retry(stop=stop_after_attempt(3), wait=wait_fixed(30))\ndef gemini_llm(gemini_client, prompt):\n    print(\"EXIT_3A\")\n    gemini_config = {\"temperature\": 0,\n                     \"response_mime_type\": \"application/json\",\n                     \"response_schema\": IntentSchema.model_json_schema()}\n    print(\"EXIT_3B\")\n    response = client.models.generate_content(model = Config.model_name,\n                                   contents = prompt,\n                                   config = gemini_config \n                                  )    \n    print(\"EXIT_3C\")\n    print(response)\n    # msg = response.parsed\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:47:57.594645Z","iopub.execute_input":"2025-07-07T04:47:57.595234Z","iopub.status.idle":"2025-07-07T04:47:57.603085Z","shell.execute_reply.started":"2025-07-07T04:47:57.595197Z","shell.execute_reply":"2025-07-07T04:47:57.601494Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"for row in subset_df.itertuples():\n    subset_row_count+=1\n    prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n    if subset_row_count == 1:\n        print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n        print(prompt)\n\n        print(\"Example of how IntentSchema looks\")\n        print(IntentSchema.model_json_schema())\n    \n    \n    try:\n        print(\"EXIT_1A\")\n        \n        # response = ollama.chat(model=model_name, \n        #                        messages=[\n        #                                     {'role': 'user', 'content': prompt}\n        #                                 ],\n        #                        format = IntentSchema.model_json_schema(),\n        #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n        #                       )\n        # msg = response['message']['content']\n        # msg = gemini_llm(client, prompt)\n        gemini_config = {\"temperature\": 0,\n                 \"response_mime_type\": \"application/json\",\n                 \"response_schema\": IntentSchema.model_json_schema()}\n        response = client.models.generate_content(model = Config.model_name,\n                                   contents = prompt,\n                                   config = gemini_config \n                                  )\n        print(response)\n        parsed = response.parsed\n        print(\"EXIT_1b\")\n        # parsed = json.loads(response.text)\n        print(\"EXIT_1c\")\n        break\n\n        \n        # Safely extract keys with defaults - resolve parsing error\n        # maybe LLM did not output a particular key-value pair\n        category = parsed.get('category', 'error')\n        confidence = parsed.get('confidence', 0.0)\n        parsed = {'category': category, 'confidence': confidence}\n    except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(\"EXIT_2A\")\n            parsed = {'category': 'error', 'confidence': 0.0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:20:30.155979Z","iopub.execute_input":"2025-07-07T03:20:30.156333Z","iopub.status.idle":"2025-07-07T03:20:31.959096Z","shell.execute_reply.started":"2025-07-07T03:20:30.156306Z","shell.execute_reply":"2025-07-07T03:20:31.957928Z"}},"outputs":[{"name":"stdout","text":"EXIT_1A\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=178, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16355) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:17:36.477236Z","iopub.execute_input":"2025-07-07T03:17:36.477760Z","iopub.status.idle":"2025-07-07T03:17:36.485496Z","shell.execute_reply.started":"2025-07-07T03:17:36.477731Z","shell.execute_reply":"2025-07-07T03:17:36.484633Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='models/gemini-2.5-flash-preview-05-20', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=30, candidates_tokens_details=None, prompt_token_count=16154, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16154)], thoughts_token_count=1693, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17877), automatic_function_calling_history=[], parsed={'category': 'transfer_not_received_by_recipient', 'confidence': 85.0})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"response.parsed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:17:42.158461Z","iopub.execute_input":"2025-07-07T03:17:42.158998Z","iopub.status.idle":"2025-07-07T03:17:42.168200Z","shell.execute_reply.started":"2025-07-07T03:17:42.158960Z","shell.execute_reply":"2025-07-07T03:17:42.166195Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"type(response.parsed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:17:49.974195Z","iopub.execute_input":"2025-07-07T03:17:49.974656Z","iopub.status.idle":"2025-07-07T03:17:49.982307Z","shell.execute_reply.started":"2025-07-07T03:17:49.974623Z","shell.execute_reply":"2025-07-07T03:17:49.981234Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"dict"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:19:44.462523Z","iopub.execute_input":"2025-07-07T03:19:44.462935Z","iopub.status.idle":"2025-07-07T03:19:44.470275Z","shell.execute_reply.started":"2025-07-07T03:19:44.462906Z","shell.execute_reply":"2025-07-07T03:19:44.469048Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}'"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"json.loads(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:19:53.317999Z","iopub.execute_input":"2025-07-07T03:19:53.318384Z","iopub.status.idle":"2025-07-07T03:19:53.326289Z","shell.execute_reply.started":"2025-07-07T03:19:53.318355Z","shell.execute_reply":"2025-07-07T03:19:53.324936Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"type(json.loads(response.text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T03:19:58.246680Z","iopub.execute_input":"2025-07-07T03:19:58.247057Z","iopub.status.idle":"2025-07-07T03:19:58.253995Z","shell.execute_reply.started":"2025-07-07T03:19:58.247030Z","shell.execute_reply":"2025-07-07T03:19:58.252893Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"dict"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"for row in subset_df.itertuples():\n    subset_row_count+=1\n    prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n    if subset_row_count == 1:\n        print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n        print(prompt)\n\n        print(\"Example of how IntentSchema looks\")\n        print(IntentSchema.model_json_schema())\n    \n    \n    try:\n        print(\"EXIT_1A\")\n        \n        # response = ollama.chat(model=model_name, \n        #                        messages=[\n        #                                     {'role': 'user', 'content': prompt}\n        #                                 ],\n        #                        format = IntentSchema.model_json_schema(),\n        #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n        #                       )\n        # msg = response['message']['content']\n        \n        response = gemini_llm(gemini_client, prompt)\n        print(response)\n        parsed = response.parsed\n        print(\"EXIT_1b\")\n        # parsed = json.loads(response.text)\n        print(\"EXIT_1c\")\n        # break\n\n        \n        # Safely extract keys with defaults - resolve parsing error\n        # maybe LLM did not output a particular key-value pair\n        category = parsed.get('category', 'error')\n        confidence = parsed.get('confidence', 0.0)\n        parsed = {'category': category, 'confidence': confidence}\n    except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(\"EXIT_2A\")\n            parsed = {'category': 'error', 'confidence': 0.0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:48:06.437769Z","iopub.execute_input":"2025-07-07T04:48:06.438578Z","iopub.status.idle":"2025-07-07T04:49:52.040718Z","shell.execute_reply.started":"2025-07-07T04:48:06.438531Z","shell.execute_reply":"2025-07-07T04:49:52.039737Z"}},"outputs":[{"name":"stdout","text":"EXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=178, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16355) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=178, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16355) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16156, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16156)], thoughts_token_count=1240, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17433) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16156, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16156)], thoughts_token_count=1240, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17433) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"beneficiary_not_allowed\",\\n  \"confidence\": 88.17\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=27, candidates_tokens_details=None, prompt_token_count=16168, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16168)], thoughts_token_count=275, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16470) automatic_function_calling_history=[] parsed={'category': 'beneficiary_not_allowed', 'confidence': 88.17}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"beneficiary_not_allowed\",\\n  \"confidence\": 88.17\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=27, candidates_tokens_details=None, prompt_token_count=16168, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16168)], thoughts_token_count=275, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16470) automatic_function_calling_history=[] parsed={'category': 'beneficiary_not_allowed', 'confidence': 88.17}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_card_payment\",\\n  \"confidence\": 75.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=622, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16799) automatic_function_calling_history=[] parsed={'category': 'pending_card_payment', 'confidence': 75.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_card_payment\",\\n  \"confidence\": 75.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=622, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16799) automatic_function_calling_history=[] parsed={'category': 'pending_card_payment', 'confidence': 75.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=140, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16317) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=140, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16317) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_limits\",\\n  \"confidence\": 98.55\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=32, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16206) automatic_function_calling_history=[] parsed={'category': 'top_up_limits', 'confidence': 98.55}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_limits\",\\n  \"confidence\": 98.55\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=32, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16206) automatic_function_calling_history=[] parsed={'category': 'top_up_limits', 'confidence': 98.55}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16150, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16150)], thoughts_token_count=1749, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17921) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16150, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16150)], thoughts_token_count=1749, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17921) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_top_up\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=60, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16234) automatic_function_calling_history=[] parsed={'category': 'pending_top_up', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_top_up\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=60, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16234) automatic_function_calling_history=[] parsed={'category': 'pending_top_up', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=661, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16834) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=661, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16834) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=489, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16679) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 85.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=489, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16679) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 85.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_into_account\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16152, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16152)], thoughts_token_count=232, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16410) automatic_function_calling_history=[] parsed={'category': 'transfer_into_account', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_into_account\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16152, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16152)], thoughts_token_count=232, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16410) automatic_function_calling_history=[] parsed={'category': 'transfer_into_account', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_source_of_funds\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16155, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16155)], thoughts_token_count=201, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16384) automatic_function_calling_history=[] parsed={'category': 'verify_source_of_funds', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_source_of_funds\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16155, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16155)], thoughts_token_count=201, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16384) automatic_function_calling_history=[] parsed={'category': 'verify_source_of_funds', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_failed\",\\n  \"confidence\": 31.94\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16146, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16146)], thoughts_token_count=51, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16223) automatic_function_calling_history=[] parsed={'category': 'top_up_failed', 'confidence': 31.94}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_failed\",\\n  \"confidence\": 31.94\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16146, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16146)], thoughts_token_count=51, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16223) automatic_function_calling_history=[] parsed={'category': 'top_up_failed', 'confidence': 31.94}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_top_up\",\\n  \"confidence\": 99.99\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=38, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16215) automatic_function_calling_history=[] parsed={'category': 'verify_top_up', 'confidence': 99.99}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_top_up\",\\n  \"confidence\": 99.99\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=38, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16215) automatic_function_calling_history=[] parsed={'category': 'verify_top_up', 'confidence': 99.99}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"unable_to_verify_identity\",\\n  \"confidence\": 65.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=792, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16973) automatic_function_calling_history=[] parsed={'category': 'unable_to_verify_identity', 'confidence': 65.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"unable_to_verify_identity\",\\n  \"confidence\": 65.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=792, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16973) automatic_function_calling_history=[] parsed={'category': 'unable_to_verify_identity', 'confidence': 65.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_my_identity\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=199, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16376) automatic_function_calling_history=[] parsed={'category': 'verify_my_identity', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_my_identity\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=199, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16376) automatic_function_calling_history=[] parsed={'category': 'verify_my_identity', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transaction_charged_twice\",\\n  \"confidence\": 45.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=2736, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=18910) automatic_function_calling_history=[] parsed={'category': 'transaction_charged_twice', 'confidence': 45.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transaction_charged_twice\",\\n  \"confidence\": 45.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=2736, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=18910) automatic_function_calling_history=[] parsed={'category': 'transaction_charged_twice', 'confidence': 45.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"card_arrival\",\\n  \"confidence\": 90.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=24, candidates_tokens_details=None, prompt_token_count=16166, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16166)], thoughts_token_count=50, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16240) automatic_function_calling_history=[] parsed={'category': 'card_arrival', 'confidence': 90.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"card_arrival\",\\n  \"confidence\": 90.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=24, candidates_tokens_details=None, prompt_token_count=16166, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16166)], thoughts_token_count=50, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16240) automatic_function_calling_history=[] parsed={'category': 'card_arrival', 'confidence': 90.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=726, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16901) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=726, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16901) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=30, candidates_tokens_details=None, prompt_token_count=16154, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16154)], thoughts_token_count=1693, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17877) automatic_function_calling_history=[] parsed={'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=30, candidates_tokens_details=None, prompt_token_count=16154, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16154)], thoughts_token_count=1693, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17877) automatic_function_calling_history=[] parsed={'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}\nEXIT_1b\nEXIT_1c\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"for row in subset_df.itertuples():\n    subset_row_count+=1\n    prompt = get_prompt(row.dataset, row.split, row.text, categories, fewshot_examples)\n    if subset_row_count == 1:\n        print(\"Example of how prompt looks, for the 1st example in this subset of data\")\n        print(prompt)\n\n        print(\"Example of how IntentSchema looks\")\n        print(IntentSchema.model_json_schema())\n    \n    \n    try:\n        print(\"EXIT_1A\")\n        \n        # response = ollama.chat(model=model_name, \n        #                        messages=[\n        #                                     {'role': 'user', 'content': prompt}\n        #                                 ],\n        #                        format = IntentSchema.model_json_schema(),\n        #                        options = {'temperature': 0},  # Set temperature to 0 for a more deterministic output\n        #                       )\n        # msg = response['message']['content']\n        # msg = gemini_llm(client, prompt)\n        response = gemini_llm(gemini_client, prompt)\n        print(response)\n        parsed = response.parsed\n        print(\"EXIT_1b\")\n        # parsed = json.loads(response.text)\n        print(\"EXIT_1c\")\n        \n        # Safely extract keys with defaults - resolve parsing error\n        # maybe LLM did not output a particular key-value pair\n        category = parsed.get('category', 'error')\n        confidence = parsed.get('confidence', 0.0)\n        parsed = {'category': category, 'confidence': confidence}\n    except (json.JSONDecodeError, KeyError, Exception) as e:\n            print(\"EXIT_2A\")\n            parsed = {'category': 'error', 'confidence': 0.0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:49:52.042388Z","iopub.execute_input":"2025-07-07T04:49:52.042706Z","iopub.status.idle":"2025-07-07T04:52:08.755861Z","shell.execute_reply.started":"2025-07-07T04:49:52.042682Z","shell.execute_reply":"2025-07-07T04:52:08.754662Z"}},"outputs":[{"name":"stdout","text":"EXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=178, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16355) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=178, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16355) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16156, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16156)], thoughts_token_count=1240, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17433) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16156, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16156)], thoughts_token_count=1240, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17433) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"beneficiary_not_allowed\",\\n  \"confidence\": 88.17\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=27, candidates_tokens_details=None, prompt_token_count=16168, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16168)], thoughts_token_count=275, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16470) automatic_function_calling_history=[] parsed={'category': 'beneficiary_not_allowed', 'confidence': 88.17}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"beneficiary_not_allowed\",\\n  \"confidence\": 88.17\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=27, candidates_tokens_details=None, prompt_token_count=16168, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16168)], thoughts_token_count=275, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16470) automatic_function_calling_history=[] parsed={'category': 'beneficiary_not_allowed', 'confidence': 88.17}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_card_payment\",\\n  \"confidence\": 75.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=622, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16799) automatic_function_calling_history=[] parsed={'category': 'pending_card_payment', 'confidence': 75.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_card_payment\",\\n  \"confidence\": 75.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=622, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16799) automatic_function_calling_history=[] parsed={'category': 'pending_card_payment', 'confidence': 75.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=140, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16317) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_fee_charged\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=140, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16317) automatic_function_calling_history=[] parsed={'category': 'transfer_fee_charged', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_limits\",\\n  \"confidence\": 98.55\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=32, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16206) automatic_function_calling_history=[] parsed={'category': 'top_up_limits', 'confidence': 98.55}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_limits\",\\n  \"confidence\": 98.55\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=32, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16206) automatic_function_calling_history=[] parsed={'category': 'top_up_limits', 'confidence': 98.55}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16150, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16150)], thoughts_token_count=1749, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17921) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16150, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16150)], thoughts_token_count=1749, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17921) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_top_up\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=60, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16234) automatic_function_calling_history=[] parsed={'category': 'pending_top_up', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"pending_top_up\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=60, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16234) automatic_function_calling_history=[] parsed={'category': 'pending_top_up', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=661, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16834) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 95.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 95.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=661, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16834) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 95.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=489, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16679) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 85.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"balance_not_updated_after_cheque_or_cash_deposit\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=37, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=489, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16679) automatic_function_calling_history=[] parsed={'category': 'balance_not_updated_after_cheque_or_cash_deposit', 'confidence': 85.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_into_account\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16152, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16152)], thoughts_token_count=232, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16410) automatic_function_calling_history=[] parsed={'category': 'transfer_into_account', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_into_account\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16152, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16152)], thoughts_token_count=232, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16410) automatic_function_calling_history=[] parsed={'category': 'transfer_into_account', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_source_of_funds\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16155, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16155)], thoughts_token_count=201, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16384) automatic_function_calling_history=[] parsed={'category': 'verify_source_of_funds', 'confidence': 85.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_source_of_funds\",\\n  \"confidence\": 85.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16155, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16155)], thoughts_token_count=201, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16384) automatic_function_calling_history=[] parsed={'category': 'verify_source_of_funds', 'confidence': 85.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_failed\",\\n  \"confidence\": 31.94\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16146, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16146)], thoughts_token_count=51, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16223) automatic_function_calling_history=[] parsed={'category': 'top_up_failed', 'confidence': 31.94}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"top_up_failed\",\\n  \"confidence\": 31.94\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16146, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16146)], thoughts_token_count=51, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16223) automatic_function_calling_history=[] parsed={'category': 'top_up_failed', 'confidence': 31.94}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_top_up\",\\n  \"confidence\": 99.99\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=38, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16215) automatic_function_calling_history=[] parsed={'category': 'verify_top_up', 'confidence': 99.99}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_top_up\",\\n  \"confidence\": 99.99\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=38, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16215) automatic_function_calling_history=[] parsed={'category': 'verify_top_up', 'confidence': 99.99}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"unable_to_verify_identity\",\\n  \"confidence\": 65.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=792, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16973) automatic_function_calling_history=[] parsed={'category': 'unable_to_verify_identity', 'confidence': 65.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"unable_to_verify_identity\",\\n  \"confidence\": 65.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=28, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=792, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16973) automatic_function_calling_history=[] parsed={'category': 'unable_to_verify_identity', 'confidence': 65.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_my_identity\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=199, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16376) automatic_function_calling_history=[] parsed={'category': 'verify_my_identity', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"verify_my_identity\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16151, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16151)], thoughts_token_count=199, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16376) automatic_function_calling_history=[] parsed={'category': 'verify_my_identity', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transaction_charged_twice\",\\n  \"confidence\": 45.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=2736, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=18910) automatic_function_calling_history=[] parsed={'category': 'transaction_charged_twice', 'confidence': 45.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transaction_charged_twice\",\\n  \"confidence\": 45.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15750)], cached_content_token_count=15750, candidates_token_count=26, candidates_tokens_details=None, prompt_token_count=16148, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16148)], thoughts_token_count=2736, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=18910) automatic_function_calling_history=[] parsed={'category': 'transaction_charged_twice', 'confidence': 45.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"card_arrival\",\\n  \"confidence\": 90.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=24, candidates_tokens_details=None, prompt_token_count=16166, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16166)], thoughts_token_count=50, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16240) automatic_function_calling_history=[] parsed={'category': 'card_arrival', 'confidence': 90.5}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"card_arrival\",\\n  \"confidence\": 90.50\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=24, candidates_tokens_details=None, prompt_token_count=16166, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16166)], thoughts_token_count=50, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16240) automatic_function_calling_history=[] parsed={'category': 'card_arrival', 'confidence': 90.5}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=726, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16901) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"oos\",\\n  \"confidence\": 90.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=22, candidates_tokens_details=None, prompt_token_count=16153, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16153)], thoughts_token_count=726, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=16901) automatic_function_calling_history=[] parsed={'category': 'oos', 'confidence': 90.0}\nEXIT_1b\nEXIT_1c\nEXIT_1A\nEXIT_3A\nEXIT_3B\nEXIT_3C\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=30, candidates_tokens_details=None, prompt_token_count=16154, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16154)], thoughts_token_count=1693, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17877) automatic_function_calling_history=[] parsed={'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}\ncandidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"category\": \"transfer_not_received_by_recipient\",\\n  \"confidence\": 85.00\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=15751)], cached_content_token_count=15751, candidates_token_count=30, candidates_tokens_details=None, prompt_token_count=16154, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=16154)], thoughts_token_count=1693, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=17877) automatic_function_calling_history=[] parsed={'category': 'transfer_not_received_by_recipient', 'confidence': 85.0}\nEXIT_1b\nEXIT_1c\n","output_type":"stream"}],"execution_count":77}]}